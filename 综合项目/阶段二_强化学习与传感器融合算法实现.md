# 阶段二：强化学习与传感器融合算法实现

## 1. 深度强化学习导航控制器

### 1.1 DQN导航网络设计

#### 理论基础

对于机器人导航任务，我们需要设计合适的状态空间、动作空间和奖励函数：

**状态空间设计**：
$$s_t = [x_t, y_t, \theta_t, v_t, \omega_t, d_{goal}, \alpha_{goal}, d_{obs1}, d_{obs2}, ..., d_{obsn}]$$

其中：
- $(x_t, y_t, \theta_t)$：机器人当前位姿
- $(v_t, \omega_t)$：当前速度
- $d_{goal}$：到目标距离
- $\alpha_{goal}$：目标方向角
- $d_{obs_i}$：到障碍物的距离（激光雷达数据）

**动作空间设计**：
离散动作空间：$A = \{0, 1, 2, 3, 4\}$
- 0: 前进
- 1: 左转
- 2: 右转
- 3: 后退
- 4: 停止

**奖励函数设计**：
$$R(s_t, a_t, s_{t+1}) = R_{goal} + R_{progress} + R_{collision} + R_{smooth}$$

其中：
- $R_{goal} = 100$ if reached goal, else $0$
- $R_{progress} = 10 \times (d_{goal}^{(t)} - d_{goal}^{(t+1)})$
- $R_{collision} = -100$ if collision, else $0$
- $R_{smooth} = -0.1 \times |\omega_t|$ （平滑性惩罚）

#### DQN导航网络实现

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import random
from collections import deque
import matplotlib.pyplot as plt

class NavigationDQN(nn.Module):
    def __init__(self, state_size=13, action_size=5, hidden_size=128):
        """
        导航专用DQN网络

        Args:
            state_size: 状态维度（位姿+速度+目标信息+激光雷达）
            action_size: 动作数量
            hidden_size: 隐藏层大小
        """
        super(NavigationDQN, self).__init__()

        # 特征提取层
        self.feature_extractor = nn.Sequential(
            nn.Linear(state_size, hidden_size),
            nn.ReLU(),
            nn.BatchNorm1d(hidden_size),
            nn.Dropout(0.2)
        )

        # 价值流（Value Stream）
        self.value_stream = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Linear(hidden_size // 2, 1)
        )

        # 优势流（Advantage Stream）
        self.advantage_stream = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Linear(hidden_size // 2, action_size)
        )

    def forward(self, state):
        """前向传播 - Dueling DQN架构"""
        features = self.feature_extractor(state)

        # 计算状态值和优势值
        value = self.value_stream(features)
        advantage = self.advantage_stream(features)

        # Dueling DQN组合
        q_values = value + (advantage - advantage.mean(dim=1, keepdim=True))

        return q_values

class PrioritizedReplayBuffer:
    def __init__(self, capacity=50000, alpha=0.6):
        """
        优先经验回放缓冲区

        Args:
            capacity: 缓冲区容量
            alpha: 优先级指数
        """
        self.capacity = capacity
        self.alpha = alpha
        self.buffer = []
        self.pos = 0
        self.priorities = np.zeros((capacity,), dtype=np.float32)

    def push(self, state, action, reward, next_state, done):
        """添加经验"""
        max_prio = self.priorities.max() if self.buffer else 1.0

        if len(self.buffer) < self.capacity:
            self.buffer.append((state, action, reward, next_state, done))
        else:
            self.buffer[self.pos] = (state, action, reward, next_state, done)

        self.priorities[self.pos] = max_prio
        self.pos = (self.pos + 1) % self.capacity

    def sample(self, batch_size, beta=0.4):
        """采样经验"""
        if len(self.buffer) == self.capacity:
            prios = self.priorities
        else:
            prios = self.priorities[:self.pos]

        probs = prios ** self.alpha
        probs /= probs.sum()

        indices = np.random.choice(len(self.buffer), batch_size, p=probs)
        samples = [self.buffer[idx] for idx in indices]

        total = len(self.buffer)
        weights = (total * probs[indices]) ** (-beta)
        weights /= weights.max()
        weights = np.array(weights, dtype=np.float32)

        batch = list(zip(*samples))
        states = np.array(batch[0])
        actions = np.array(batch[1])
        rewards = np.array(batch[2])
        next_states = np.array(batch[3])
        dones = np.array(batch[4])

        return states, actions, rewards, next_states, dones, indices, weights

    def update_priorities(self, batch_indices, batch_priorities):
        """更新优先级"""
        for idx, prio in zip(batch_indices, batch_priorities):
            self.priorities[idx] = prio

    def __len__(self):
        return len(self.buffer)

class NavigationDQNAgent:
    def __init__(self, state_size, action_size, lr=1e-3, gamma=0.99,
                 epsilon_start=1.0, epsilon_end=0.01, epsilon_decay=0.995):
        """
        导航DQN智能体

        Args:
            state_size: 状态空间维度
            action_size: 动作空间大小
            lr: 学习率
            gamma: 折扣因子
            epsilon_start: 初始探索率
            epsilon_end: 最小探索率
            epsilon_decay: 探索率衰减
        """
        self.state_size = state_size
        self.action_size = action_size
        self.gamma = gamma
        self.epsilon = epsilon_start
        self.epsilon_end = epsilon_end
        self.epsilon_decay = epsilon_decay

        # 设备配置
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"使用设备: {self.device}")

        # 神经网络
        self.q_network = NavigationDQN(state_size, action_size).to(self.device)
        self.target_network = NavigationDQN(state_size, action_size).to(self.device)
        self.optimizer = optim.Adam(self.q_network.parameters(), lr=lr)

        # 经验回放
        self.memory = PrioritizedReplayBuffer()
        self.batch_size = 64
        self.update_frequency = 4
        self.target_update_frequency = 1000
        self.step_count = 0

        # 训练记录
        self.loss_history = []
        self.reward_history = []
        self.epsilon_history = []

    def act(self, state, training=True):
        """选择动作"""
        if training and random.random() <= self.epsilon:
            return random.choice(range(self.action_size))

        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)
        with torch.no_grad():
            q_values = self.q_network(state)
        return q_values.argmax().item()

    def remember(self, state, action, reward, next_state, done):
        """存储经验"""
        self.memory.push(state, action, reward, next_state, done)

    def learn(self):
        """从经验中学习"""
        if len(self.memory) < self.batch_size:
            return

        # 采样经验
        states, actions, rewards, next_states, dones, indices, weights = \
            self.memory.sample(self.batch_size)

        states = torch.FloatTensor(states).to(self.device)
        actions = torch.LongTensor(actions).to(self.device)
        rewards = torch.FloatTensor(rewards).to(self.device)
        next_states = torch.FloatTensor(next_states).to(self.device)
        dones = torch.BoolTensor(dones).to(self.device)
        weights = torch.FloatTensor(weights).to(self.device)

        # 当前Q值
        current_q_values = self.q_network(states).gather(1, actions.unsqueeze(1))

        # Double DQN目标Q值
        with torch.no_grad():
            next_actions = self.q_network(next_states).argmax(1, keepdim=True)
            next_q_values = self.target_network(next_states).gather(1, next_actions)
            target_q_values = rewards.unsqueeze(1) + (self.gamma * next_q_values * ~dones.unsqueeze(1))

        # 计算TD误差
        td_errors = target_q_values - current_q_values

        # 加权损失
        loss = (weights.unsqueeze(1) * td_errors.pow(2)).mean()

        # 优化
        self.optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(self.q_network.parameters(), 1.0)
        self.optimizer.step()

        # 更新优先级
        priorities = td_errors.abs().detach().cpu().numpy().flatten()
        self.memory.update_priorities(indices, priorities + 1e-6)

        # 记录损失
        self.loss_history.append(loss.item())

        # 更新目标网络
        self.step_count += 1
        if self.step_count % self.target_update_frequency == 0:
            self.target_network.load_state_dict(self.q_network.state_dict())

        # 衰减探索率
        if self.epsilon > self.epsilon_end:
            self.epsilon *= self.epsilon_decay

    def save_model(self, filepath):
        """保存模型"""
        torch.save({
            'q_network_state_dict': self.q_network.state_dict(),
            'target_network_state_dict': self.target_network.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'epsilon': self.epsilon,
            'step_count': self.step_count
        }, filepath)

    def load_model(self, filepath):
        """加载模型"""
        checkpoint = torch.load(filepath, map_location=self.device)
        self.q_network.load_state_dict(checkpoint['q_network_state_dict'])
        self.target_network.load_state_dict(checkpoint['target_network_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.epsilon = checkpoint['epsilon']
        self.step_count = checkpoint['step_count']

class NavigationEnvironment:
    def __init__(self, map_size=(10, 10), obstacle_ratio=0.2):
        """
        导航环境模拟器

        Args:
            map_size: 地图大小
            obstacle_ratio: 障碍物密度
        """
        self.map_size = map_size
        self.obstacle_ratio = obstacle_ratio
        self.reset()

    def reset(self):
        """重置环境"""
        # 生成随机地图
        self.map = np.random.random(self.map_size) < self.obstacle_ratio

        # 确保起点和终点可达
        self.start_pos = (1, 1)
        self.goal_pos = (self.map_size[0]-2, self.map_size[1]-2)
        self.map[self.start_pos] = False
        self.map[self.goal_pos] = False

        # 机器人状态
        self.robot_pos = np.array(self.start_pos, dtype=float)
        self.robot_theta = 0.0
        self.robot_v = 0.0
        self.robot_omega = 0.0

        # 步数计数
        self.step_count = 0
        self.max_steps = 200

        return self.get_state()

    def get_state(self):
        """获取当前状态"""
        # 机器人位姿和速度
        x, y = self.robot_pos
        theta = self.robot_theta
        v = self.robot_v
        omega = self.robot_omega

        # 目标相关信息
        goal_vector = np.array(self.goal_pos) - self.robot_pos
        d_goal = np.linalg.norm(goal_vector)
        alpha_goal = np.arctan2(goal_vector[1], goal_vector[0]) - theta
        alpha_goal = np.arctan2(np.sin(alpha_goal), np.cos(alpha_goal))  # 角度归一化

        # 激光雷达模拟（8个方向）
        laser_angles = np.linspace(0, 2*np.pi, 8, endpoint=False)
        laser_ranges = []
        max_range = 3.0

        for angle in laser_angles:
            scan_angle = theta + angle
            laser_range = self.cast_ray(self.robot_pos, scan_angle, max_range)
            laser_ranges.append(laser_range / max_range)  # 归一化

        # 组合状态
        state = np.array([
            x / self.map_size[0],  # 归一化位置
            y / self.map_size[1],
            np.sin(theta), np.cos(theta),  # 角度编码
            v, omega,  # 速度
            d_goal / (self.map_size[0] + self.map_size[1]),  # 归一化距离
            np.sin(alpha_goal), np.cos(alpha_goal),  # 目标角度编码
        ] + laser_ranges)

        return state.astype(np.float32)

    def cast_ray(self, start_pos, angle, max_range):
        """激光雷达射线投射"""
        step_size = 0.1
        current_pos = start_pos.copy()
        direction = np.array([np.cos(angle), np.sin(angle)])

        for distance in np.arange(0, max_range, step_size):
            current_pos += direction * step_size

            # 检查边界
            if (current_pos[0] < 0 or current_pos[0] >= self.map_size[0] or
                current_pos[1] < 0 or current_pos[1] >= self.map_size[1]):
                return distance

            # 检查障碍物
            map_pos = current_pos.astype(int)
            if self.map[map_pos[0], map_pos[1]]:
                return distance

        return max_range

    def step(self, action):
        """执行动作"""
        dt = 0.1

        # 动作映射
        if action == 0:  # 前进
            self.robot_v = min(self.robot_v + 0.5, 2.0)
            self.robot_omega = 0
        elif action == 1:  # 左转
            self.robot_omega = min(self.robot_omega + 0.5, 1.5)
        elif action == 2:  # 右转
            self.robot_omega = max(self.robot_omega - 0.5, -1.5)
        elif action == 3:  # 后退
            self.robot_v = max(self.robot_v - 0.5, -1.0)
            self.robot_omega = 0
        elif action == 4:  # 停止
            self.robot_v *= 0.8
            self.robot_omega *= 0.8

        # 更新机器人状态
        self.robot_pos[0] += self.robot_v * np.cos(self.robot_theta) * dt
        self.robot_pos[1] += self.robot_v * np.sin(self.robot_theta) * dt
        self.robot_theta += self.robot_omega * dt
        self.robot_theta = np.mod(self.robot_theta, 2 * np.pi)

        # 计算奖励
        reward = self.calculate_reward()

        # 检查终止条件
        done = self.is_done()

        self.step_count += 1

        return self.get_state(), reward, done

    def calculate_reward(self):
        """计算奖励"""
        # 到达目标
        goal_distance = np.linalg.norm(self.robot_pos - np.array(self.goal_pos))
        if goal_distance < 0.5:
            return 100

        # 碰撞检测
        if self.check_collision():
            return -100

        # 边界检测
        if (self.robot_pos[0] < 0 or self.robot_pos[0] >= self.map_size[0] or
            self.robot_pos[1] < 0 or self.robot_pos[1] >= self.map_size[1]):
            return -100

        # 进度奖励
        progress_reward = -goal_distance * 0.1

        # 平滑性惩罚
        smooth_penalty = -0.01 * abs(self.robot_omega)

        # 时间惩罚
        time_penalty = -0.1

        return progress_reward + smooth_penalty + time_penalty

    def check_collision(self):
        """碰撞检测"""
        robot_radius = 0.3
        map_pos = self.robot_pos.astype(int)

        # 检查机器人周围的网格
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                check_pos = map_pos + np.array([dx, dy])

                if (0 <= check_pos[0] < self.map_size[0] and
                    0 <= check_pos[1] < self.map_size[1]):

                    if self.map[check_pos[0], check_pos[1]]:
                        obstacle_center = check_pos + 0.5
                        distance = np.linalg.norm(self.robot_pos - obstacle_center)
                        if distance < robot_radius + 0.5:
                            return True

        return False

    def is_done(self):
        """检查是否结束"""
        # 到达目标
        goal_distance = np.linalg.norm(self.robot_pos - np.array(self.goal_pos))
        if goal_distance < 0.5:
            return True

        # 碰撞或越界
        if self.check_collision():
            return True

        if (self.robot_pos[0] < 0 or self.robot_pos[0] >= self.map_size[0] or
            self.robot_pos[1] < 0 or self.robot_pos[1] >= self.map_size[1]):
            return True

        # 超时
        if self.step_count >= self.max_steps:
            return True

        return False

    def render(self):
        """可视化环境"""
        plt.figure(figsize=(8, 8))

        # 绘制地图
        plt.imshow(self.map, cmap='Greys', origin='lower')

        # 绘制起点和终点
        plt.scatter(self.start_pos[1], self.start_pos[0], c='green', s=100, marker='s', label='起点')
        plt.scatter(self.goal_pos[1], self.goal_pos[0], c='red', s=100, marker='*', label='目标')

        # 绘制机器人
        plt.scatter(self.robot_pos[1], self.robot_pos[0], c='blue', s=80, marker='o', label='机器人')

        # 绘制机器人朝向
        arrow_length = 0.5
        dx = arrow_length * np.cos(self.robot_theta)
        dy = arrow_length * np.sin(self.robot_theta)
        plt.arrow(self.robot_pos[1], self.robot_pos[0], dy, dx,
                 head_width=0.2, head_length=0.1, fc='blue', ec='blue')

        plt.title(f'导航环境 - 步数: {self.step_count}')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.show()

# DQN训练函数
def train_navigation_dqn():
    """训练导航DQN智能体"""
    print("=== 开始训练导航DQN ===")

    # 创建环境和智能体
    env = NavigationEnvironment(map_size=(15, 15), obstacle_ratio=0.15)
    state_size = len(env.get_state())
    action_size = 5

    agent = NavigationDQNAgent(state_size, action_size)

    # 训练参数
    num_episodes = 2000
    max_steps_per_episode = 200
    target_score = 50  # 目标分数

    # 记录训练过程
    scores = []
    success_rates = []
    recent_scores = deque(maxlen=100)

    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0

        for step in range(max_steps_per_episode):
            action = agent.act(state)
            next_state, reward, done = env.step(action)

            agent.remember(state, action, reward, next_state, done)

            if step % agent.update_frequency == 0:
                agent.learn()

            state = next_state
            total_reward += reward

            if done:
                break

        scores.append(total_reward)
        recent_scores.append(total_reward)
        agent.reward_history.append(total_reward)
        agent.epsilon_history.append(agent.epsilon)

        # 计算成功率
        if episode >= 99:
            success_count = sum(1 for score in recent_scores if score > 50)
            success_rate = success_count / len(recent_scores)
            success_rates.append(success_rate)

        # 打印进度
        if episode % 100 == 0:
            avg_score = np.mean(recent_scores) if recent_scores else 0
            success_rate = success_rates[-1] if success_rates else 0
            print(f"Episode {episode}: 平均分数={avg_score:.2f}, "
                  f"成功率={success_rate:.2%}, ε={agent.epsilon:.3f}")

        # 早停条件
        if len(recent_scores) == 100 and np.mean(recent_scores) >= target_score:
            print(f"在第{episode}个episode达到目标分数！")
            break

    # 保存模型
    agent.save_model('navigation_dqn_model.pth')
    print("模型已保存")

    return agent, env, scores, success_rates

# 运行训练
if __name__ == "__main__":
    trained_agent, env, training_scores, success_rates = train_navigation_dqn()

    # 可视化训练结果
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # 学习曲线
    axes[0, 0].plot(training_scores, alpha=0.3)
    axes[0, 0].plot(np.convolve(training_scores, np.ones(100)/100, mode='valid'),
                    linewidth=2, label='100集平均')
    axes[0, 0].set_xlabel('Episode')
    axes[0, 0].set_ylabel('Total Reward')
    axes[0, 0].set_title('DQN学习曲线')
    axes[0, 0].legend()
    axes[0, 0].grid(True)

    # 成功率
    if success_rates:
        axes[0, 1].plot(success_rates, linewidth=2)
        axes[0, 1].set_xlabel('Episode (滑动窗口)')
        axes[0, 1].set_ylabel('Success Rate')
        axes[0, 1].set_title('导航成功率')
        axes[0, 1].grid(True)

    # 损失曲线
    if trained_agent.loss_history:
        axes[1, 0].plot(trained_agent.loss_history, alpha=0.7)
        axes[1, 0].set_xlabel('Training Step')
        axes[1, 0].set_ylabel('Loss')
        axes[1, 0].set_title('训练损失')
        axes[1, 0].grid(True)

    # 探索率衰减
    axes[1, 1].plot(trained_agent.epsilon_history, linewidth=2)
    axes[1, 1].set_xlabel('Episode')
    axes[1, 1].set_ylabel('Epsilon')
    axes[1, 1].set_title('探索率衰减')
    axes[1, 1].grid(True)

    plt.tight_layout()
    plt.show()

    print("DQN导航控制器训练完成！")
```

## 2. 多传感器融合EKF系统

### 2.1 机器人运动模型

#### 理论基础

**状态向量定义**：
$$\mathbf{x} = [p_x, p_y, \theta, v, \omega, b_{acc}, b_{gyro}]^T$$

其中：
- $(p_x, p_y, \theta)$：机器人位姿
- $(v, \omega)$：线速度和角速度
- $(b_{acc}, b_{gyro})$：加速度计和陀螺仪偏置

**运动模型**：
$$f(\mathbf{x}_k, \mathbf{u}_k, \Delta t) = \begin{bmatrix}
p_x + v \cos(\theta) \Delta t \\
p_y + v \sin(\theta) \Delta t \\
\theta + \omega \Delta t \\
v + u_v \Delta t \\
\omega + u_\omega \Delta t \\
b_{acc} \\
b_{gyro}
\end{bmatrix}$$

**观测模型**：
- IMU: $\mathbf{z}_{imu} = [\omega + b_{gyro} + n_\omega, a_x + b_{acc} + n_{acc}]^T$
- 里程计: $\mathbf{z}_{odom} = [p_x + n_{px}, p_y + n_{py}, \theta + n_\theta]^T$
- GPS: $\mathbf{z}_{gps} = [p_x + n_{gps_x}, p_y + n_{gps_y}]^T$

#### 多传感器EKF实现

```python
import numpy as np
from scipy.linalg import inv, cholesky
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse
from collections import deque
import threading
import time

class MultiSensorEKF:
    def __init__(self):
        """多传感器融合EKF"""

        # 状态维度：[px, py, theta, v, omega, b_acc, b_gyro]
        self.state_dim = 7

        # 初始化状态和协方差
        self.x = np.zeros((self.state_dim, 1))
        self.P = np.eye(self.state_dim) * 0.1

        # 过程噪声协方差
        self.Q = np.diag([0.01, 0.01, 0.005, 0.1, 0.05, 0.001, 0.001])

        # 观测噪声协方差
        self.R_imu = np.diag([0.01, 0.1])  # [gyro, acc]
        self.R_odom = np.diag([0.1, 0.1, 0.05])  # [px, py, theta]
        self.R_gps = np.diag([1.0, 1.0])  # [px, py]

        # 历史记录
        self.history = {
            'time': [],
            'state': [],
            'covariance': [],
            'innovation': {'imu': [], 'odom': [], 'gps': []},
            'measurement': {'imu': [], 'odom': [], 'gps': []}
        }

        # 数据同步
        self.last_predict_time = time.time()

    def predict(self, control_input, dt):
        """
        EKF预测步骤

        Args:
            control_input: [u_v, u_omega] 控制输入
            dt: 时间步长
        """
        # 当前状态
        px, py, theta, v, omega, b_acc, b_gyro = self.x.flatten()
        u_v, u_omega = control_input

        # 状态预测
        self.x = np.array([
            [px + v * np.cos(theta) * dt],
            [py + v * np.sin(theta) * dt],
            [theta + omega * dt],
            [v + u_v * dt],
            [omega + u_omega * dt],
            [b_acc],  # 偏置假设为常数
            [b_gyro]
        ])

        # 角度归一化
        self.x[2, 0] = self.normalize_angle(self.x[2, 0])

        # 雅可比矩阵
        F = self.compute_jacobian_f(v, theta, dt)

        # 协方差预测
        self.P = F @ self.P @ F.T + self.Q

        # 记录
        current_time = time.time()
        self.history['time'].append(current_time)
        self.history['state'].append(self.x.copy())
        self.history['covariance'].append(self.P.copy())

    def compute_jacobian_f(self, v, theta, dt):
        """计算运动模型雅可比矩阵"""
        F = np.eye(self.state_dim)

        F[0, 2] = -v * np.sin(theta) * dt  # dpx/dtheta
        F[0, 3] = np.cos(theta) * dt       # dpx/dv
        F[1, 2] = v * np.cos(theta) * dt   # dpy/dtheta
        F[1, 3] = np.sin(theta) * dt       # dpy/dv
        F[2, 4] = dt                       # dtheta/domega

        return F

    def update_imu(self, imu_measurement):
        """
        IMU观测更新

        Args:
            imu_measurement: [omega_measured, acc_x_measured]
        """
        # 当前状态
        omega, b_gyro = self.x[4, 0], self.x[6, 0]

        # 观测预测
        h = np.array([
            [omega + b_gyro],      # 角速度观测
            [imu_measurement[1]]   # 加速度（简化处理）
        ])

        # 观测雅可比矩阵
        H = np.zeros((2, self.state_dim))
        H[0, 4] = 1  # domega_obs/domega
        H[0, 6] = 1  # domega_obs/db_gyro
        H[1, 5] = 1  # dacc_obs/db_acc

        # 创新序列
        z = np.array(imu_measurement).reshape(-1, 1)
        y = z - h
        y[0, 0] = self.normalize_angle(y[0, 0])  # 角度创新归一化

        # 创新协方差
        S = H @ self.P @ H.T + self.R_imu

        # 卡尔曼增益
        K = self.P @ H.T @ inv(S)

        # 状态更新
        self.x = self.x + K @ y
        self.x[2, 0] = self.normalize_angle(self.x[2, 0])

        # 协方差更新
        I = np.eye(self.state_dim)
        self.P = (I - K @ H) @ self.P

        # 记录
        self.history['innovation']['imu'].append(y.copy())
        self.history['measurement']['imu'].append(z.copy())

    def update_odometry(self, odom_measurement):
        """
        里程计观测更新

        Args:
            odom_measurement: [px, py, theta]
        """
        # 观测预测（直接观测位姿）
        h = self.x[:3]  # [px, py, theta]

        # 观测雅可比矩阵
        H = np.zeros((3, self.state_dim))
        H[:3, :3] = np.eye(3)

        # 创新序列
        z = np.array(odom_measurement).reshape(-1, 1)
        y = z - h
        y[2, 0] = self.normalize_angle(y[2, 0])

        # 创新协方差
        S = H @ self.P @ H.T + self.R_odom

        # 卡尔曼增益
        K = self.P @ H.T @ inv(S)

        # 状态更新
        self.x = self.x + K @ y
        self.x[2, 0] = self.normalize_angle(self.x[2, 0])

        # 协方差更新
        I = np.eye(self.state_dim)
        self.P = (I - K @ H) @ self.P

        # 记录
        self.history['innovation']['odom'].append(y.copy())
        self.history['measurement']['odom'].append(z.copy())

    def update_gps(self, gps_measurement):
        """
        GPS观测更新

        Args:
            gps_measurement: [px, py]
        """
        # 观测预测（只观测位置）
        h = self.x[:2]  # [px, py]

        # 观测雅可比矩阵
        H = np.zeros((2, self.state_dim))
        H[:2, :2] = np.eye(2)

        # 创新序列
        z = np.array(gps_measurement).reshape(-1, 1)
        y = z - h

        # 创新协方差
        S = H @ self.P @ H.T + self.R_gps

        # 卡尔曼增益
        K = self.P @ H.T @ inv(S)

        # 状态更新
        self.x = self.x + K @ y

        # 协方差更新
        I = np.eye(self.state_dim)
        self.P = (I - K @ H) @ self.P

        # 记录
        self.history['innovation']['gps'].append(y.copy())
        self.history['measurement']['gps'].append(z.copy())

    def normalize_angle(self, angle):
        """角度归一化到[-π, π]"""
        return np.arctan2(np.sin(angle), np.cos(angle))

    def get_state(self):
        """获取当前状态估计"""
        return self.x.copy()

    def get_pose(self):
        """获取位姿估计"""
        return self.x[:3].flatten()

    def get_uncertainty_ellipse(self, confidence=0.95):
        """获取位置不确定性椭圆"""
        # 提取位置协方差
        P_pos = self.P[:2, :2]

        # 特征值分解
        eigenvals, eigenvecs = np.linalg.eigh(P_pos)

        # 置信度对应的卡方值
        chi2_val = 5.991 if confidence == 0.95 else 9.210  # 95% or 99%

        # 椭圆参数
        angle = np.degrees(np.arctan2(eigenvecs[1, 0], eigenvecs[0, 0]))
        width = 2 * np.sqrt(chi2_val * eigenvals[0])
        height = 2 * np.sqrt(chi2_val * eigenvals[1])

        return width, height, angle

class SensorDataSimulator:
    """传感器数据模拟器"""

    def __init__(self, true_trajectory):
        """
        Args:
            true_trajectory: 真实轨迹 [[x, y, theta, v, omega], ...]
        """
        self.true_trajectory = np.array(true_trajectory)

        # 传感器噪声参数
        self.imu_noise_std = {'gyro': 0.01, 'acc': 0.1}
        self.odom_noise_std = {'pos': 0.1, 'angle': 0.05}
        self.gps_noise_std = {'pos': 1.0}

        # 传感器偏置
        self.imu_bias = {'gyro': 0.02, 'acc': 0.05}

        # 传感器频率
        self.freq = {'imu': 100, 'odom': 10, 'gps': 1}

    def generate_imu_data(self, true_state, time_step):
        """生成IMU数据"""
        true_omega = true_state[4]

        # 添加偏置和噪声
        gyro_measurement = (true_omega + self.imu_bias['gyro'] +
                          np.random.normal(0, self.imu_noise_std['gyro']))

        # 简化的加速度测量（这里只考虑噪声）
        acc_measurement = np.random.normal(0, self.imu_noise_std['acc'])

        return [gyro_measurement, acc_measurement]

    def generate_odometry_data(self, true_state, time_step):
        """生成里程计数据"""
        true_px, true_py, true_theta = true_state[:3]

        # 添加噪声
        px_meas = true_px + np.random.normal(0, self.odom_noise_std['pos'])
        py_meas = true_py + np.random.normal(0, self.odom_noise_std['pos'])
        theta_meas = true_theta + np.random.normal(0, self.odom_noise_std['angle'])

        return [px_meas, py_meas, theta_meas]

    def generate_gps_data(self, true_state, time_step):
        """生成GPS数据"""
        true_px, true_py = true_state[:2]

        # 添加噪声
        px_meas = true_px + np.random.normal(0, self.gps_noise_std['pos'])
        py_meas = true_py + np.random.normal(0, self.gps_noise_std['pos'])

        return [px_meas, py_meas]

# 多传感器融合测试
def test_multisensor_ekf():
    """测试多传感器融合EKF"""
    print("=== 多传感器融合EKF测试 ===")

    # 生成真实轨迹（圆形轨迹）
    dt = 0.1
    time_steps = 300
    radius = 5.0
    angular_vel = 0.2

    true_trajectory = []
    for t in range(time_steps):
        time_val = t * dt
        x = radius * np.cos(angular_vel * time_val)
        y = radius * np.sin(angular_vel * time_val)
        theta = angular_vel * time_val + np.pi/2
        v = radius * angular_vel
        omega = angular_vel

        true_trajectory.append([x, y, theta, v, omega])

    # 创建EKF和传感器模拟器
    ekf = MultiSensorEKF()
    sensor_sim = SensorDataSimulator(true_trajectory)

    # 初始化EKF状态
    ekf.x[:3] = np.array([[true_trajectory[0][0]],
                         [true_trajectory[0][1]],
                         [true_trajectory[0][2]]])

    # 仿真数据融合
    estimates = []
    true_states = []

    for t in range(time_steps - 1):
        true_state = true_trajectory[t]
        next_true_state = true_trajectory[t + 1]

        # 控制输入（从真实轨迹推算）
        u_v = (next_true_state[3] - true_state[3]) / dt
        u_omega = (next_true_state[4] - true_state[4]) / dt
        control_input = [u_v, u_omega]

        # EKF预测
        ekf.predict(control_input, dt)

        # 传感器更新（不同频率）

        # IMU（高频）
        if t % (10 // sensor_sim.freq['imu'] * 10) == 0:
            imu_data = sensor_sim.generate_imu_data(true_state, t)
            ekf.update_imu(imu_data)

        # 里程计（中频）
        if t % (10 // sensor_sim.freq['odom']) == 0:
            odom_data = sensor_sim.generate_odometry_data(true_state, t)
            ekf.update_odometry(odom_data)

        # GPS（低频）
        if t % (10 // sensor_sim.freq['gps'] * 10) == 0:
            gps_data = sensor_sim.generate_gps_data(true_state, t)
            ekf.update_gps(gps_data)

        # 记录结果
        estimates.append(ekf.get_state().flatten())
        true_states.append(true_state)

    # 转换为numpy数组
    estimates = np.array(estimates)
    true_states = np.array(true_states)

    # 计算误差
    position_errors = np.sqrt((estimates[:, 0] - true_states[:, 0])**2 +
                             (estimates[:, 1] - true_states[:, 1])**2)
    angle_errors = np.abs(estimates[:, 2] - true_states[:, 2])

    # 可视化结果
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))

    # 轨迹对比
    axes[0, 0].plot(true_states[:, 0], true_states[:, 1], 'g-',
                    label='真实轨迹', linewidth=3)
    axes[0, 0].plot(estimates[:, 0], estimates[:, 1], 'b--',
                    label='EKF估计', linewidth=2)

    # 添加不确定性椭圆（每20个点一个）
    for i in range(0, len(estimates), 20):
        ekf.x = estimates[i].reshape(-1, 1)
        ekf.P = ekf.history['covariance'][i]
        width, height, angle = ekf.get_uncertainty_ellipse()

        ellipse = Ellipse((estimates[i, 0], estimates[i, 1]),
                         width, height, angle=angle,
                         fill=False, color='red', alpha=0.5)
        axes[0, 0].add_patch(ellipse)

    axes[0, 0].set_xlabel('X (m)')
    axes[0, 0].set_ylabel('Y (m)')
    axes[0, 0].set_title('轨迹对比与不确定性')
    axes[0, 0].legend()
    axes[0, 0].grid(True)
    axes[0, 0].axis('equal')

    # 位置误差
    time_axis = np.arange(len(position_errors)) * dt
    axes[0, 1].plot(time_axis, position_errors, 'r-', linewidth=2)
    axes[0, 1].set_xlabel('时间 (s)')
    axes[0, 1].set_ylabel('位置误差 (m)')
    axes[0, 1].set_title('位置估计误差')
    axes[0, 1].grid(True)

    # 角度误差
    axes[0, 2].plot(time_axis, np.degrees(angle_errors), 'b-', linewidth=2)
    axes[0, 2].set_xlabel('时间 (s)')
    axes[0, 2].set_ylabel('角度误差 (度)')
    axes[0, 2].set_title('角度估计误差')
    axes[0, 2].grid(True)

    # 状态分量对比
    state_labels = ['X位置', 'Y位置', '角度', '线速度', '角速度']
    for i in range(5):
        if i < 3:
            axes[1, i // 2 if i < 2 else 2].plot(time_axis, true_states[:, i],
                                                'g-', label=f'真实{state_labels[i]}', linewidth=2)
            axes[1, i // 2 if i < 2 else 2].plot(time_axis, estimates[:, i],
                                                'b--', label=f'估计{state_labels[i]}', linewidth=2)
            axes[1, i // 2 if i < 2 else 2].set_xlabel('时间 (s)')
            axes[1, i // 2 if i < 2 else 2].set_ylabel(state_labels[i])
            axes[1, i // 2 if i < 2 else 2].set_title(f'{state_labels[i]}对比')
            axes[1, i // 2 if i < 2 else 2].legend()
            axes[1, i // 2 if i < 2 else 2].grid(True)

    plt.tight_layout()
    plt.show()

    # 性能统计
    print(f"\n=== 性能统计 ===")
    print(f"平均位置误差: {np.mean(position_errors):.3f} m")
    print(f"位置误差标准差: {np.std(position_errors):.3f} m")
    print(f"最大位置误差: {np.max(position_errors):.3f} m")
    print(f"平均角度误差: {np.degrees(np.mean(angle_errors)):.2f} 度")
    print(f"角度误差标准差: {np.degrees(np.std(angle_errors)):.2f} 度")

    # 传感器融合效果分析
    print(f"\n=== 传感器融合分析 ===")
    print(f"IMU更新次数: {len(ekf.history['innovation']['imu'])}")
    print(f"里程计更新次数: {len(ekf.history['innovation']['odom'])}")
    print(f"GPS更新次数: {len(ekf.history['innovation']['gps'])}")

    # 创新序列分析
    if ekf.history['innovation']['imu']:
        imu_innovations = np.array(ekf.history['innovation']['imu'])
        print(f"IMU创新序列均值: {np.mean(imu_innovations, axis=0)}")
        print(f"IMU创新序列标准差: {np.std(imu_innovations, axis=0)}")

    return ekf, estimates, true_states

# 运行测试
if __name__ == "__main__":
    ekf_system, ekf_estimates, true_trajectory = test_multisensor_ekf()
    print("多传感器融合EKF测试完成！")
```

## 3. 传感器数据质量分析

### 3.1 创新序列分析

```python
def analyze_innovation_sequences(ekf):
    """分析创新序列以评估滤波器性能"""

    innovations = ekf.history['innovation']

    fig, axes = plt.subplots(3, 2, figsize=(15, 12))

    sensors = ['imu', 'odom', 'gps']
    sensor_names = ['IMU', '里程计', 'GPS']

    for i, (sensor, name) in enumerate(zip(sensors, sensor_names)):
        if innovations[sensor]:
            innov_data = np.array(innovations[sensor])

            # 创新序列时间序列
            axes[i, 0].plot(innov_data)
            axes[i, 0].set_title(f'{name} 创新序列')
            axes[i, 0].set_xlabel('更新次数')
            axes[i, 0].set_ylabel('创新值')
            axes[i, 0].grid(True)

            # 创新序列直方图
            for j in range(innov_data.shape[1]):
                axes[i, 1].hist(innov_data[:, j], bins=20, alpha=0.7,
                               label=f'分量 {j+1}')
            axes[i, 1].set_title(f'{name} 创新分布')
            axes[i, 1].set_xlabel('创新值')
            axes[i, 1].set_ylabel('频次')
            axes[i, 1].legend()
            axes[i, 1].grid(True)

            # 统计分析
            mean_innov = np.mean(innov_data, axis=0)
            std_innov = np.std(innov_data, axis=0)

            print(f"\n{name} 创新序列统计:")
            print(f"均值: {mean_innov}")
            print(f"标准差: {std_innov}")

            # 白噪声检验（简化）
            autocorr = np.corrcoef(innov_data[:-1, 0], innov_data[1:, 0])[0, 1]
            print(f"自相关系数: {autocorr:.4f}")

    plt.tight_layout()
    plt.show()

# 调用分析函数
analyze_innovation_sequences(ekf_system)
```

### 3.2 协方差一致性检验

```python
def covariance_consistency_check(estimates, true_states, covariances):
    """协方差一致性检验"""

    errors = estimates - true_states

    # 归一化误差平方（NEES）
    nees_values = []
    for i in range(len(errors)):
        error = errors[i][:3].reshape(-1, 1)  # 只检验位姿
        P_inv = np.linalg.inv(covariances[i][:3, :3])
        nees = float(error.T @ P_inv @ error)
        nees_values.append(nees)

    nees_values = np.array(nees_values)

    # 理论期望值（3个状态的卡方分布）
    expected_nees = 3.0

    # 95%置信区间
    from scipy.stats import chi2
    alpha = 0.05
    lower_bound = chi2.ppf(alpha/2, 3)
    upper_bound = chi2.ppf(1-alpha/2, 3)

    # 可视化
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(nees_values, 'b-', linewidth=2, label='NEES')
    plt.axhline(expected_nees, color='green', linestyle='--',
                label='理论期望值')
    plt.axhline(lower_bound, color='red', linestyle='--', alpha=0.7,
                label='95%置信区间')
    plt.axhline(upper_bound, color='red', linestyle='--', alpha=0.7)
    plt.xlabel('时间步')
    plt.ylabel('NEES值')
    plt.title('归一化误差平方检验')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.hist(nees_values, bins=30, density=True, alpha=0.7, label='实际分布')

    # 理论卡方分布
    x = np.linspace(0, max(nees_values), 100)
    theoretical_pdf = chi2.pdf(x, 3)
    plt.plot(x, theoretical_pdf, 'r-', linewidth=2, label='理论χ²(3)分布')

    plt.xlabel('NEES值')
    plt.ylabel('概率密度')
    plt.title('NEES分布对比')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

    # 统计检验
    mean_nees = np.mean(nees_values)
    consistency_ratio = np.sum((nees_values >= lower_bound) &
                              (nees_values <= upper_bound)) / len(nees_values)

    print(f"\n=== 协方差一致性检验结果 ===")
    print(f"平均NEES值: {mean_nees:.3f} (理论值: {expected_nees:.3f})")
    print(f"95%置信区间内比例: {consistency_ratio:.2%} (期望: 95%)")

    if 0.85 <= consistency_ratio <= 0.95:
        print("✓ 协方差估计一致")
    elif consistency_ratio < 0.85:
        print("✗ 协方差过估计（过于保守）")
    else:
        print("✗ 协方差欠估计（过于乐观）")

# 运行一致性检验
covariance_consistency_check(ekf_estimates, true_trajectory,
                           ekf_system.history['covariance'])
```

## 4. 算法性能优化

### 4.1 自适应噪声调整

```python
class AdaptiveMultiSensorEKF(MultiSensorEKF):
    """自适应噪声调整的多传感器EKF"""

    def __init__(self):
        super().__init__()

        # 自适应参数
        self.innovation_window = 10
        self.innovation_history = {
            'imu': deque(maxlen=self.innovation_window),
            'odom': deque(maxlen=self.innovation_window),
            'gps': deque(maxlen=self.innovation_window)
        }

        # 初始噪声协方差（作为基准）
        self.base_R_imu = self.R_imu.copy()
        self.base_R_odom = self.R_odom.copy()
        self.base_R_gps = self.R_gps.copy()

        # 自适应因子
        self.adaptation_factor = 1.5

    def adaptive_noise_adjustment(self, sensor_type, innovation):
        """自适应噪声调整"""

        # 存储创新序列
        self.innovation_history[sensor_type].append(innovation.copy())

        if len(self.innovation_history[sensor_type]) < self.innovation_window:
            return

        # 计算创新序列统计
        innovations = np.array(list(self.innovation_history[sensor_type]))
        sample_cov = np.cov(innovations.T)

        # 获取当前观测噪声协方差
        if sensor_type == 'imu':
            current_R = self.R_imu
            base_R = self.base_R_imu
        elif sensor_type == 'odom':
            current_R = self.R_odom
            base_R = self.base_R_odom
        elif sensor_type == 'gps':
            current_R = self.R_gps
            base_R = self.base_R_gps

        # 理论创新协方差（H*P*H' + R）
        # 简化：假设理论值约等于当前R
        theoretical_cov = current_R

        # 计算调整因子
        if sample_cov.shape == theoretical_cov.shape:
            # 使用迹比作为调整因子
            trace_ratio = np.trace(sample_cov) / np.trace(theoretical_cov)
            adjustment_factor = np.clip(trace_ratio, 0.5, 2.0)

            # 更新噪声协方差
            new_R = base_R * adjustment_factor

            if sensor_type == 'imu':
                self.R_imu = new_R
            elif sensor_type == 'odom':
                self.R_odom = new_R
            elif sensor_type == 'gps':
                self.R_gps = new_R

            print(f"{sensor_type} 噪声调整因子: {adjustment_factor:.3f}")

    def update_imu(self, imu_measurement):
        """带自适应调整的IMU更新"""
        # 标准更新
        super().update_imu(imu_measurement)

        # 自适应调整
        if self.history['innovation']['imu']:
            latest_innovation = self.history['innovation']['imu'][-1]
            self.adaptive_noise_adjustment('imu', latest_innovation)

    def update_odometry(self, odom_measurement):
        """带自适应调整的里程计更新"""
        super().update_odometry(odom_measurement)

        if self.history['innovation']['odom']:
            latest_innovation = self.history['innovation']['odom'][-1]
            self.adaptive_noise_adjustment('odom', latest_innovation)

    def update_gps(self, gps_measurement):
        """带自适应调整的GPS更新"""
        super().update_gps(gps_measurement)

        if self.history['innovation']['gps']:
            latest_innovation = self.history['innovation']['gps'][-1]
            self.adaptive_noise_adjustment('gps', latest_innovation)
```

### 4.2 异常检测与鲁棒滤波

```python
class RobustMultiSensorEKF(AdaptiveMultiSensorEKF):
    """鲁棒多传感器EKF（异常检测）"""

    def __init__(self):
        super().__init__()

        # 异常检测参数
        self.outlier_threshold = 3.0  # 3-sigma准则
        self.rejected_measurements = {
            'imu': 0, 'odom': 0, 'gps': 0
        }

    def mahalanobis_distance(self, innovation, innovation_cov):
        """计算马氏距离"""
        try:
            inv_cov = np.linalg.inv(innovation_cov)
            distance = np.sqrt(innovation.T @ inv_cov @ innovation)
            return float(distance)
        except np.linalg.LinAlgError:
            return float('inf')

    def outlier_detection(self, innovation, innovation_cov, sensor_type):
        """异常检测"""

        # 计算马氏距离
        mahal_dist = self.mahalanobis_distance(innovation, innovation_cov)

        # 异常检测
        is_outlier = mahal_dist > self.outlier_threshold

        if is_outlier:
            self.rejected_measurements[sensor_type] += 1
            print(f"检测到{sensor_type}异常测量，马氏距离: {mahal_dist:.3f}")

        return is_outlier

    def robust_update_imu(self, imu_measurement):
        """鲁棒IMU更新"""
        # 计算创新和创新协方差
        omega, b_gyro = self.x[4, 0], self.x[6, 0]
        h = np.array([[omega + b_gyro], [imu_measurement[1]]])

        H = np.zeros((2, self.state_dim))
        H[0, 4] = 1
        H[0, 6] = 1
        H[1, 5] = 1

        z = np.array(imu_measurement).reshape(-1, 1)
        innovation = z - h
        innovation[0, 0] = self.normalize_angle(innovation[0, 0])

        innovation_cov = H @ self.P @ H.T + self.R_imu

        # 异常检测
        if not self.outlier_detection(innovation, innovation_cov, 'imu'):
            self.update_imu(imu_measurement)

    def robust_update_odometry(self, odom_measurement):
        """鲁棒里程计更新"""
        h = self.x[:3]
        H = np.zeros((3, self.state_dim))
        H[:3, :3] = np.eye(3)

        z = np.array(odom_measurement).reshape(-1, 1)
        innovation = z - h
        innovation[2, 0] = self.normalize_angle(innovation[2, 0])

        innovation_cov = H @ self.P @ H.T + self.R_odom

        if not self.outlier_detection(innovation, innovation_cov, 'odom'):
            self.update_odometry(odom_measurement)

    def robust_update_gps(self, gps_measurement):
        """鲁棒GPS更新"""
        h = self.x[:2]
        H = np.zeros((2, self.state_dim))
        H[:2, :2] = np.eye(2)

        z = np.array(gps_measurement).reshape(-1, 1)
        innovation = z - h

        innovation_cov = H @ self.P @ H.T + self.R_gps

        if not self.outlier_detection(innovation, innovation_cov, 'gps'):
            self.update_gps(gps_measurement)

    def get_rejection_statistics(self):
        """获取异常拒绝统计"""
        total_measurements = sum(self.rejected_measurements.values())
        print(f"\n=== 异常检测统计 ===")
        for sensor, count in self.rejected_measurements.items():
            print(f"{sensor} 拒绝次数: {count}")
        print(f"总拒绝次数: {total_measurements}")
```

## 学习检查点

### 算法实现验证

1. **DQN导航控制器**：
   - 网络架构合理性
   - 训练收敛性分析
   - 导航成功率评估

2. **多传感器EKF**：
   - 状态估计精度
   - 创新序列白噪声特性
   - 协方差一致性

3. **算法优化效果**：
   - 自适应调整有效性
   - 异常检测准确率
   - 整体系统鲁棒性

### 下一阶段准备

完成本阶段后，学生应掌握：
- 深度强化学习在导航中的应用
- 多传感器数据融合的完整实现
- 滤波器性能分析和优化方法
- 为系统集成做好技术准备

**推荐实践**：
1. 调试和优化DQN网络参数
2. 验证EKF在不同噪声条件下的性能
3. 实现并测试自适应和鲁棒滤波算法