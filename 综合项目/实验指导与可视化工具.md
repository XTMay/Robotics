# å®éªŒæŒ‡å¯¼ä¸å¯è§†åŒ–å·¥å…·

## 1. é€æ­¥å®éªŒæŒ‡å¯¼

### 1.1 å®éªŒç¯å¢ƒæ­å»ºæŒ‡å¯¼

#### Step 1: åŸºç¡€ç¯å¢ƒå®‰è£…

```bash
#!/bin/bash
# ç¯å¢ƒå®‰è£…è„šæœ¬ï¼šsetup_environment.sh

echo "=== å¼ºåŒ–å­¦ä¹ ä¸ä¼ æ„Ÿå™¨èåˆé¡¹ç›®ç¯å¢ƒæ­å»º ==="

# æ£€æŸ¥æ“ä½œç³»ç»Ÿ
if [[ "$OSTYPE" == "linux-gnu"* ]]; then
    echo "æ£€æµ‹åˆ°Linuxç³»ç»Ÿï¼Œå¼€å§‹å®‰è£…..."

    # æ›´æ–°ç³»ç»ŸåŒ…
    sudo apt update && sudo apt upgrade -y

    # å®‰è£…Python 3.8+
    sudo apt install python3.8 python3.8-dev python3.8-venv python3-pip -y

    # å®‰è£…ç³»ç»Ÿä¾èµ–
    sudo apt install build-essential cmake git wget curl -y
    sudo apt install libatlas-base-dev liblapack-dev gfortran -y
    sudo apt install libjpeg-dev libpng-dev -y

elif [[ "$OSTYPE" == "darwin"* ]]; then
    echo "æ£€æµ‹åˆ°macOSç³»ç»Ÿï¼Œå¼€å§‹å®‰è£…..."

    # æ£€æŸ¥Homebrew
    if ! command -v brew &> /dev/null; then
        echo "å®‰è£…Homebrew..."
        /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
    fi

    # å®‰è£…ä¾èµ–
    brew install python@3.8 cmake git wget
    brew install openblas lapack

else
    echo "ä¸æ”¯æŒçš„æ“ä½œç³»ç»Ÿ: $OSTYPE"
    exit 1
fi

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
echo "åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ..."
python3 -m venv venv_rl_fusion
source venv_rl_fusion/bin/activate

# å‡çº§pip
pip install --upgrade pip setuptools wheel

# å®‰è£…æ ¸å¿ƒä¾èµ–
echo "å®‰è£…Pythonä¾èµ–åŒ…..."
pip install torch torchvision torchaudio
pip install numpy scipy matplotlib seaborn
pip install pandas scikit-learn
pip install jupyter ipykernel
pip install tqdm psutil

# å®‰è£…æœºå™¨äººç›¸å…³åŒ…
pip install gymnasium[classic_control]
pip install stable-baselines3
pip install opencv-python
pip install plotly dash

# å®‰è£…å¯é€‰çš„ROSåŒ…ï¼ˆå¦‚æœéœ€è¦ï¼‰
read -p "æ˜¯å¦å®‰è£…ROS Noetic? (y/n): " install_ros
if [[ $install_ros == "y" ]]; then
    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        echo "å®‰è£…ROS Noetic..."
        sudo sh -c 'echo "deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main" > /etc/apt/sources.list.d/ros-latest.list'
        sudo apt-key adv --keyserver 'hkp://keyserver.ubuntu.com:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654
        sudo apt update
        sudo apt install ros-noetic-desktop-full -y
        sudo apt install python3-rosdep python3-rosinstall python3-rosinstall-generator python3-wstool build-essential -y
        sudo rosdep init && rosdep update
        echo "source /opt/ros/noetic/setup.bash" >> ~/.bashrc
    else
        echo "ROSä»…æ”¯æŒLinuxç³»ç»Ÿ"
    fi
fi

# åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„
echo "åˆ›å»ºé¡¹ç›®ç›®å½•..."
mkdir -p project_rl_fusion/{src,data,models,results,docs,tests}

# åˆ›å»ºé…ç½®æ–‡ä»¶
cat > project_rl_fusion/requirements.txt << EOF
torch>=1.8.0
numpy>=1.21.0
scipy>=1.7.0
matplotlib>=3.3.0
seaborn>=0.11.0
pandas>=1.3.0
scikit-learn>=1.0.0
jupyter>=1.0.0
tqdm>=4.62.0
psutil>=5.8.0
gymnasium>=0.26.0
stable-baselines3>=1.6.0
opencv-python>=4.5.0
plotly>=5.0.0
dash>=2.0.0
EOF

echo "=== ç¯å¢ƒæ­å»ºå®Œæˆ ==="
echo "æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ: source venv_rl_fusion/bin/activate"
echo "è¿›å…¥é¡¹ç›®ç›®å½•: cd project_rl_fusion"
```

#### Step 2: éªŒè¯å®‰è£…

```python
# verification_script.py
"""
ç¯å¢ƒéªŒè¯è„šæœ¬
è¿è¡Œæ­¤è„šæœ¬éªŒè¯æ‰€æœ‰ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…
"""

import sys
import importlib
import torch
import numpy as np
import matplotlib.pyplot as plt

def check_python_version():
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    version = sys.version_info
    print(f"Pythonç‰ˆæœ¬: {version.major}.{version.minor}.{version.micro}")

    if version.major >= 3 and version.minor >= 8:
        print("âœ“ Pythonç‰ˆæœ¬ç¬¦åˆè¦æ±‚")
        return True
    else:
        print("âœ— Pythonç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦3.8+")
        return False

def check_package(package_name, import_name=None):
    """æ£€æŸ¥åŒ…æ˜¯å¦å®‰è£…"""
    if import_name is None:
        import_name = package_name

    try:
        importlib.import_module(import_name)
        print(f"âœ“ {package_name} å·²å®‰è£…")
        return True
    except ImportError:
        print(f"âœ— {package_name} æœªå®‰è£…")
        return False

def check_gpu_availability():
    """æ£€æŸ¥GPUå¯ç”¨æ€§"""
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        gpu_name = torch.cuda.get_device_name(0)
        print(f"âœ“ GPUå¯ç”¨: {gpu_count}ä¸ªè®¾å¤‡")
        print(f"  ä¸»è¦GPU: {gpu_name}")
        return True
    else:
        print("! GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
        return False

def main():
    """ä¸»éªŒè¯å‡½æ•°"""
    print("=== ç¯å¢ƒéªŒè¯ ===")

    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_ok = check_python_version()

    # æ£€æŸ¥æ ¸å¿ƒåŒ…
    packages = [
        ('NumPy', 'numpy'),
        ('SciPy', 'scipy'),
        ('Matplotlib', 'matplotlib'),
        ('PyTorch', 'torch'),
        ('Pandas', 'pandas'),
        ('Scikit-learn', 'sklearn'),
        ('Jupyter', 'jupyter'),
        ('OpenCV', 'cv2'),
        ('Gymnasium', 'gymnasium'),
        ('Stable-Baselines3', 'stable_baselines3')
    ]

    package_status = []
    for package_name, import_name in packages:
        status = check_package(package_name, import_name)
        package_status.append(status)

    # æ£€æŸ¥GPU
    gpu_available = check_gpu_availability()

    # è¿è¡Œç®€å•æµ‹è¯•
    print("\n=== åŠŸèƒ½æµ‹è¯• ===")

    try:
        # NumPyæµ‹è¯•
        arr = np.random.randn(100, 100)
        result = np.dot(arr, arr.T)
        print("âœ“ NumPyçŸ©é˜µè¿ç®—æ­£å¸¸")
    except Exception as e:
        print(f"âœ— NumPyæµ‹è¯•å¤±è´¥: {e}")

    try:
        # PyTorchæµ‹è¯•
        x = torch.randn(10, 10)
        y = torch.mm(x, x.t())
        if torch.cuda.is_available():
            x_gpu = x.cuda()
            y_gpu = torch.mm(x_gpu, x_gpu.t())
            print("âœ“ PyTorch GPUè¿ç®—æ­£å¸¸")
        else:
            print("âœ“ PyTorch CPUè¿ç®—æ­£å¸¸")
    except Exception as e:
        print(f"âœ— PyTorchæµ‹è¯•å¤±è´¥: {e}")

    try:
        # Matplotlibæµ‹è¯•
        fig, ax = plt.subplots()
        ax.plot([1, 2, 3], [1, 4, 9])
        plt.close(fig)
        print("âœ“ Matplotlibç»˜å›¾æ­£å¸¸")
    except Exception as e:
        print(f"âœ— Matplotlibæµ‹è¯•å¤±è´¥: {e}")

    # æ€»ç»“
    print("\n=== éªŒè¯æ€»ç»“ ===")
    total_packages = len(packages)
    installed_packages = sum(package_status)

    print(f"Pythonç‰ˆæœ¬: {'ç¬¦åˆè¦æ±‚' if python_ok else 'éœ€è¦å‡çº§'}")
    print(f"ä¾èµ–åŒ…: {installed_packages}/{total_packages} å·²å®‰è£…")
    print(f"GPUæ”¯æŒ: {'å¯ç”¨' if gpu_available else 'ä¸å¯ç”¨'}")

    if python_ok and installed_packages == total_packages:
        print("ğŸ‰ ç¯å¢ƒéªŒè¯æˆåŠŸï¼å¯ä»¥å¼€å§‹é¡¹ç›®å¼€å‘")
        return True
    else:
        print("âŒ ç¯å¢ƒéªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
```

### 1.2 å®éªŒä¸€ï¼šåŸºç¡€ç®—æ³•éªŒè¯

#### å®éªŒç›®æ ‡
éªŒè¯Q-Learningå’Œå¡å°”æ›¼æ»¤æ³¢çš„åŸºæœ¬å®ç°

#### å®éªŒæ­¥éª¤

```python
# experiment_1_basic_verification.py
"""
å®éªŒä¸€ï¼šåŸºç¡€ç®—æ³•éªŒè¯
"""

import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict, deque
import time

class ExperimentLogger:
    """å®éªŒæ—¥å¿—è®°å½•å™¨"""

    def __init__(self, experiment_name):
        self.experiment_name = experiment_name
        self.start_time = time.time()
        self.logs = []
        self.metrics = {}

        print(f"=== å¼€å§‹å®éªŒ: {experiment_name} ===")
        print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")

    def log(self, message):
        """è®°å½•æ—¥å¿—"""
        timestamp = time.time() - self.start_time
        log_entry = f"[{timestamp:.2f}s] {message}"
        print(log_entry)
        self.logs.append(log_entry)

    def record_metric(self, name, value):
        """è®°å½•æŒ‡æ ‡"""
        if name not in self.metrics:
            self.metrics[name] = []
        self.metrics[name].append(value)

    def finish(self):
        """ç»“æŸå®éªŒ"""
        duration = time.time() - self.start_time
        print(f"=== å®éªŒå®Œæˆ: {self.experiment_name} ===")
        print(f"æ€»è€—æ—¶: {duration:.2f}ç§’")
        return duration

def experiment_1_q_learning():
    """å®éªŒ1ï¼šQ-Learningç®—æ³•éªŒè¯"""

    logger = ExperimentLogger("Q-Learningç®—æ³•éªŒè¯")

    # æ­¥éª¤1: åˆ›å»ºç®€å•ç¯å¢ƒ
    logger.log("æ­¥éª¤1: åˆ›å»ºGridWorldç¯å¢ƒ")

    class SimpleGridWorld:
        def __init__(self, size=5):
            self.size = size
            self.reset()

        def reset(self):
            self.state = (0, 0)
            self.goal = (self.size-1, self.size-1)
            return self.state

        def step(self, action):
            x, y = self.state

            if action == 0 and x > 0:  # ä¸Š
                x -= 1
            elif action == 1 and x < self.size-1:  # ä¸‹
                x += 1
            elif action == 2 and y > 0:  # å·¦
                y -= 1
            elif action == 3 and y < self.size-1:  # å³
                y += 1

            self.state = (x, y)

            if self.state == self.goal:
                reward = 10
                done = True
            else:
                reward = -0.1
                done = False

            return self.state, reward, done

    env = SimpleGridWorld(5)
    logger.log(f"ç¯å¢ƒåˆ›å»ºå®Œæˆ: {env.size}x{env.size}ç½‘æ ¼")

    # æ­¥éª¤2: å®ç°Q-Learning
    logger.log("æ­¥éª¤2: å®ç°Q-Learningç®—æ³•")

    class QLearningAgent:
        def __init__(self, actions, lr=0.1, gamma=0.9, epsilon=0.1):
            self.actions = actions
            self.lr = lr
            self.gamma = gamma
            self.epsilon = epsilon
            self.q_table = defaultdict(lambda: np.zeros(len(actions)))

        def get_action(self, state):
            if np.random.random() < self.epsilon:
                return np.random.choice(self.actions)
            else:
                return np.argmax(self.q_table[state])

        def learn(self, state, action, reward, next_state):
            current_q = self.q_table[state][action]
            next_max_q = np.max(self.q_table[next_state])

            td_error = reward + self.gamma * next_max_q - current_q
            self.q_table[state][action] += self.lr * td_error

            return abs(td_error)

    agent = QLearningAgent([0, 1, 2, 3])
    logger.log("Q-Learningæ™ºèƒ½ä½“åˆ›å»ºå®Œæˆ")

    # æ­¥éª¤3: è®­ç»ƒæ™ºèƒ½ä½“
    logger.log("æ­¥éª¤3: å¼€å§‹è®­ç»ƒ")

    num_episodes = 500
    rewards_per_episode = []
    td_errors = []

    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0
        episode_td_errors = []

        for step in range(100):
            action = agent.get_action(state)
            next_state, reward, done = env.step(action)

            td_error = agent.learn(state, action, reward, next_state)
            episode_td_errors.append(td_error)

            state = next_state
            total_reward += reward

            if done:
                break

        rewards_per_episode.append(total_reward)
        td_errors.extend(episode_td_errors)

        logger.record_metric('episode_reward', total_reward)
        logger.record_metric('avg_td_error', np.mean(episode_td_errors))

        if episode % 100 == 0:
            avg_reward = np.mean(rewards_per_episode[-100:])
            logger.log(f"Episode {episode}: å¹³å‡å¥–åŠ± = {avg_reward:.2f}")

    # æ­¥éª¤4: è¯„ä¼°æ€§èƒ½
    logger.log("æ­¥éª¤4: è¯„ä¼°å­¦ä¹ æ•ˆæœ")

    # æµ‹è¯•å­¦ä¹ åçš„ç­–ç•¥
    agent.epsilon = 0  # å…³é—­æ¢ç´¢
    test_rewards = []

    for _ in range(100):
        state = env.reset()
        total_reward = 0

        for step in range(100):
            action = agent.get_action(state)
            state, reward, done = env.step(action)
            total_reward += reward

            if done:
                break

        test_rewards.append(total_reward)

    success_rate = sum(1 for r in test_rewards if r > 5) / len(test_rewards)
    avg_test_reward = np.mean(test_rewards)

    logger.log(f"æµ‹è¯•ç»“æœ:")
    logger.log(f"  æˆåŠŸç‡: {success_rate:.2%}")
    logger.log(f"  å¹³å‡å¥–åŠ±: {avg_test_reward:.2f}")

    # æ­¥éª¤5: å¯è§†åŒ–ç»“æœ
    logger.log("æ­¥éª¤5: ç”Ÿæˆå¯è§†åŒ–ç»“æœ")

    fig, axes = plt.subplots(2, 2, figsize=(12, 10))

    # å­¦ä¹ æ›²çº¿
    axes[0, 0].plot(rewards_per_episode, alpha=0.3)
    axes[0, 0].plot(np.convolve(rewards_per_episode, np.ones(50)/50, mode='valid'), linewidth=2)
    axes[0, 0].set_title('Q-Learningå­¦ä¹ æ›²çº¿')
    axes[0, 0].set_xlabel('Episode')
    axes[0, 0].set_ylabel('æ€»å¥–åŠ±')
    axes[0, 0].grid(True)

    # TDè¯¯å·®
    axes[0, 1].plot(td_errors[:1000], alpha=0.7)
    axes[0, 1].set_title('TDè¯¯å·®å˜åŒ–')
    axes[0, 1].set_xlabel('è®­ç»ƒæ­¥éª¤')
    axes[0, 1].set_ylabel('TDè¯¯å·®')
    axes[0, 1].grid(True)

    # Qå€¼çƒ­åŠ›å›¾
    q_values = np.zeros((env.size, env.size))
    for i in range(env.size):
        for j in range(env.size):
            state = (i, j)
            q_values[i, j] = np.max(agent.q_table[state])

    im = axes[1, 0].imshow(q_values, cmap='viridis')
    axes[1, 0].set_title('çŠ¶æ€å€¼å‡½æ•°')
    plt.colorbar(im, ax=axes[1, 0])

    # æœ€ä¼˜ç­–ç•¥
    policy = np.zeros((env.size, env.size))
    for i in range(env.size):
        for j in range(env.size):
            state = (i, j)
            policy[i, j] = np.argmax(agent.q_table[state])

    axes[1, 1].imshow(policy, cmap='tab10')
    axes[1, 1].set_title('æœ€ä¼˜ç­–ç•¥')

    # æ·»åŠ ç®­å¤´è¡¨ç¤ºåŠ¨ä½œ
    for i in range(env.size):
        for j in range(env.size):
            action = int(policy[i, j])
            if action == 0:  # ä¸Š
                axes[1, 1].arrow(j, i, 0, -0.3, head_width=0.1, head_length=0.1, fc='white', ec='white')
            elif action == 1:  # ä¸‹
                axes[1, 1].arrow(j, i, 0, 0.3, head_width=0.1, head_length=0.1, fc='white', ec='white')
            elif action == 2:  # å·¦
                axes[1, 1].arrow(j, i, -0.3, 0, head_width=0.1, head_length=0.1, fc='white', ec='white')
            elif action == 3:  # å³
                axes[1, 1].arrow(j, i, 0.3, 0, head_width=0.1, head_length=0.1, fc='white', ec='white')

    plt.tight_layout()
    plt.savefig('experiment_1_q_learning_results.png', dpi=300, bbox_inches='tight')
    plt.show()

    duration = logger.finish()

    return {
        'success_rate': success_rate,
        'avg_reward': avg_test_reward,
        'duration': duration,
        'convergence_episodes': num_episodes
    }

def experiment_2_kalman_filter():
    """å®éªŒ2ï¼šå¡å°”æ›¼æ»¤æ³¢éªŒè¯"""

    logger = ExperimentLogger("å¡å°”æ›¼æ»¤æ³¢éªŒè¯")

    # æ­¥éª¤1: åˆ›å»ºä¸€ç»´è·Ÿè¸ªé—®é¢˜
    logger.log("æ­¥éª¤1: è®¾ç½®ä¸€ç»´ç‰©ä½“è·Ÿè¸ªé—®é¢˜")

    dt = 0.1
    time_steps = 200

    # ç³»ç»Ÿå‚æ•°
    F = np.array([[1, dt], [0, 1]])  # çŠ¶æ€è½¬ç§»çŸ©é˜µ
    H = np.array([[1, 0]])           # è§‚æµ‹çŸ©é˜µ
    Q = np.array([[0.01, 0], [0, 0.01]])  # è¿‡ç¨‹å™ªå£°
    R = np.array([[1.0]])            # è§‚æµ‹å™ªå£°

    x0 = np.array([[0], [1]])        # åˆå§‹çŠ¶æ€
    P0 = np.eye(2)                   # åˆå§‹åæ–¹å·®

    logger.log(f"ç³»ç»Ÿå‚æ•°è®¾ç½®å®Œæˆï¼Œä»¿çœŸæ—¶é•¿: {time_steps * dt:.1f}ç§’")

    # æ­¥éª¤2: å®ç°å¡å°”æ›¼æ»¤æ³¢å™¨
    logger.log("æ­¥éª¤2: å®ç°å¡å°”æ›¼æ»¤æ³¢å™¨")

    class KalmanFilter:
        def __init__(self, F, H, Q, R, x0, P0):
            self.F = F
            self.H = H
            self.Q = Q
            self.R = R
            self.x = x0
            self.P = P0
            self.history = {'x': [], 'P': []}

        def predict(self):
            self.x = self.F @ self.x
            self.P = self.F @ self.P @ self.F.T + self.Q

        def update(self, z):
            S = self.H @ self.P @ self.H.T + self.R
            K = self.P @ self.H.T @ np.linalg.inv(S)

            y = z - self.H @ self.x
            self.x = self.x + K @ y
            self.P = (np.eye(len(self.x)) - K @ self.H) @ self.P

            self.history['x'].append(self.x.copy())
            self.history['P'].append(self.P.copy())

            return y, S  # è¿”å›åˆ›æ–°å’Œåˆ›æ–°åæ–¹å·®

    kf = KalmanFilter(F, H, Q, R, x0, P0)
    logger.log("å¡å°”æ›¼æ»¤æ³¢å™¨åˆ›å»ºå®Œæˆ")

    # æ­¥éª¤3: ç”Ÿæˆä»¿çœŸæ•°æ®
    logger.log("æ­¥éª¤3: ç”ŸæˆçœŸå®è½¨è¿¹å’Œè§‚æµ‹æ•°æ®")

    true_positions = []
    true_velocities = []
    observations = []

    true_pos = 0
    true_vel = 1

    for t in range(time_steps):
        # çœŸå®ç³»ç»Ÿæ¼”åŒ–
        true_pos += true_vel * dt
        true_vel += np.random.normal(0, 0.1)  # è¿‡ç¨‹å™ªå£°

        true_positions.append(true_pos)
        true_velocities.append(true_vel)

        # ç”Ÿæˆè§‚æµ‹
        obs = true_pos + np.random.normal(0, 1.0)
        observations.append(obs)

    logger.log(f"ç”Ÿæˆäº†{len(observations)}ä¸ªè§‚æµ‹æ•°æ®ç‚¹")

    # æ­¥éª¤4: è¿è¡Œæ»¤æ³¢
    logger.log("æ­¥éª¤4: è¿è¡Œå¡å°”æ›¼æ»¤æ³¢")

    estimates = []
    innovations = []
    innovation_covariances = []

    for obs in observations:
        kf.predict()
        innovation, innovation_cov = kf.update(np.array([[obs]]))

        estimates.append(kf.x[0, 0])
        innovations.append(innovation[0, 0])
        innovation_covariances.append(innovation_cov[0, 0])

        logger.record_metric('position_estimate', kf.x[0, 0])
        logger.record_metric('velocity_estimate', kf.x[1, 0])
        logger.record_metric('innovation', innovation[0, 0])

    # æ­¥éª¤5: æ€§èƒ½è¯„ä¼°
    logger.log("æ­¥éª¤5: è¯„ä¼°æ»¤æ³¢æ€§èƒ½")

    position_errors = np.array(estimates) - np.array(true_positions)
    rmse = np.sqrt(np.mean(position_errors**2))
    mae = np.mean(np.abs(position_errors))

    # åˆ›æ–°åºåˆ—ç»Ÿè®¡æ£€éªŒ
    innovation_mean = np.mean(innovations)
    innovation_std = np.std(innovations)
    theoretical_std = np.sqrt(np.mean(innovation_covariances))

    logger.log(f"æ€§èƒ½æŒ‡æ ‡:")
    logger.log(f"  RMSE: {rmse:.3f}")
    logger.log(f"  MAE: {mae:.3f}")
    logger.log(f"  åˆ›æ–°åºåˆ—å‡å€¼: {innovation_mean:.3f} (ç†è®ºå€¼: 0)")
    logger.log(f"  åˆ›æ–°åºåˆ—æ ‡å‡†å·®: {innovation_std:.3f} (ç†è®ºå€¼: {theoretical_std:.3f})")

    # æ­¥éª¤6: å¯è§†åŒ–ç»“æœ
    logger.log("æ­¥éª¤6: ç”Ÿæˆå¯è§†åŒ–ç»“æœ")

    fig, axes = plt.subplots(2, 2, figsize=(12, 10))

    time_axis = np.arange(len(true_positions)) * dt

    # ä½ç½®è·Ÿè¸ª
    axes[0, 0].plot(time_axis, true_positions, 'g-', label='çœŸå®ä½ç½®', linewidth=2)
    axes[0, 0].plot(time_axis, observations, 'r.', label='è§‚æµ‹', alpha=0.6)
    axes[0, 0].plot(time_axis, estimates, 'b-', label='å¡å°”æ›¼ä¼°è®¡', linewidth=2)
    axes[0, 0].set_xlabel('æ—¶é—´ (s)')
    axes[0, 0].set_ylabel('ä½ç½®')
    axes[0, 0].set_title('ä½ç½®è·Ÿè¸ª')
    axes[0, 0].legend()
    axes[0, 0].grid(True)

    # ä¼°è®¡è¯¯å·®
    axes[0, 1].plot(time_axis, position_errors, 'r-', linewidth=2)
    axes[0, 1].axhline(0, color='k', linestyle='--', alpha=0.5)
    axes[0, 1].set_xlabel('æ—¶é—´ (s)')
    axes[0, 1].set_ylabel('ä½ç½®è¯¯å·®')
    axes[0, 1].set_title(f'ä½ç½®ä¼°è®¡è¯¯å·® (RMSE={rmse:.3f})')
    axes[0, 1].grid(True)

    # åˆ›æ–°åºåˆ—
    axes[1, 0].plot(time_axis, innovations, 'b-', alpha=0.7)
    axes[1, 0].axhline(0, color='k', linestyle='--', alpha=0.5)
    axes[1, 0].set_xlabel('æ—¶é—´ (s)')
    axes[1, 0].set_ylabel('åˆ›æ–°')
    axes[1, 0].set_title('åˆ›æ–°åºåˆ—')
    axes[1, 0].grid(True)

    # ä¸ç¡®å®šæ€§æ¼”åŒ–
    uncertainties = [np.sqrt(P[0, 0]) for P in kf.history['P']]
    axes[1, 1].plot(time_axis, uncertainties, 'purple', linewidth=2)
    axes[1, 1].set_xlabel('æ—¶é—´ (s)')
    axes[1, 1].set_ylabel('ä½ç½®ä¸ç¡®å®šæ€§ (Ïƒ)')
    axes[1, 1].set_title('ä¼°è®¡ä¸ç¡®å®šæ€§')
    axes[1, 1].grid(True)

    plt.tight_layout()
    plt.savefig('experiment_2_kalman_filter_results.png', dpi=300, bbox_inches='tight')
    plt.show()

    duration = logger.finish()

    return {
        'rmse': rmse,
        'mae': mae,
        'innovation_consistency': abs(innovation_std - theoretical_std) < 0.1,
        'duration': duration
    }

def run_experiment_1():
    """è¿è¡Œå®éªŒä¸€ï¼šåŸºç¡€ç®—æ³•éªŒè¯"""

    print("=" * 60)
    print("å®éªŒä¸€ï¼šåŸºç¡€ç®—æ³•éªŒè¯")
    print("=" * 60)

    # è¿è¡ŒQ-Learningå®éªŒ
    q_learning_results = experiment_1_q_learning()

    print("\n" + "-" * 40)

    # è¿è¡Œå¡å°”æ›¼æ»¤æ³¢å®éªŒ
    kalman_results = experiment_2_kalman_filter()

    # å®éªŒæ€»ç»“
    print("\n" + "=" * 60)
    print("å®éªŒä¸€æ€»ç»“")
    print("=" * 60)

    print(f"Q-Learningå®éªŒ:")
    print(f"  æˆåŠŸç‡: {q_learning_results['success_rate']:.2%}")
    print(f"  å¹³å‡å¥–åŠ±: {q_learning_results['avg_reward']:.2f}")
    print(f"  è®­ç»ƒæ—¶é—´: {q_learning_results['duration']:.2f}ç§’")

    print(f"\nå¡å°”æ›¼æ»¤æ³¢å®éªŒ:")
    print(f"  RMSE: {kalman_results['rmse']:.3f}")
    print(f"  MAE: {kalman_results['mae']:.3f}")
    print(f"  åˆ›æ–°ä¸€è‡´æ€§: {'é€šè¿‡' if kalman_results['innovation_consistency'] else 'æœªé€šè¿‡'}")
    print(f"  æ»¤æ³¢æ—¶é—´: {kalman_results['duration']:.2f}ç§’")

    # åˆ¤æ–­å®éªŒæ˜¯å¦æˆåŠŸ
    q_learning_success = q_learning_results['success_rate'] > 0.8
    kalman_success = kalman_results['rmse'] < 1.0 and kalman_results['innovation_consistency']

    if q_learning_success and kalman_success:
        print("\nğŸ‰ å®éªŒä¸€éªŒè¯æˆåŠŸï¼åŸºç¡€ç®—æ³•å®ç°æ­£ç¡®")
        return True
    else:
        print("\nâŒ å®éªŒä¸€éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç®—æ³•å®ç°")
        return False

if __name__ == "__main__":
    success = run_experiment_1()
    print(f"\nå®éªŒä¸€ç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
```

### 1.3 å®éªŒäºŒï¼šæ·±åº¦å¼ºåŒ–å­¦ä¹ å¯¼èˆª

#### å®éªŒç›®æ ‡
å®ç°å¹¶è®­ç»ƒDQNæ™ºèƒ½ä½“è¿›è¡Œç½‘æ ¼ä¸–ç•Œå¯¼èˆª

#### å®éªŒæ­¥éª¤

```python
# experiment_2_dqn_navigation.py
"""
å®éªŒäºŒï¼šæ·±åº¦å¼ºåŒ–å­¦ä¹ å¯¼èˆª
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from collections import deque
import random
import time

class ExperimentTracker:
    """å®éªŒè¿½è¸ªå™¨"""

    def __init__(self, experiment_name):
        self.experiment_name = experiment_name
        self.metrics = {}
        self.checkpoints = {}
        self.start_time = time.time()

        print(f"å¼€å§‹å®éªŒ: {experiment_name}")

    def log_metric(self, name, value, step):
        """è®°å½•æŒ‡æ ‡"""
        if name not in self.metrics:
            self.metrics[name] = {'values': [], 'steps': []}

        self.metrics[name]['values'].append(value)
        self.metrics[name]['steps'].append(step)

    def save_checkpoint(self, name, data):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        self.checkpoints[name] = {
            'data': data,
            'timestamp': time.time() - self.start_time
        }

    def plot_metrics(self):
        """ç»˜åˆ¶æŒ‡æ ‡"""
        if not self.metrics:
            return

        num_metrics = len(self.metrics)
        fig, axes = plt.subplots(1, num_metrics, figsize=(5*num_metrics, 4))

        if num_metrics == 1:
            axes = [axes]

        for i, (metric_name, data) in enumerate(self.metrics.items()):
            axes[i].plot(data['steps'], data['values'])
            axes[i].set_title(metric_name)
            axes[i].set_xlabel('Step')
            axes[i].set_ylabel('Value')
            axes[i].grid(True)

        plt.tight_layout()
        plt.show()

def experiment_2_dqn_navigation():
    """å®éªŒ2ï¼šDQNå¯¼èˆªè®­ç»ƒ"""

    tracker = ExperimentTracker("DQNå¯¼èˆªè®­ç»ƒ")

    print("æ­¥éª¤1: åˆ›å»ºå¯¼èˆªç¯å¢ƒ")

    class NavigationEnvironment:
        def __init__(self, size=10, num_obstacles=10):
            self.size = size
            self.num_obstacles = num_obstacles
            self.reset()

        def reset(self):
            # ç”Ÿæˆåœ°å›¾
            self.grid = np.zeros((self.size, self.size))

            # éšæœºæ”¾ç½®éšœç¢ç‰©
            obstacle_positions = set()
            while len(obstacle_positions) < self.num_obstacles:
                pos = (np.random.randint(1, self.size-1), np.random.randint(1, self.size-1))
                obstacle_positions.add(pos)

            for pos in obstacle_positions:
                self.grid[pos] = 1

            # è®¾ç½®èµ·ç‚¹å’Œç»ˆç‚¹
            self.start_pos = (0, 0)
            self.goal_pos = (self.size-1, self.size-1)
            self.grid[self.start_pos] = 0
            self.grid[self.goal_pos] = 0

            self.agent_pos = self.start_pos
            self.steps = 0
            self.max_steps = self.size * self.size

            return self.get_state()

        def get_state(self):
            """è·å–çŠ¶æ€è¡¨ç¤º"""
            # ç®€åŒ–çŠ¶æ€ï¼šæ™ºèƒ½ä½“ä½ç½® + ç›®æ ‡ä½ç½® + å‘¨å›´ç¯å¢ƒ
            state = []

            # æ™ºèƒ½ä½“ä½ç½®ï¼ˆå½’ä¸€åŒ–ï¼‰
            state.extend([self.agent_pos[0] / self.size, self.agent_pos[1] / self.size])

            # ç›®æ ‡ä½ç½®ï¼ˆå½’ä¸€åŒ–ï¼‰
            state.extend([self.goal_pos[0] / self.size, self.goal_pos[1] / self.size])

            # åˆ°ç›®æ ‡çš„è·ç¦»å’Œè§’åº¦
            dx = self.goal_pos[0] - self.agent_pos[0]
            dy = self.goal_pos[1] - self.agent_pos[1]
            distance = np.sqrt(dx**2 + dy**2) / (self.size * np.sqrt(2))
            angle = np.arctan2(dy, dx) / np.pi
            state.extend([distance, np.sin(angle), np.cos(angle)])

            # å‘¨å›´8ä¸ªæ–¹å‘çš„éšœç¢ç‰©ä¿¡æ¯
            directions = [(-1,-1), (-1,0), (-1,1), (0,-1), (0,1), (1,-1), (1,0), (1,1)]
            for dx, dy in directions:
                new_x, new_y = self.agent_pos[0] + dx, self.agent_pos[1] + dy
                if 0 <= new_x < self.size and 0 <= new_y < self.size:
                    obstacle = self.grid[new_x, new_y]
                else:
                    obstacle = 1  # è¾¹ç•Œè§†ä¸ºéšœç¢ç‰©
                state.append(obstacle)

            return np.array(state, dtype=np.float32)

        def step(self, action):
            """æ‰§è¡ŒåŠ¨ä½œ"""
            # åŠ¨ä½œæ˜ å°„ï¼š0-ä¸Šï¼Œ1-ä¸‹ï¼Œ2-å·¦ï¼Œ3-å³
            moves = [(-1, 0), (1, 0), (0, -1), (0, 1)]
            dx, dy = moves[action]

            new_x = self.agent_pos[0] + dx
            new_y = self.agent_pos[1] + dy

            # æ£€æŸ¥è¾¹ç•Œå’Œéšœç¢ç‰©
            if (0 <= new_x < self.size and 0 <= new_y < self.size and
                self.grid[new_x, new_y] == 0):
                self.agent_pos = (new_x, new_y)
                collision = False
            else:
                collision = True

            self.steps += 1

            # è®¡ç®—å¥–åŠ±
            if self.agent_pos == self.goal_pos:
                reward = 100
                done = True
            elif collision:
                reward = -10
                done = False
            elif self.steps >= self.max_steps:
                reward = -50
                done = True
            else:
                # è·ç¦»å¥–åŠ±
                distance = np.sqrt((self.goal_pos[0] - self.agent_pos[0])**2 +
                                 (self.goal_pos[1] - self.agent_pos[1])**2)
                reward = -0.1 - distance * 0.01
                done = False

            return self.get_state(), reward, done

        def render(self):
            """å¯è§†åŒ–ç¯å¢ƒ"""
            grid_display = self.grid.copy()
            grid_display[self.agent_pos] = 0.5  # æ™ºèƒ½ä½“
            grid_display[self.goal_pos] = 0.7   # ç›®æ ‡

            plt.imshow(grid_display, cmap='RdYlBu')
            plt.title(f"æ­¥æ•°: {self.steps}")
            plt.colorbar()
            plt.show()

    env = NavigationEnvironment(size=8, num_obstacles=8)
    state_size = len(env.get_state())
    action_size = 4

    print(f"ç¯å¢ƒåˆ›å»ºå®Œæˆ: {env.size}x{env.size}, çŠ¶æ€ç»´åº¦: {state_size}")

    print("æ­¥éª¤2: æ„å»ºDQNç½‘ç»œ")

    class DQNNetwork(nn.Module):
        def __init__(self, state_size, action_size, hidden_size=64):
            super(DQNNetwork, self).__init__()
            self.network = nn.Sequential(
                nn.Linear(state_size, hidden_size),
                nn.ReLU(),
                nn.Linear(hidden_size, hidden_size),
                nn.ReLU(),
                nn.Linear(hidden_size, action_size)
            )

        def forward(self, x):
            return self.network(x)

    class DQNAgent:
        def __init__(self, state_size, action_size, lr=1e-3):
            self.state_size = state_size
            self.action_size = action_size
            self.epsilon = 1.0
            self.epsilon_min = 0.01
            self.epsilon_decay = 0.995

            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            self.q_network = DQNNetwork(state_size, action_size).to(self.device)
            self.target_network = DQNNetwork(state_size, action_size).to(self.device)
            self.optimizer = optim.Adam(self.q_network.parameters(), lr=lr)

            self.memory = deque(maxlen=10000)
            self.batch_size = 32
            self.update_frequency = 4
            self.target_update_frequency = 100
            self.learn_step = 0

        def remember(self, state, action, reward, next_state, done):
            self.memory.append((state, action, reward, next_state, done))

        def act(self, state):
            if np.random.random() <= self.epsilon:
                return random.choice(range(self.action_size))

            state = torch.FloatTensor(state).unsqueeze(0).to(self.device)
            q_values = self.q_network(state)
            return q_values.argmax().item()

        def learn(self):
            if len(self.memory) < self.batch_size:
                return 0

            batch = random.sample(self.memory, self.batch_size)
            states, actions, rewards, next_states, dones = zip(*batch)

            states = torch.FloatTensor(states).to(self.device)
            actions = torch.LongTensor(actions).to(self.device)
            rewards = torch.FloatTensor(rewards).to(self.device)
            next_states = torch.FloatTensor(next_states).to(self.device)
            dones = torch.BoolTensor(dones).to(self.device)

            current_q_values = self.q_network(states).gather(1, actions.unsqueeze(1))
            next_q_values = self.target_network(next_states).max(1)[0].detach()
            target_q_values = rewards + (0.99 * next_q_values * ~dones)

            loss = nn.MSELoss()(current_q_values.squeeze(), target_q_values)

            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            if self.learn_step % self.target_update_frequency == 0:
                self.target_network.load_state_dict(self.q_network.state_dict())

            if self.epsilon > self.epsilon_min:
                self.epsilon *= self.epsilon_decay

            self.learn_step += 1
            return loss.item()

    agent = DQNAgent(state_size, action_size)
    print(f"DQNæ™ºèƒ½ä½“åˆ›å»ºå®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {agent.device}")

    print("æ­¥éª¤3: å¼€å§‹è®­ç»ƒ")

    num_episodes = 1000
    scores = deque(maxlen=100)
    losses = []

    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0
        episode_loss = []

        for step in range(env.max_steps):
            action = agent.act(state)
            next_state, reward, done = env.step(action)

            agent.remember(state, action, reward, next_state, done)

            if step % agent.update_frequency == 0:
                loss = agent.learn()
                if loss > 0:
                    episode_loss.append(loss)

            state = next_state
            total_reward += reward

            if done:
                break

        scores.append(total_reward)
        if episode_loss:
            losses.append(np.mean(episode_loss))

        # è®°å½•æŒ‡æ ‡
        tracker.log_metric('episode_reward', total_reward, episode)
        tracker.log_metric('epsilon', agent.epsilon, episode)
        if episode_loss:
            tracker.log_metric('loss', np.mean(episode_loss), episode)

        if episode % 100 == 0:
            avg_score = np.mean(scores)
            print(f"Episode {episode}: å¹³å‡åˆ†æ•°={avg_score:.2f}, Îµ={agent.epsilon:.3f}")

            # ä¿å­˜æ£€æŸ¥ç‚¹
            tracker.save_checkpoint(f'episode_{episode}', {
                'model_state': agent.q_network.state_dict(),
                'avg_score': avg_score,
                'epsilon': agent.epsilon
            })

    print("æ­¥éª¤4: æµ‹è¯•è®­ç»ƒç»“æœ")

    # æµ‹è¯•æ™ºèƒ½ä½“
    agent.epsilon = 0  # å…³é—­æ¢ç´¢
    test_scores = []
    success_count = 0

    for test_episode in range(100):
        state = env.reset()
        total_reward = 0

        for step in range(env.max_steps):
            action = agent.act(state)
            state, reward, done = env.step(action)
            total_reward += reward

            if done:
                if env.agent_pos == env.goal_pos:
                    success_count += 1
                break

        test_scores.append(total_reward)

    success_rate = success_count / 100
    avg_test_score = np.mean(test_scores)

    print(f"æµ‹è¯•ç»“æœ:")
    print(f"  æˆåŠŸç‡: {success_rate:.2%}")
    print(f"  å¹³å‡åˆ†æ•°: {avg_test_score:.2f}")

    print("æ­¥éª¤5: å¯è§†åŒ–å­¦ä¹ è¿‡ç¨‹")

    # ç»˜åˆ¶å­¦ä¹ æ›²çº¿
    tracker.plot_metrics()

    # å±•ç¤ºä¸€ä¸ªæˆåŠŸçš„å¯¼èˆªç¤ºä¾‹
    if success_rate > 0:
        print("å±•ç¤ºå¯¼èˆªç¤ºä¾‹...")
        state = env.reset()
        trajectory = [env.agent_pos]

        for step in range(env.max_steps):
            action = agent.act(state)
            state, reward, done = env.step(action)
            trajectory.append(env.agent_pos)

            if done:
                break

        # å¯è§†åŒ–è½¨è¿¹
        grid_display = env.grid.copy()
        for i, pos in enumerate(trajectory):
            grid_display[pos] = 0.5 + 0.3 * (i / len(trajectory))

        grid_display[env.start_pos] = 0.8
        grid_display[env.goal_pos] = 1.0

        plt.figure(figsize=(8, 8))
        plt.imshow(grid_display, cmap='viridis')
        plt.title('DQNå¯¼èˆªè½¨è¿¹ç¤ºä¾‹')
        plt.colorbar(label='è½¨è¿¹è¿›åº¦')

        # æ·»åŠ è½¨è¿¹çº¿
        traj_x = [pos[1] for pos in trajectory]
        traj_y = [pos[0] for pos in trajectory]
        plt.plot(traj_x, traj_y, 'r-', linewidth=2, alpha=0.7)

        plt.savefig('experiment_2_dqn_trajectory.png', dpi=300, bbox_inches='tight')
        plt.show()

    return {
        'success_rate': success_rate,
        'avg_test_score': avg_test_score,
        'training_episodes': num_episodes,
        'final_epsilon': agent.epsilon
    }

def run_experiment_2():
    """è¿è¡Œå®éªŒäºŒ"""

    print("=" * 60)
    print("å®éªŒäºŒï¼šæ·±åº¦å¼ºåŒ–å­¦ä¹ å¯¼èˆª")
    print("=" * 60)

    results = experiment_2_dqn_navigation()

    print("\n" + "=" * 60)
    print("å®éªŒäºŒæ€»ç»“")
    print("=" * 60)

    print(f"DQNå¯¼èˆªè®­ç»ƒç»“æœ:")
    print(f"  æœ€ç»ˆæˆåŠŸç‡: {results['success_rate']:.2%}")
    print(f"  å¹³å‡æµ‹è¯•åˆ†æ•°: {results['avg_test_score']:.2f}")
    print(f"  è®­ç»ƒå›åˆæ•°: {results['training_episodes']}")
    print(f"  æœ€ç»ˆæ¢ç´¢ç‡: {results['final_epsilon']:.3f}")

    # åˆ¤æ–­å®éªŒæˆåŠŸ
    success = results['success_rate'] > 0.7  # æˆåŠŸç‡è¶…è¿‡70%

    if success:
        print("\nğŸ‰ å®éªŒäºŒæˆåŠŸï¼DQNæ™ºèƒ½ä½“å­¦ä¼šäº†å¯¼èˆª")
    else:
        print("\nâŒå®éªŒäºŒéœ€è¦æ”¹è¿›ï¼Œå»ºè®®:")
        print("  - è°ƒæ•´ç½‘ç»œç»“æ„")
        print("  - å¢åŠ è®­ç»ƒå›åˆ")
        print("  - è°ƒæ•´å¥–åŠ±å‡½æ•°")
        print("  - ä¼˜åŒ–è¶…å‚æ•°")

    return success

if __name__ == "__main__":
    success = run_experiment_2()
    print(f"\nå®éªŒäºŒç»“æœ: {'æˆåŠŸ' if success else 'éœ€è¦æ”¹è¿›'}")
```

## 2. äº¤äº’å¼å¯è§†åŒ–ç³»ç»Ÿ

### 2.1 å®æ—¶çŠ¶æ€ç›‘æ§ç•Œé¢

```python
# interactive_visualization.py
"""
äº¤äº’å¼å¯è§†åŒ–ç³»ç»Ÿ
"""

import dash
from dash import dcc, html, Input, Output, State
import plotly.graph_objs as go
import plotly.express as px
import numpy as np
import pandas as pd
import threading
import time
from collections import deque
import json

class RealTimeDataGenerator:
    """å®æ—¶æ•°æ®ç”Ÿæˆå™¨ï¼ˆæ¨¡æ‹Ÿä¼ æ„Ÿå™¨æ•°æ®ï¼‰"""

    def __init__(self):
        self.running = False
        self.data_buffers = {
            'ekf_state': deque(maxlen=1000),
            'sensor_data': deque(maxlen=1000),
            'dqn_metrics': deque(maxlen=1000),
            'system_performance': deque(maxlen=1000)
        }
        self.timestamps = deque(maxlen=1000)
        self.start_time = time.time()

    def start(self):
        """å¼€å§‹æ•°æ®ç”Ÿæˆ"""
        self.running = True
        self.data_thread = threading.Thread(target=self._generate_data)
        self.data_thread.daemon = True
        self.data_thread.start()

    def stop(self):
        """åœæ­¢æ•°æ®ç”Ÿæˆ"""
        self.running = False

    def _generate_data(self):
        """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®"""
        t = 0
        while self.running:
            current_time = time.time() - self.start_time

            # æ¨¡æ‹Ÿæœºå™¨äººè¿åŠ¨è½¨è¿¹ï¼ˆåœ†å½¢è·¯å¾„ï¼‰
            radius = 5
            angular_freq = 0.1

            x = radius * np.cos(angular_freq * current_time)
            y = radius * np.sin(angular_freq * current_time)
            theta = angular_freq * current_time + np.pi/2
            v = radius * angular_freq
            omega = angular_freq

            # EKFçŠ¶æ€æ•°æ®
            ekf_state = {
                'x': x + np.random.normal(0, 0.1),
                'y': y + np.random.normal(0, 0.1),
                'theta': theta + np.random.normal(0, 0.05),
                'v': v + np.random.normal(0, 0.1),
                'omega': omega + np.random.normal(0, 0.05),
                'uncertainty_x': 0.1 + 0.05 * np.sin(0.2 * current_time),
                'uncertainty_y': 0.1 + 0.05 * np.cos(0.2 * current_time)
            }

            # ä¼ æ„Ÿå™¨æ•°æ®
            sensor_data = {
                'imu_gyro': omega + np.random.normal(0, 0.01),
                'imu_acc': np.random.normal(0, 0.1),
                'odom_x': x + np.random.normal(0, 0.1),
                'odom_y': y + np.random.normal(0, 0.1),
                'gps_x': x + np.random.normal(0, 1.0),
                'gps_y': y + np.random.normal(0, 1.0)
            }

            # DQNæŒ‡æ ‡
            dqn_metrics = {
                'q_value': 10 + 5 * np.sin(0.1 * current_time) + np.random.normal(0, 1),
                'epsilon': max(0.01, 1.0 - current_time * 0.01),
                'loss': max(0, 2 * np.exp(-current_time * 0.1) + np.random.normal(0, 0.1)),
                'reward': 50 + 30 * np.sin(0.05 * current_time) + np.random.normal(0, 5)
            }

            # ç³»ç»Ÿæ€§èƒ½
            system_performance = {
                'cpu_usage': 20 + 10 * np.sin(0.3 * current_time) + np.random.normal(0, 2),
                'memory_usage': 60 + 15 * np.cos(0.2 * current_time) + np.random.normal(0, 3),
                'computation_time': 50 + 20 * np.sin(0.15 * current_time) + np.random.normal(0, 5),
                'success_rate': min(1.0, max(0.0, 0.5 + 0.3 * np.tanh(current_time * 0.1) + np.random.normal(0, 0.05)))
            }

            # å­˜å‚¨æ•°æ®
            self.timestamps.append(current_time)
            self.data_buffers['ekf_state'].append(ekf_state)
            self.data_buffers['sensor_data'].append(sensor_data)
            self.data_buffers['dqn_metrics'].append(dqn_metrics)
            self.data_buffers['system_performance'].append(system_performance)

            time.sleep(0.1)  # 10Hzæ›´æ–°é¢‘ç‡

    def get_latest_data(self):
        """è·å–æœ€æ–°æ•°æ®"""
        if not self.timestamps:
            return None

        return {
            'timestamps': list(self.timestamps),
            'ekf_state': list(self.data_buffers['ekf_state']),
            'sensor_data': list(self.data_buffers['sensor_data']),
            'dqn_metrics': list(self.data_buffers['dqn_metrics']),
            'system_performance': list(self.data_buffers['system_performance'])
        }

class VisualizationDashboard:
    """å¯è§†åŒ–ä»ªè¡¨æ¿"""

    def __init__(self):
        self.app = dash.Dash(__name__)
        self.data_generator = RealTimeDataGenerator()
        self.setup_layout()
        self.setup_callbacks()

    def setup_layout(self):
        """è®¾ç½®å¸ƒå±€"""
        self.app.layout = html.Div([
            html.H1("å¼ºåŒ–å­¦ä¹ ä¸ä¼ æ„Ÿå™¨èåˆå®æ—¶ç›‘æ§",
                   style={'textAlign': 'center', 'marginBottom': 30}),

            # æ§åˆ¶é¢æ¿
            html.Div([
                html.Button("å¼€å§‹ç›‘æ§", id="start-btn", n_clicks=0,
                          style={'marginRight': 10}),
                html.Button("åœæ­¢ç›‘æ§", id="stop-btn", n_clicks=0),
                html.Div(id="status-display", style={'marginLeft': 20, 'display': 'inline-block'})
            ], style={'textAlign': 'center', 'marginBottom': 20}),

            # ä¸»è¦å›¾è¡¨åŒºåŸŸ
            html.Div([
                # å·¦åˆ—
                html.Div([
                    dcc.Graph(id="trajectory-plot"),
                    dcc.Graph(id="sensor-data-plot")
                ], style={'width': '50%', 'display': 'inline-block', 'verticalAlign': 'top'}),

                # å³åˆ—
                html.Div([
                    dcc.Graph(id="dqn-metrics-plot"),
                    dcc.Graph(id="performance-plot")
                ], style={'width': '50%', 'display': 'inline-block', 'verticalAlign': 'top'})
            ]),

            # è¯¦ç»†ä¿¡æ¯é¢æ¿
            html.Div([
                html.H3("ç³»ç»ŸçŠ¶æ€è¯¦æƒ…"),
                html.Div(id="detailed-info")
            ], style={'marginTop': 30}),

            # è‡ªåŠ¨åˆ·æ–°ç»„ä»¶
            dcc.Interval(
                id='interval-component',
                interval=1000,  # 1ç§’æ›´æ–°ä¸€æ¬¡
                n_intervals=0
            )
        ])

    def setup_callbacks(self):
        """è®¾ç½®å›è°ƒå‡½æ•°"""

        @self.app.callback(
            Output('status-display', 'children'),
            [Input('start-btn', 'n_clicks'),
             Input('stop-btn', 'n_clicks')]
        )
        def control_monitoring(start_clicks, stop_clicks):
            """æ§åˆ¶ç›‘æ§å¼€å§‹/åœæ­¢"""
            ctx = dash.callback_context
            if not ctx.triggered:
                return "çŠ¶æ€: æœªå¼€å§‹"

            button_id = ctx.triggered[0]['prop_id'].split('.')[0]

            if button_id == 'start-btn' and start_clicks > 0:
                self.data_generator.start()
                return "çŠ¶æ€: è¿è¡Œä¸­"
            elif button_id == 'stop-btn' and stop_clicks > 0:
                self.data_generator.stop()
                return "çŠ¶æ€: å·²åœæ­¢"

            return "çŠ¶æ€: æœªå¼€å§‹"

        @self.app.callback(
            [Output('trajectory-plot', 'figure'),
             Output('sensor-data-plot', 'figure'),
             Output('dqn-metrics-plot', 'figure'),
             Output('performance-plot', 'figure'),
             Output('detailed-info', 'children')],
            [Input('interval-component', 'n_intervals')]
        )
        def update_all_plots(n):
            """æ›´æ–°æ‰€æœ‰å›¾è¡¨"""
            data = self.data_generator.get_latest_data()

            if data is None or not data['timestamps']:
                # è¿”å›ç©ºå›¾è¡¨
                empty_fig = go.Figure()
                return empty_fig, empty_fig, empty_fig, empty_fig, "ç­‰å¾…æ•°æ®..."

            timestamps = data['timestamps']
            ekf_data = data['ekf_state']
            sensor_data = data['sensor_data']
            dqn_data = data['dqn_metrics']
            perf_data = data['system_performance']

            # 1. è½¨è¿¹å›¾
            trajectory_fig = self.create_trajectory_plot(ekf_data)

            # 2. ä¼ æ„Ÿå™¨æ•°æ®å›¾
            sensor_fig = self.create_sensor_plot(timestamps, sensor_data)

            # 3. DQNæŒ‡æ ‡å›¾
            dqn_fig = self.create_dqn_plot(timestamps, dqn_data)

            # 4. æ€§èƒ½å›¾
            performance_fig = self.create_performance_plot(timestamps, perf_data)

            # 5. è¯¦ç»†ä¿¡æ¯
            detailed_info = self.create_detailed_info(ekf_data, dqn_data, perf_data)

            return trajectory_fig, sensor_fig, dqn_fig, performance_fig, detailed_info

    def create_trajectory_plot(self, ekf_data):
        """åˆ›å»ºè½¨è¿¹å›¾"""
        if not ekf_data:
            return go.Figure()

        x_vals = [d['x'] for d in ekf_data]
        y_vals = [d['y'] for d in ekf_data]
        uncertainties_x = [d['uncertainty_x'] for d in ekf_data]
        uncertainties_y = [d['uncertainty_y'] for d in ekf_data]

        fig = go.Figure()

        # è½¨è¿¹çº¿
        fig.add_trace(go.Scatter(
            x=x_vals, y=y_vals,
            mode='lines+markers',
            name='æœºå™¨äººè½¨è¿¹',
            line=dict(color='blue', width=2),
            marker=dict(size=4)
        ))

        # ä¸ç¡®å®šæ€§æ¤­åœ†ï¼ˆåªæ˜¾ç¤ºæœ€è¿‘å‡ ä¸ªç‚¹ï¼‰
        for i in range(max(0, len(x_vals)-10), len(x_vals), 2):
            fig.add_shape(
                type="circle",
                xref="x", yref="y",
                x0=x_vals[i] - uncertainties_x[i],
                y0=y_vals[i] - uncertainties_y[i],
                x1=x_vals[i] + uncertainties_x[i],
                y1=y_vals[i] + uncertainties_y[i],
                line=dict(color="red", width=1),
                fillcolor="rgba(255,0,0,0.1)"
            )

        fig.update_layout(
            title="æœºå™¨äººè½¨è¿¹ä¸ä¸ç¡®å®šæ€§",
            xaxis_title="X ä½ç½® (m)",
            yaxis_title="Y ä½ç½® (m)",
            showlegend=True,
            height=400
        )
        fig.update_xaxis(scaleanchor="y", scaleratio=1)

        return fig

    def create_sensor_plot(self, timestamps, sensor_data):
        """åˆ›å»ºä¼ æ„Ÿå™¨æ•°æ®å›¾"""
        if not sensor_data:
            return go.Figure()

        fig = go.Figure()

        # IMUé™€èºä»ª
        imu_gyro = [d['imu_gyro'] for d in sensor_data]
        fig.add_trace(go.Scatter(
            x=timestamps, y=imu_gyro,
            mode='lines',
            name='IMU é™€èºä»ª',
            line=dict(color='red')
        ))

        # é‡Œç¨‹è®¡æ•°æ®
        odom_x = [d['odom_x'] for d in sensor_data]
        fig.add_trace(go.Scatter(
            x=timestamps, y=odom_x,
            mode='lines',
            name='é‡Œç¨‹è®¡ X',
            line=dict(color='blue'),
            yaxis='y2'
        ))

        fig.update_layout(
            title="ä¼ æ„Ÿå™¨æ•°æ®å®æ—¶ç›‘æ§",
            xaxis_title="æ—¶é—´ (s)",
            yaxis=dict(title="è§’é€Ÿåº¦ (rad/s)", side="left"),
            yaxis2=dict(title="ä½ç½® (m)", side="right", overlaying="y"),
            showlegend=True,
            height=400
        )

        return fig

    def create_dqn_plot(self, timestamps, dqn_data):
        """åˆ›å»ºDQNæŒ‡æ ‡å›¾"""
        if not dqn_data:
            return go.Figure()

        fig = go.Figure()

        # Qå€¼
        q_values = [d['q_value'] for d in dqn_data]
        fig.add_trace(go.Scatter(
            x=timestamps, y=q_values,
            mode='lines',
            name='Qå€¼',
            line=dict(color='green')
        ))

        # æ¢ç´¢ç‡
        epsilon_values = [d['epsilon'] for d in dqn_data]
        fig.add_trace(go.Scatter(
            x=timestamps, y=epsilon_values,
            mode='lines',
            name='æ¢ç´¢ç‡ (Îµ)',
            line=dict(color='orange'),
            yaxis='y2'
        ))

        # æŸå¤±
        loss_values = [d['loss'] for d in dqn_data]
        fig.add_trace(go.Scatter(
            x=timestamps, y=loss_values,
            mode='lines',
            name='è®­ç»ƒæŸå¤±',
            line=dict(color='purple'),
            yaxis='y3'
        ))

        fig.update_layout(
            title="DQNè®­ç»ƒæŒ‡æ ‡",
            xaxis_title="æ—¶é—´ (s)",
            yaxis=dict(title="Qå€¼", side="left"),
            yaxis2=dict(title="æ¢ç´¢ç‡", side="right", overlaying="y", position=0.85),
            yaxis3=dict(title="æŸå¤±", side="right", overlaying="y", position=1.0),
            showlegend=True,
            height=400
        )

        return fig

    def create_performance_plot(self, timestamps, perf_data):
        """åˆ›å»ºæ€§èƒ½ç›‘æ§å›¾"""
        if not perf_data:
            return go.Figure()

        fig = go.Figure()

        # CPUä½¿ç”¨ç‡
        cpu_usage = [d['cpu_usage'] for d in perf_data]
        fig.add_trace(go.Scatter(
            x=timestamps, y=cpu_usage,
            mode='lines',
            name='CPUä½¿ç”¨ç‡ (%)',
            line=dict(color='red')
        ))

        # å†…å­˜ä½¿ç”¨ç‡
        memory_usage = [d['memory_usage'] for d in perf_data]
        fig.add_trace(go.Scatter(
            x=timestamps, y=memory_usage,
            mode='lines',
            name='å†…å­˜ä½¿ç”¨ç‡ (%)',
            line=dict(color='blue')
        ))

        # è®¡ç®—æ—¶é—´
        comp_time = [d['computation_time'] for d in perf_data]
        fig.add_trace(go.Scatter(
            x=timestamps, y=comp_time,
            mode='lines',
            name='è®¡ç®—æ—¶é—´ (ms)',
            line=dict(color='green'),
            yaxis='y2'
        ))

        fig.update_layout(
            title="ç³»ç»Ÿæ€§èƒ½ç›‘æ§",
            xaxis_title="æ—¶é—´ (s)",
            yaxis=dict(title="ä½¿ç”¨ç‡ (%)", side="left"),
            yaxis2=dict(title="è®¡ç®—æ—¶é—´ (ms)", side="right", overlaying="y"),
            showlegend=True,
            height=400
        )

        return fig

    def create_detailed_info(self, ekf_data, dqn_data, perf_data):
        """åˆ›å»ºè¯¦ç»†ä¿¡æ¯é¢æ¿"""
        if not ekf_data or not dqn_data or not perf_data:
            return "ç­‰å¾…æ•°æ®..."

        latest_ekf = ekf_data[-1]
        latest_dqn = dqn_data[-1]
        latest_perf = perf_data[-1]

        info_cards = html.Div([
            # EKFçŠ¶æ€å¡ç‰‡
            html.Div([
                html.H4("EKFçŠ¶æ€ä¼°è®¡"),
                html.P(f"ä½ç½®: ({latest_ekf['x']:.2f}, {latest_ekf['y']:.2f})"),
                html.P(f"æœå‘: {latest_ekf['theta']:.2f} rad"),
                html.P(f"é€Ÿåº¦: {latest_ekf['v']:.2f} m/s"),
                html.P(f"ä¸ç¡®å®šæ€§: Â±{latest_ekf['uncertainty_x']:.3f} m")
            ], className="info-card", style={
                'width': '30%', 'display': 'inline-block', 'margin': '10px',
                'padding': '15px', 'border': '1px solid #ddd', 'borderRadius': '5px'
            }),

            # DQNçŠ¶æ€å¡ç‰‡
            html.Div([
                html.H4("DQNå­¦ä¹ çŠ¶æ€"),
                html.P(f"å½“å‰Qå€¼: {latest_dqn['q_value']:.2f}"),
                html.P(f"æ¢ç´¢ç‡: {latest_dqn['epsilon']:.3f}"),
                html.P(f"è®­ç»ƒæŸå¤±: {latest_dqn['loss']:.3f}"),
                html.P(f"å¥–åŠ±: {latest_dqn['reward']:.1f}")
            ], className="info-card", style={
                'width': '30%', 'display': 'inline-block', 'margin': '10px',
                'padding': '15px', 'border': '1px solid #ddd', 'borderRadius': '5px'
            }),

            # ç³»ç»Ÿæ€§èƒ½å¡ç‰‡
            html.Div([
                html.H4("ç³»ç»Ÿæ€§èƒ½"),
                html.P(f"CPU: {latest_perf['cpu_usage']:.1f}%"),
                html.P(f"å†…å­˜: {latest_perf['memory_usage']:.1f}%"),
                html.P(f"è®¡ç®—æ—¶é—´: {latest_perf['computation_time']:.1f}ms"),
                html.P(f"æˆåŠŸç‡: {latest_perf['success_rate']:.1%}")
            ], className="info-card", style={
                'width': '30%', 'display': 'inline-block', 'margin': '10px',
                'padding': '15px', 'border': '1px solid #ddd', 'borderRadius': '5px'
            })
        ])

        return info_cards

    def run(self, debug=False, port=8050):
        """è¿è¡Œä»ªè¡¨æ¿"""
        print(f"å¯åŠ¨å¯è§†åŒ–ä»ªè¡¨æ¿: http://localhost:{port}")
        self.app.run_server(debug=debug, port=port)

def create_parameter_tuning_interface():
    """åˆ›å»ºå‚æ•°è°ƒä¼˜ç•Œé¢"""

    app = dash.Dash(__name__)

    app.layout = html.Div([
        html.H1("ç®—æ³•å‚æ•°è°ƒä¼˜ç•Œé¢", style={'textAlign': 'center'}),

        html.Div([
            # DQNå‚æ•°
            html.Div([
                html.H3("DQNå‚æ•°"),
                html.Label("å­¦ä¹ ç‡:"),
                dcc.Slider(id='lr-slider', min=0.0001, max=0.01, step=0.0001,
                          value=0.001, marks={i/1000: str(i/1000) for i in range(1, 11)}),

                html.Label("æ¢ç´¢ç‡è¡°å‡:"),
                dcc.Slider(id='epsilon-decay-slider', min=0.99, max=0.999, step=0.001,
                          value=0.995, marks={0.99+i*0.002: f"{0.99+i*0.002:.3f}" for i in range(5)}),

                html.Label("æ‰¹æ¬¡å¤§å°:"),
                dcc.Dropdown(id='batch-size-dropdown',
                           options=[{'label': str(i), 'value': i} for i in [16, 32, 64, 128]],
                           value=32),

                html.Label("ç›®æ ‡ç½‘ç»œæ›´æ–°é¢‘ç‡:"),
                dcc.Input(id='target-update-input', type='number', value=100, min=10, max=1000)
            ], style={'width': '45%', 'display': 'inline-block', 'padding': '20px'}),

            # EKFå‚æ•°
            html.Div([
                html.H3("EKFå‚æ•°"),
                html.Label("è¿‡ç¨‹å™ªå£°:"),
                dcc.Slider(id='process-noise-slider', min=0.001, max=0.1, step=0.001,
                          value=0.01, marks={i/100: str(i/100) for i in range(1, 11)}),

                html.Label("è§‚æµ‹å™ªå£°:"),
                dcc.Slider(id='obs-noise-slider', min=0.1, max=5.0, step=0.1,
                          value=1.0, marks={i: str(i) for i in range(1, 6)}),

                html.Label("åˆå§‹ä¸ç¡®å®šæ€§:"),
                dcc.Slider(id='init-uncertainty-slider', min=0.01, max=1.0, step=0.01,
                          value=0.1, marks={i/10: str(i/10) for i in range(1, 11)}),

                html.Label("è‡ªé€‚åº”å› å­:"),
                dcc.Input(id='adaptive-factor-input', type='number', value=1.5,
                         min=1.0, max=3.0, step=0.1)
            ], style={'width': '45%', 'display': 'inline-block', 'padding': '20px'})
        ]),

        html.Div([
            html.Button("åº”ç”¨å‚æ•°", id="apply-params-btn", n_clicks=0,
                       style={'marginRight': '10px'}),
            html.Button("é‡ç½®ä¸ºé»˜è®¤", id="reset-params-btn", n_clicks=0),
            html.Div(id="param-status")
        ], style={'textAlign': 'center', 'margin': '20px'}),

        html.Div([
            dcc.Graph(id="param-effect-plot")
        ])
    ])

    @app.callback(
        [Output('param-status', 'children'),
         Output('param-effect-plot', 'figure')],
        [Input('apply-params-btn', 'n_clicks'),
         Input('reset-params-btn', 'n_clicks')],
        [State('lr-slider', 'value'),
         State('epsilon-decay-slider', 'value'),
         State('batch-size-dropdown', 'value'),
         State('target-update-input', 'value'),
         State('process-noise-slider', 'value'),
         State('obs-noise-slider', 'value'),
         State('init-uncertainty-slider', 'value'),
         State('adaptive-factor-input', 'value')]
    )
    def update_parameters(apply_clicks, reset_clicks, lr, epsilon_decay, batch_size,
                         target_update, process_noise, obs_noise, init_uncertainty, adaptive_factor):
        ctx = dash.callback_context

        if not ctx.triggered:
            return "ç­‰å¾…å‚æ•°è°ƒæ•´...", go.Figure()

        button_id = ctx.triggered[0]['prop_id'].split('.')[0]

        if button_id == 'apply-params-btn':
            # è¿™é‡Œä¼šåº”ç”¨æ–°å‚æ•°åˆ°å®é™…ç®—æ³•
            status = f"å‚æ•°å·²åº”ç”¨: LR={lr}, Îµè¡°å‡={epsilon_decay}, æ‰¹æ¬¡={batch_size}"

            # æ¨¡æ‹Ÿå‚æ•°æ•ˆæœå›¾
            x = np.linspace(0, 100, 100)
            y1 = np.exp(-x * lr) * 100  # å­¦ä¹ æ›²çº¿
            y2 = epsilon_decay ** x     # æ¢ç´¢ç‡è¡°å‡

            fig = go.Figure()
            fig.add_trace(go.Scatter(x=x, y=y1, name='å­¦ä¹ è¿›åº¦', line=dict(color='blue')))
            fig.add_trace(go.Scatter(x=x, y=y2, name='æ¢ç´¢ç‡', line=dict(color='red'), yaxis='y2'))

            fig.update_layout(
                title="å‚æ•°æ•ˆæœé¢„æµ‹",
                xaxis_title="è®­ç»ƒæ­¥éª¤",
                yaxis=dict(title="å­¦ä¹ è¿›åº¦", side="left"),
                yaxis2=dict(title="æ¢ç´¢ç‡", side="right", overlaying="y")
            )

            return status, fig

        return "å‚æ•°å·²é‡ç½®ä¸ºé»˜è®¤å€¼", go.Figure()

    return app

def run_visualization_system():
    """è¿è¡Œå®Œæ•´çš„å¯è§†åŒ–ç³»ç»Ÿ"""

    print("=== å¯åŠ¨äº¤äº’å¼å¯è§†åŒ–ç³»ç»Ÿ ===")

    # åˆ›å»ºä¸»ç›‘æ§ä»ªè¡¨æ¿
    dashboard = VisualizationDashboard()

    # åœ¨åå°å¯åŠ¨å‚æ•°è°ƒä¼˜ç•Œé¢
    param_app = create_parameter_tuning_interface()

    print("å¯ç”¨ç•Œé¢:")
    print("1. å®æ—¶ç›‘æ§ä»ªè¡¨æ¿: http://localhost:8050")
    print("2. å‚æ•°è°ƒä¼˜ç•Œé¢: http://localhost:8051")

    # å¯åŠ¨å‚æ•°è°ƒä¼˜ç•Œé¢ï¼ˆåå°ï¼‰
    import threading
    param_thread = threading.Thread(
        target=lambda: param_app.run_server(debug=False, port=8051)
    )
    param_thread.daemon = True
    param_thread.start()

    # å¯åŠ¨ä¸»ä»ªè¡¨æ¿
    dashboard.run(debug=False, port=8050)

if __name__ == "__main__":
    run_visualization_system()
```

## 3. æ€§èƒ½åˆ†æå·¥å…·

### 3.1 è¯¦ç»†æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå™¨

```python
# performance_analysis_tools.py
"""
æ€§èƒ½åˆ†æå·¥å…·é›†
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import time
import psutil
import threading
from collections import defaultdict
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class DetailedPerformanceAnalyzer:
    """è¯¦ç»†æ€§èƒ½åˆ†æå™¨"""

    def __init__(self):
        self.performance_data = {
            'navigation': defaultdict(list),
            'ekf': defaultdict(list),
            'dqn': defaultdict(list),
            'system': defaultdict(list),
            'timestamps': []
        }

        self.analysis_results = {}

    def record_navigation_performance(self, episode_data):
        """è®°å½•å¯¼èˆªæ€§èƒ½æ•°æ®"""

        # åŸºæœ¬æŒ‡æ ‡
        self.performance_data['navigation']['success_rate'].append(
            1 if episode_data.get('success', False) else 0
        )
        self.performance_data['navigation']['episode_length'].append(
            episode_data.get('steps', 0)
        )
        self.performance_data['navigation']['total_reward'].append(
            episode_data.get('total_reward', 0)
        )

        # è½¨è¿¹åˆ†æ
        if 'trajectory' in episode_data:
            trajectory = np.array(episode_data['trajectory'])
            if len(trajectory) > 1:
                # è·¯å¾„é•¿åº¦
                path_length = np.sum(np.linalg.norm(np.diff(trajectory[:, :2], axis=0), axis=1))
                self.performance_data['navigation']['path_length'].append(path_length)

                # è·¯å¾„å¹³æ»‘åº¦
                if len(trajectory) > 2:
                    angles = []
                    for i in range(len(trajectory) - 2):
                        v1 = trajectory[i+1, :2] - trajectory[i, :2]
                        v2 = trajectory[i+2, :2] - trajectory[i+1, :2]
                        if np.linalg.norm(v1) > 0 and np.linalg.norm(v2) > 0:
                            angle = np.arccos(np.clip(np.dot(v1, v2) /
                                                    (np.linalg.norm(v1) * np.linalg.norm(v2)), -1, 1))
                            angles.append(angle)

                    path_smoothness = np.mean(angles) if angles else 0
                    self.performance_data['navigation']['path_smoothness'].append(path_smoothness)

        # æ•ˆç‡æŒ‡æ ‡
        if 'goal_distance_initial' in episode_data and 'goal_distance_final' in episode_data:
            efficiency = (episode_data['goal_distance_initial'] - episode_data['goal_distance_final']) / \
                        episode_data['goal_distance_initial']
            self.performance_data['navigation']['efficiency'].append(efficiency)

    def record_ekf_performance(self, ekf_data):
        """è®°å½•EKFæ€§èƒ½æ•°æ®"""

        if 'position_error' in ekf_data:
            self.performance_data['ekf']['position_error'].append(ekf_data['position_error'])

        if 'angle_error' in ekf_data:
            self.performance_data['ekf']['angle_error'].append(ekf_data['angle_error'])

        if 'innovation' in ekf_data:
            self.performance_data['ekf']['innovation_norm'].append(
                np.linalg.norm(ekf_data['innovation'])
            )

        if 'uncertainty' in ekf_data:
            self.performance_data['ekf']['uncertainty'].append(ekf_data['uncertainty'])

        if 'computation_time' in ekf_data:
            self.performance_data['ekf']['computation_time'].append(ekf_data['computation_time'])

    def record_dqn_performance(self, dqn_data):
        """è®°å½•DQNæ€§èƒ½æ•°æ®"""

        if 'q_value' in dqn_data:
            self.performance_data['dqn']['q_value'].append(dqn_data['q_value'])

        if 'loss' in dqn_data:
            self.performance_data['dqn']['loss'].append(dqn_data['loss'])

        if 'epsilon' in dqn_data:
            self.performance_data['dqn']['epsilon'].append(dqn_data['epsilon'])

        if 'action_distribution' in dqn_data:
            # è®°å½•åŠ¨ä½œåˆ†å¸ƒç†µï¼ˆæ¢ç´¢å¤šæ ·æ€§ï¼‰
            action_probs = np.array(dqn_data['action_distribution'])
            action_probs = action_probs / np.sum(action_probs)  # å½’ä¸€åŒ–
            entropy = -np.sum(action_probs * np.log(action_probs + 1e-8))
            self.performance_data['dqn']['action_entropy'].append(entropy)

    def record_system_performance(self):
        """è®°å½•ç³»ç»Ÿæ€§èƒ½æ•°æ®"""

        # CPUå’Œå†…å­˜ä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent()
        memory_info = psutil.virtual_memory()

        self.performance_data['system']['cpu_usage'].append(cpu_percent)
        self.performance_data['system']['memory_usage'].append(memory_info.percent)
        self.performance_data['system']['memory_available'].append(memory_info.available / 1024**3)  # GB

        # GPUä½¿ç”¨ç‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            import GPUtil
            gpus = GPUtil.getGPUs()
            if gpus:
                gpu = gpus[0]
                self.performance_data['system']['gpu_usage'].append(gpu.load * 100)
                self.performance_data['system']['gpu_memory_usage'].append(gpu.memoryUtil * 100)
        except ImportError:
            pass

        # æ—¶é—´æˆ³
        self.performance_data['timestamps'].append(time.time())

    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæ€§èƒ½æŠ¥å‘Š"""

        report = {
            'generation_time': datetime.now().isoformat(),
            'analysis_summary': {},
            'detailed_metrics': {},
            'recommendations': []
        }

        # å¯¼èˆªæ€§èƒ½åˆ†æ
        nav_analysis = self.analyze_navigation_performance()
        report['analysis_summary']['navigation'] = nav_analysis

        # EKFæ€§èƒ½åˆ†æ
        ekf_analysis = self.analyze_ekf_performance()
        report['analysis_summary']['ekf'] = ekf_analysis

        # DQNæ€§èƒ½åˆ†æ
        dqn_analysis = self.analyze_dqn_performance()
        report['analysis_summary']['dqn'] = dqn_analysis

        # ç³»ç»Ÿæ€§èƒ½åˆ†æ
        system_analysis = self.analyze_system_performance()
        report['analysis_summary']['system'] = system_analysis

        # ç”Ÿæˆå»ºè®®
        report['recommendations'] = self.generate_recommendations()

        # è¯¦ç»†æŒ‡æ ‡
        report['detailed_metrics'] = self.performance_data

        return report

    def analyze_navigation_performance(self):
        """åˆ†æå¯¼èˆªæ€§èƒ½"""

        nav_data = self.performance_data['navigation']
        analysis = {}

        if nav_data['success_rate']:
            success_rates = nav_data['success_rate']
            analysis['overall_success_rate'] = np.mean(success_rates)
            analysis['success_rate_trend'] = self.calculate_trend(success_rates)
            analysis['recent_success_rate'] = np.mean(success_rates[-50:]) if len(success_rates) >= 50 else np.mean(success_rates)

        if nav_data['episode_length']:
            episode_lengths = nav_data['episode_length']
            analysis['avg_episode_length'] = np.mean(episode_lengths)
            analysis['episode_length_std'] = np.std(episode_lengths)
            analysis['episode_length_trend'] = self.calculate_trend(episode_lengths)

        if nav_data['total_reward']:
            rewards = nav_data['total_reward']
            analysis['avg_reward'] = np.mean(rewards)
            analysis['reward_std'] = np.std(rewards)
            analysis['reward_trend'] = self.calculate_trend(rewards)

        if nav_data['path_length']:
            path_lengths = nav_data['path_length']
            analysis['avg_path_length'] = np.mean(path_lengths)
            analysis['path_efficiency'] = self.calculate_path_efficiency(path_lengths)

        if nav_data['path_smoothness']:
            smoothness = nav_data['path_smoothness']
            analysis['avg_path_smoothness'] = np.mean(smoothness)

        return analysis

    def analyze_ekf_performance(self):
        """åˆ†æEKFæ€§èƒ½"""

        ekf_data = self.performance_data['ekf']
        analysis = {}

        if ekf_data['position_error']:
            pos_errors = ekf_data['position_error']
            analysis['mean_position_error'] = np.mean(pos_errors)
            analysis['position_error_std'] = np.std(pos_errors)
            analysis['position_rmse'] = np.sqrt(np.mean(np.array(pos_errors)**2))
            analysis['position_error_trend'] = self.calculate_trend(pos_errors)

        if ekf_data['innovation_norm']:
            innovations = ekf_data['innovation_norm']
            analysis['mean_innovation'] = np.mean(innovations)
            analysis['innovation_consistency'] = self.check_innovation_consistency(innovations)

        if ekf_data['uncertainty']:
            uncertainties = ekf_data['uncertainty']
            analysis['mean_uncertainty'] = np.mean(uncertainties)
            analysis['uncertainty_trend'] = self.calculate_trend(uncertainties)

        if ekf_data['computation_time']:
            comp_times = ekf_data['computation_time']
            analysis['mean_computation_time'] = np.mean(comp_times)
            analysis['max_computation_time'] = np.max(comp_times)
            analysis['computation_time_std'] = np.std(comp_times)

        return analysis

    def analyze_dqn_performance(self):
        """åˆ†æDQNæ€§èƒ½"""

        dqn_data = self.performance_data['dqn']
        analysis = {}

        if dqn_data['q_value']:
            q_values = dqn_data['q_value']
            analysis['mean_q_value'] = np.mean(q_values)
            analysis['q_value_trend'] = self.calculate_trend(q_values)
            analysis['q_value_stability'] = np.std(q_values[-100:]) if len(q_values) >= 100 else np.std(q_values)

        if dqn_data['loss']:
            losses = dqn_data['loss']
            analysis['mean_loss'] = np.mean(losses)
            analysis['loss_trend'] = self.calculate_trend(losses)
            analysis['loss_convergence'] = self.check_convergence(losses)

        if dqn_data['epsilon']:
            epsilons = dqn_data['epsilon']
            analysis['current_epsilon'] = epsilons[-1] if epsilons else 0
            analysis['exploration_schedule'] = self.analyze_exploration_schedule(epsilons)

        if dqn_data['action_entropy']:
            entropies = dqn_data['action_entropy']
            analysis['mean_action_entropy'] = np.mean(entropies)
            analysis['exploration_diversity'] = self.classify_exploration_diversity(np.mean(entropies))

        return analysis

    def analyze_system_performance(self):
        """åˆ†æç³»ç»Ÿæ€§èƒ½"""

        sys_data = self.performance_data['system']
        analysis = {}

        if sys_data['cpu_usage']:
            cpu_usage = sys_data['cpu_usage']
            analysis['mean_cpu_usage'] = np.mean(cpu_usage)
            analysis['max_cpu_usage'] = np.max(cpu_usage)
            analysis['cpu_usage_std'] = np.std(cpu_usage)

        if sys_data['memory_usage']:
            memory_usage = sys_data['memory_usage']
            analysis['mean_memory_usage'] = np.mean(memory_usage)
            analysis['max_memory_usage'] = np.max(memory_usage)

        if sys_data['gpu_usage']:
            gpu_usage = sys_data['gpu_usage']
            analysis['mean_gpu_usage'] = np.mean(gpu_usage)
            analysis['max_gpu_usage'] = np.max(gpu_usage)

        return analysis

    def calculate_trend(self, data):
        """è®¡ç®—æ•°æ®è¶‹åŠ¿"""
        if len(data) < 2:
            return 0

        x = np.arange(len(data))
        y = np.array(data)

        # çº¿æ€§å›å½’
        slope = np.polyfit(x, y, 1)[0]
        return slope

    def calculate_path_efficiency(self, path_lengths):
        """è®¡ç®—è·¯å¾„æ•ˆç‡"""
        if not path_lengths:
            return 0

        # å‡è®¾æœ€ä¼˜è·¯å¾„é•¿åº¦ï¼ˆç›´çº¿è·ç¦»ï¼‰
        optimal_length = 10.0  # æ ¹æ®ç¯å¢ƒè®¾ç½®
        avg_path_length = np.mean(path_lengths)

        efficiency = optimal_length / avg_path_length if avg_path_length > 0 else 0
        return min(efficiency, 1.0)

    def check_innovation_consistency(self, innovations):
        """æ£€æŸ¥åˆ›æ–°åºåˆ—ä¸€è‡´æ€§"""
        if len(innovations) < 10:
            return "æ•°æ®ä¸è¶³"

        # ç®€åŒ–çš„ä¸€è‡´æ€§æ£€æŸ¥
        mean_innovation = np.mean(innovations)
        std_innovation = np.std(innovations)

        # ç†è®ºä¸Šåˆ›æ–°åºåˆ—åº”è¯¥æ¥è¿‘é›¶å‡å€¼
        if abs(mean_innovation) < 0.1 and std_innovation < 2.0:
            return "ä¸€è‡´"
        else:
            return "ä¸ä¸€è‡´"

    def check_convergence(self, losses):
        """æ£€æŸ¥æŸå¤±æ”¶æ•›æ€§"""
        if len(losses) < 50:
            return "æ•°æ®ä¸è¶³"

        # æ£€æŸ¥æœ€è¿‘50ä¸ªæŸå¤±å€¼çš„è¶‹åŠ¿
        recent_losses = losses[-50:]
        trend = self.calculate_trend(recent_losses)

        if trend < -0.001:
            return "æ”¶æ•›ä¸­"
        elif abs(trend) < 0.001:
            return "å·²æ”¶æ•›"
        else:
            return "å‘æ•£"

    def analyze_exploration_schedule(self, epsilons):
        """åˆ†ææ¢ç´¢è®¡åˆ’"""
        if not epsilons:
            return "æ— æ•°æ®"

        start_epsilon = epsilons[0]
        end_epsilon = epsilons[-1]

        if start_epsilon > 0.9 and end_epsilon < 0.1:
            return "æ ‡å‡†è¡°å‡"
        elif end_epsilon > 0.3:
            return "è¿‡åº¦æ¢ç´¢"
        else:
            return "æ¢ç´¢ä¸è¶³"

    def classify_exploration_diversity(self, mean_entropy):
        """åˆ†ç±»æ¢ç´¢å¤šæ ·æ€§"""
        max_entropy = np.log(4)  # 4ä¸ªåŠ¨ä½œçš„æœ€å¤§ç†µ

        if mean_entropy > 0.8 * max_entropy:
            return "é«˜å¤šæ ·æ€§"
        elif mean_entropy > 0.5 * max_entropy:
            return "ä¸­ç­‰å¤šæ ·æ€§"
        else:
            return "ä½å¤šæ ·æ€§"

    def generate_recommendations(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""

        recommendations = []

        # å¯¼èˆªæ€§èƒ½å»ºè®®
        nav_analysis = self.analysis_results.get('navigation', {})
        if nav_analysis.get('overall_success_rate', 0) < 0.8:
            recommendations.append({
                'category': 'å¯¼èˆªæ€§èƒ½',
                'issue': 'æˆåŠŸç‡åä½',
                'suggestion': 'å»ºè®®è°ƒæ•´å¥–åŠ±å‡½æ•°ï¼Œå¢åŠ ä¸­é—´å¥–åŠ±å¼•å¯¼'
            })

        if nav_analysis.get('avg_episode_length', 0) > 200:
            recommendations.append({
                'category': 'å¯¼èˆªæ•ˆç‡',
                'issue': 'å›åˆé•¿åº¦è¿‡é•¿',
                'suggestion': 'è€ƒè™‘å¢åŠ æ¢ç´¢ç­–ç•¥æˆ–è°ƒæ•´ç½‘ç»œç»“æ„'
            })

        # EKFæ€§èƒ½å»ºè®®
        ekf_analysis = self.analysis_results.get('ekf', {})
        if ekf_analysis.get('mean_position_error', float('inf')) > 1.0:
            recommendations.append({
                'category': 'EKFæ€§èƒ½',
                'issue': 'å®šä½è¯¯å·®è¾ƒå¤§',
                'suggestion': 'æ£€æŸ¥ä¼ æ„Ÿå™¨æ ¡å‡†å’Œå™ªå£°æ¨¡å‹å‚æ•°'
            })

        if ekf_analysis.get('innovation_consistency') == 'ä¸ä¸€è‡´':
            recommendations.append({
                'category': 'EKFè°ƒä¼˜',
                'issue': 'åˆ›æ–°åºåˆ—ä¸ä¸€è‡´',
                'suggestion': 'éœ€è¦é‡æ–°è°ƒæ•´è¿‡ç¨‹å™ªå£°å’Œè§‚æµ‹å™ªå£°åæ–¹å·®'
            })

        # DQNæ€§èƒ½å»ºè®®
        dqn_analysis = self.analysis_results.get('dqn', {})
        if dqn_analysis.get('loss_convergence') == 'å‘æ•£':
            recommendations.append({
                'category': 'DQNè®­ç»ƒ',
                'issue': 'æŸå¤±å‘æ•£',
                'suggestion': 'é™ä½å­¦ä¹ ç‡æˆ–è°ƒæ•´ç½‘ç»œç»“æ„'
            })

        if dqn_analysis.get('exploration_diversity') == 'ä½å¤šæ ·æ€§':
            recommendations.append({
                'category': 'DQNæ¢ç´¢',
                'issue': 'æ¢ç´¢ä¸å……åˆ†',
                'suggestion': 'å¢åŠ æ¢ç´¢ç‡æˆ–ä½¿ç”¨æ›´å¤æ‚çš„æ¢ç´¢ç­–ç•¥'
            })

        # ç³»ç»Ÿæ€§èƒ½å»ºè®®
        sys_analysis = self.analysis_results.get('system', {})
        if sys_analysis.get('mean_cpu_usage', 0) > 80:
            recommendations.append({
                'category': 'ç³»ç»Ÿä¼˜åŒ–',
                'issue': 'CPUä½¿ç”¨ç‡è¿‡é«˜',
                'suggestion': 'è€ƒè™‘å¹¶è¡ŒåŒ–å¤„ç†æˆ–ç®—æ³•ä¼˜åŒ–'
            })

        return recommendations

    def create_performance_dashboard(self):
        """åˆ›å»ºæ€§èƒ½åˆ†æä»ªè¡¨æ¿"""

        # è®¾ç½®ç»˜å›¾é£æ ¼
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")

        fig, axes = plt.subplots(3, 4, figsize=(20, 15))
        fig.suptitle('ç»¼åˆæ€§èƒ½åˆ†ææŠ¥å‘Š', fontsize=16, fontweight='bold')

        # å¯¼èˆªæ€§èƒ½å›¾è¡¨
        self.plot_navigation_metrics(axes[0, :])

        # EKFæ€§èƒ½å›¾è¡¨
        self.plot_ekf_metrics(axes[1, :])

        # DQNå’Œç³»ç»Ÿæ€§èƒ½å›¾è¡¨
        self.plot_dqn_metrics(axes[2, :2])
        self.plot_system_metrics(axes[2, 2:])

        plt.tight_layout()
        plt.savefig('comprehensive_performance_report.png', dpi=300, bbox_inches='tight')
        plt.show()

        return fig

    def plot_navigation_metrics(self, axes):
        """ç»˜åˆ¶å¯¼èˆªæŒ‡æ ‡"""

        nav_data = self.performance_data['navigation']

        # æˆåŠŸç‡è¶‹åŠ¿
        if nav_data['success_rate']:
            success_rates = nav_data['success_rate']
            window_size = min(20, len(success_rates))
            if len(success_rates) >= window_size:
                smoothed = pd.Series(success_rates).rolling(window=window_size).mean()
                axes[0].plot(smoothed.index, smoothed.values, linewidth=2)
            axes[0].set_title('æˆåŠŸç‡è¶‹åŠ¿')
            axes[0].set_ylabel('æˆåŠŸç‡')
            axes[0].grid(True, alpha=0.3)

        # å¥–åŠ±åˆ†å¸ƒ
        if nav_data['total_reward']:
            axes[1].hist(nav_data['total_reward'], bins=30, alpha=0.7, edgecolor='black')
            axes[1].set_title('å¥–åŠ±åˆ†å¸ƒ')
            axes[1].set_xlabel('æ€»å¥–åŠ±')
            axes[1].set_ylabel('é¢‘æ¬¡')
            axes[1].grid(True, alpha=0.3)

        # å›åˆé•¿åº¦è¶‹åŠ¿
        if nav_data['episode_length']:
            episode_lengths = nav_data['episode_length']
            axes[2].plot(episode_lengths, alpha=0.7)
            if len(episode_lengths) >= 20:
                smoothed = pd.Series(episode_lengths).rolling(window=20).mean()
                axes[2].plot(smoothed.index, smoothed.values, 'r-', linewidth=2, label='å¹³å‡å€¼')
                axes[2].legend()
            axes[2].set_title('å›åˆé•¿åº¦è¶‹åŠ¿')
            axes[2].set_ylabel('æ­¥æ•°')
            axes[2].grid(True, alpha=0.3)

        # è·¯å¾„æ•ˆç‡ç®±çº¿å›¾
        if nav_data['path_length']:
            path_lengths = nav_data['path_length']
            axes[3].boxplot(path_lengths)
            axes[3].set_title('è·¯å¾„é•¿åº¦åˆ†å¸ƒ')
            axes[3].set_ylabel('è·¯å¾„é•¿åº¦')
            axes[3].grid(True, alpha=0.3)

    def plot_ekf_metrics(self, axes):
        """ç»˜åˆ¶EKFæŒ‡æ ‡"""

        ekf_data = self.performance_data['ekf']

        # ä½ç½®è¯¯å·®è¶‹åŠ¿
        if ekf_data['position_error']:
            pos_errors = ekf_data['position_error']
            axes[0].plot(pos_errors, alpha=0.7)
            axes[0].axhline(np.mean(pos_errors), color='red', linestyle='--',
                           label=f'å¹³å‡å€¼: {np.mean(pos_errors):.3f}')
            axes[0].set_title('ä½ç½®è¯¯å·®è¶‹åŠ¿')
            axes[0].set_ylabel('ä½ç½®è¯¯å·® (m)')
            axes[0].legend()
            axes[0].grid(True, alpha=0.3)

        # åˆ›æ–°åºåˆ—
        if ekf_data['innovation_norm']:
            innovations = ekf_data['innovation_norm']
            axes[1].plot(innovations, alpha=0.7)
            axes[1].set_title('åˆ›æ–°åºåˆ—')
            axes[1].set_ylabel('åˆ›æ–°èŒƒæ•°')
            axes[1].grid(True, alpha=0.3)

        # ä¸ç¡®å®šæ€§æ¼”åŒ–
        if ekf_data['uncertainty']:
            uncertainties = ekf_data['uncertainty']
            axes[2].plot(uncertainties, linewidth=2)
            axes[2].set_title('ä¼°è®¡ä¸ç¡®å®šæ€§')
            axes[2].set_ylabel('ä¸ç¡®å®šæ€§')
            axes[2].grid(True, alpha=0.3)

        # è®¡ç®—æ—¶é—´åˆ†å¸ƒ
        if ekf_data['computation_time']:
            comp_times = np.array(ekf_data['computation_time']) * 1000  # è½¬æ¢ä¸ºms
            axes[3].hist(comp_times, bins=20, alpha=0.7, edgecolor='black')
            axes[3].axvline(np.mean(comp_times), color='red', linestyle='--',
                           label=f'å¹³å‡: {np.mean(comp_times):.1f}ms')
            axes[3].set_title('EKFè®¡ç®—æ—¶é—´åˆ†å¸ƒ')
            axes[3].set_xlabel('è®¡ç®—æ—¶é—´ (ms)')
            axes[3].set_ylabel('é¢‘æ¬¡')
            axes[3].legend()
            axes[3].grid(True, alpha=0.3)

    def plot_dqn_metrics(self, axes):
        """ç»˜åˆ¶DQNæŒ‡æ ‡"""

        dqn_data = self.performance_data['dqn']

        # Qå€¼å’ŒæŸå¤±
        if dqn_data['q_value'] and dqn_data['loss']:
            ax1 = axes[0]
            ax2 = ax1.twinx()

            ax1.plot(dqn_data['q_value'], 'b-', label='Qå€¼')
            ax2.plot(dqn_data['loss'], 'r-', alpha=0.7, label='æŸå¤±')

            ax1.set_xlabel('è®­ç»ƒæ­¥éª¤')
            ax1.set_ylabel('Qå€¼', color='b')
            ax2.set_ylabel('æŸå¤±', color='r')
            ax1.set_title('Qå€¼ä¸æŸå¤±è¶‹åŠ¿')

            # æ·»åŠ å›¾ä¾‹
            lines1, labels1 = ax1.get_legend_handles_labels()
            lines2, labels2 = ax2.get_legend_handles_labels()
            ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')

            ax1.grid(True, alpha=0.3)

        # æ¢ç´¢ç‡è¡°å‡
        if dqn_data['epsilon']:
            axes[1].plot(dqn_data['epsilon'], linewidth=2)
            axes[1].set_title('æ¢ç´¢ç‡è¡°å‡')
            axes[1].set_ylabel('Îµå€¼')
            axes[1].set_xlabel('è®­ç»ƒæ­¥éª¤')
            axes[1].grid(True, alpha=0.3)

    def plot_system_metrics(self, axes):
        """ç»˜åˆ¶ç³»ç»ŸæŒ‡æ ‡"""

        sys_data = self.performance_data['system']

        # CPUå’Œå†…å­˜ä½¿ç”¨ç‡
        if sys_data['cpu_usage'] and sys_data['memory_usage']:
            timestamps = range(len(sys_data['cpu_usage']))

            axes[0].plot(timestamps, sys_data['cpu_usage'], 'b-', label='CPUä½¿ç”¨ç‡')
            axes[0].plot(timestamps, sys_data['memory_usage'], 'r-', label='å†…å­˜ä½¿ç”¨ç‡')
            axes[0].set_title('ç³»ç»Ÿèµ„æºä½¿ç”¨ç‡')
            axes[0].set_ylabel('ä½¿ç”¨ç‡ (%)')
            axes[0].set_xlabel('æ—¶é—´')
            axes[0].legend()
            axes[0].grid(True, alpha=0.3)

        # èµ„æºä½¿ç”¨ç»Ÿè®¡
        if sys_data['cpu_usage']:
            resource_stats = {
                'CPUå¹³å‡': np.mean(sys_data['cpu_usage']),
                'CPUæœ€å¤§': np.max(sys_data['cpu_usage']),
                'å†…å­˜å¹³å‡': np.mean(sys_data['memory_usage']) if sys_data['memory_usage'] else 0,
                'å†…å­˜æœ€å¤§': np.max(sys_data['memory_usage']) if sys_data['memory_usage'] else 0
            }

            bars = axes[1].bar(resource_stats.keys(), resource_stats.values(),
                              color=['skyblue', 'lightcoral', 'lightgreen', 'orange'])
            axes[1].set_title('èµ„æºä½¿ç”¨ç»Ÿè®¡')
            axes[1].set_ylabel('ä½¿ç”¨ç‡ (%)')

            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value in zip(bars, resource_stats.values()):
                axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                           f'{value:.1f}%', ha='center', va='bottom')

            axes[1].grid(True, alpha=0.3)

    def save_report(self, filename='performance_analysis_report.json'):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""

        report = self.generate_comprehensive_report()

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)

        print(f"æ€§èƒ½åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        return filename

def run_performance_analysis_demo():
    """è¿è¡Œæ€§èƒ½åˆ†ææ¼”ç¤º"""

    print("=== æ€§èƒ½åˆ†æå·¥å…·æ¼”ç¤º ===")

    # åˆ›å»ºæ€§èƒ½åˆ†æå™¨
    analyzer = DetailedPerformanceAnalyzer()

    # æ¨¡æ‹Ÿè®°å½•æ•°æ®
    print("ç”Ÿæˆæ¨¡æ‹Ÿæ€§èƒ½æ•°æ®...")

    for episode in range(200):
        # æ¨¡æ‹Ÿå¯¼èˆªæ•°æ®
        nav_data = {
            'success': np.random.random() > (0.5 - episode * 0.002),  # é€æ¸æé«˜æˆåŠŸç‡
            'steps': max(50, 200 - episode + np.random.randint(-20, 20)),
            'total_reward': 50 + episode * 0.3 + np.random.normal(0, 10),
            'trajectory': np.random.randn(100, 3),  # æ¨¡æ‹Ÿè½¨è¿¹
            'goal_distance_initial': 10.0,
            'goal_distance_final': max(0.1, 5.0 - episode * 0.02 + np.random.normal(0, 1))
        }
        analyzer.record_navigation_performance(nav_data)

        # æ¨¡æ‹ŸEKFæ•°æ®
        ekf_data = {
            'position_error': max(0.1, 2.0 - episode * 0.005 + np.random.normal(0, 0.1)),
            'angle_error': np.random.normal(0, 0.1),
            'innovation': np.random.normal(0, 0.5, 3),
            'uncertainty': 0.2 + 0.1 * np.sin(episode * 0.1),
            'computation_time': 0.01 + np.random.normal(0, 0.002)
        }
        analyzer.record_ekf_performance(ekf_data)

        # æ¨¡æ‹ŸDQNæ•°æ®
        dqn_data = {
            'q_value': 10 + episode * 0.1 + np.random.normal(0, 2),
            'loss': max(0.1, 5.0 * np.exp(-episode * 0.01) + np.random.normal(0, 0.5)),
            'epsilon': max(0.01, 1.0 - episode * 0.005),
            'action_distribution': np.random.dirichlet([1, 1, 1, 1])
        }
        analyzer.record_dqn_performance(dqn_data)

        # è®°å½•ç³»ç»Ÿæ€§èƒ½ï¼ˆæ¯10ä¸ªepisodeä¸€æ¬¡ï¼‰
        if episode % 10 == 0:
            analyzer.record_system_performance()

    print("æ•°æ®ç”Ÿæˆå®Œæˆï¼Œå¼€å§‹åˆ†æ...")

    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    report = analyzer.generate_comprehensive_report()

    # æ‰“å°å…³é”®æŒ‡æ ‡
    print("\n=== å…³é”®æ€§èƒ½æŒ‡æ ‡ ===")
    nav_summary = report['analysis_summary']['navigation']
    print(f"å¯¼èˆªæˆåŠŸç‡: {nav_summary.get('overall_success_rate', 0):.2%}")
    print(f"æœ€è¿‘æˆåŠŸç‡: {nav_summary.get('recent_success_rate', 0):.2%}")
    print(f"å¹³å‡å›åˆé•¿åº¦: {nav_summary.get('avg_episode_length', 0):.1f}")

    ekf_summary = report['analysis_summary']['ekf']
    print(f"å¹³å‡å®šä½è¯¯å·®: {ekf_summary.get('mean_position_error', 0):.3f}m")
    print(f"EKFè®¡ç®—æ—¶é—´: {ekf_summary.get('mean_computation_time', 0)*1000:.1f}ms")

    dqn_summary = report['analysis_summary']['dqn']
    print(f"æŸå¤±æ”¶æ•›çŠ¶æ€: {dqn_summary.get('loss_convergence', 'æœªçŸ¥')}")
    print(f"æ¢ç´¢å¤šæ ·æ€§: {dqn_summary.get('exploration_diversity', 'æœªçŸ¥')}")

    # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
    print("\n=== ä¼˜åŒ–å»ºè®® ===")
    for i, rec in enumerate(report['recommendations'], 1):
        print(f"{i}. [{rec['category']}] {rec['issue']}")
        print(f"   å»ºè®®: {rec['suggestion']}")

    # åˆ›å»ºå¯è§†åŒ–ä»ªè¡¨æ¿
    print("\nç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š...")
    analyzer.create_performance_dashboard()

    # ä¿å­˜æŠ¥å‘Š
    report_file = analyzer.save_report()

    print(f"\n=== åˆ†æå®Œæˆ ===")
    print(f"å¯è§†åŒ–å›¾è¡¨å·²æ˜¾ç¤º")
    print(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    return analyzer, report

if __name__ == "__main__":
    analyzer, report = run_performance_analysis_demo()
    print("æ€§èƒ½åˆ†ææ¼”ç¤ºå®Œæˆï¼")
```

## å­¦ä¹ æ£€æŸ¥ç‚¹

### å®éªŒå®ŒæˆéªŒè¯

1. **å®éªŒç¯å¢ƒ**ï¼š
   - æ‰€æœ‰ä¾èµ–åŒ…æ­£ç¡®å®‰è£…
   - éªŒè¯è„šæœ¬é€šè¿‡æµ‹è¯•
   - GPU/CPUç¯å¢ƒé…ç½®æ­£ç¡®

2. **åŸºç¡€ç®—æ³•éªŒè¯**ï¼š
   - Q-LearningæˆåŠŸç‡ > 80%
   - å¡å°”æ›¼æ»¤æ³¢RMSE < 1.0
   - åˆ›æ–°åºåˆ—ä¸€è‡´æ€§æ£€éªŒé€šè¿‡

3. **æ·±åº¦å­¦ä¹ å¯¼èˆª**ï¼š
   - DQNè®­ç»ƒæ”¶æ•›
   - å¯¼èˆªæˆåŠŸç‡ > 70%
   - å¯è§†åŒ–è½¨è¿¹åˆç†

4. **å¯è§†åŒ–ç³»ç»Ÿ**ï¼š
   - å®æ—¶ç›‘æ§ç•Œé¢è¿è¡Œ
   - å‚æ•°è°ƒä¼˜ç•Œé¢å¯ç”¨
   - æ€§èƒ½åˆ†ææŠ¥å‘Šç”Ÿæˆ

### å·¥å…·ä½¿ç”¨èƒ½åŠ›

å®Œæˆæœ¬éƒ¨åˆ†åï¼Œå­¦ç”Ÿåº”èƒ½å¤Ÿï¼š
- ç‹¬ç«‹æ­å»ºå®éªŒç¯å¢ƒ
- è¿è¡Œå’Œè°ƒè¯•å®éªŒä»£ç 
- ä½¿ç”¨å¯è§†åŒ–å·¥å…·åˆ†æç»“æœ
- ç”Ÿæˆä¸“ä¸šçš„æ€§èƒ½æŠ¥å‘Š
- åŸºäºåˆ†æç»“æœä¼˜åŒ–ç®—æ³•

**å®è·µå»ºè®®**ï¼š
1. é€æ­¥å®Œæˆæ‰€æœ‰å®éªŒï¼Œç¡®ä¿æ¯ä¸ªç¯èŠ‚éƒ½ç†è§£
2. å°è¯•ä¿®æ”¹å‚æ•°è§‚å¯Ÿå¯¹ç»“æœçš„å½±å“
3. ä½¿ç”¨å¯è§†åŒ–å·¥å…·æ·±å…¥åˆ†æç®—æ³•è¡Œä¸º
4. è®°å½•å®éªŒè¿‡ç¨‹å’Œå‘ç°çš„é—®é¢˜