#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®3ï¼šæ™ºèƒ½å¯¼èˆªç»¼åˆç³»ç»Ÿæ¼”ç¤ºé¡¹ç›®
==============================

æœ¬é¡¹ç›®æ˜¯å¼ºåŒ–å­¦ä¹ ä¸ä¼ æ„Ÿå™¨èåˆæŠ€æœ¯çš„ç»¼åˆåº”ç”¨ï¼Œå±•ç¤ºäº†ä¸€ä¸ªå®Œæ•´çš„
æ™ºèƒ½æœºå™¨äººå¯¼èˆªç³»ç»Ÿï¼Œç»“åˆæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„è·¯å¾„è§„åˆ’å’Œå¤šä¼ æ„Ÿå™¨èåˆ
çš„ç²¾ç¡®å®šä½ï¼Œå®ç°å¤æ‚ç¯å¢ƒä¸‹çš„è‡ªä¸»å¯¼èˆªã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. åŸºäºDQNçš„æ™ºèƒ½è·¯å¾„è§„åˆ’
2. å¤šä¼ æ„Ÿå™¨èåˆå®šä½ç³»ç»Ÿ
3. åŠ¨æ€ç¯å¢ƒé€‚åº”èƒ½åŠ›
4. å®æ—¶æ€§èƒ½ç›‘æ§ä¸ä¼˜åŒ–
5. ç»¼åˆç³»ç»Ÿè¯„ä¼°ä¸åˆ†æ

ä½œè€…ï¼šæœºå™¨äººè¯¾ç¨‹å›¢é˜Ÿ
æ—¥æœŸï¼š2025å¹´
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import os
import json
from datetime import datetime
from collections import deque
import random
from scipy.spatial.transform import Rotation
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import platform
import matplotlib.font_manager as fm

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾è¡¨æ ·å¼ - æ”¹è¿›ç‰ˆ
def setup_chinese_fonts():
    """è®¾ç½®ä¸­æ–‡å­—ä½“çš„å‡½æ•°"""
    # æ ¹æ®æ“ä½œç³»ç»Ÿé€‰æ‹©å­—ä½“
    if platform.system() == 'Darwin':  # macOS
        font_candidates = ['Arial Unicode MS', 'PingFang SC', 'Helvetica', 'SimHei']
    elif platform.system() == 'Windows':
        font_candidates = ['SimHei', 'Microsoft YaHei', 'KaiTi', 'Arial Unicode MS']
    else:  # Linux
        font_candidates = ['WenQuanYi Micro Hei', 'SimHei', 'DejaVu Sans', 'Arial Unicode MS']

    # æ£€æŸ¥å¯ç”¨å­—ä½“
    available_fonts = [f.name for f in fm.fontManager.ttflist]

    # é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„å­—ä½“
    selected_font = 'DejaVu Sans'  # é»˜è®¤å­—ä½“
    for font in font_candidates:
        if font in available_fonts:
            selected_font = font
            break

    # è®¾ç½®å­—ä½“
    plt.rcParams['font.sans-serif'] = [selected_font] + font_candidates
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams['font.size'] = 10
    plt.rcParams['figure.facecolor'] = 'white'  # è®¾ç½®å›¾è¡¨èƒŒæ™¯ä¸ºç™½è‰²
    plt.rcParams['axes.facecolor'] = 'white'    # è®¾ç½®åæ ‡è½´èƒŒæ™¯ä¸ºç™½è‰²

    print(f"å­—ä½“è®¾ç½®å®Œæˆï¼Œä½¿ç”¨å­—ä½“: {selected_font}")
    return selected_font

# è°ƒç”¨å­—ä½“è®¾ç½®å‡½æ•°
try:
    setup_chinese_fonts()
except Exception as e:
    print(f"å­—ä½“è®¾ç½®è­¦å‘Š: {e}")
    # ä½¿ç”¨åŸºæœ¬è®¾ç½®ä½œä¸ºå¤‡ç”¨
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False

sns.set_style("whitegrid")

# è®¾ç½®éšæœºç§å­
np.random.seed(42)
torch.manual_seed(42)
random.seed(42)

class NavigationEnvironment:
    """å¤æ‚å¯¼èˆªç¯å¢ƒ"""

    def __init__(self, size=20, num_obstacles=15, num_dynamic_obstacles=3):
        self.size = size
        self.num_obstacles = num_obstacles
        self.num_dynamic_obstacles = num_dynamic_obstacles

        # åˆ›å»ºç¯å¢ƒåœ°å›¾
        self.static_map = np.zeros((size, size))
        self.dynamic_map = np.zeros((size, size))

        # å…ˆå®šä¹‰èµ·ç‚¹å’Œç»ˆç‚¹ï¼Œå†ç”Ÿæˆéšœç¢ç‰©
        self.start_pos = (1, 1)
        self.goal_pos = (size-2, size-2)

        # ç”Ÿæˆé™æ€éšœç¢ç‰©
        self.generate_static_obstacles()

        # åŠ¨æ€éšœç¢ç‰©
        self.dynamic_obstacles = []
        self.generate_dynamic_obstacles()

        # å½“å‰æœºå™¨äººä½ç½®
        self.robot_pos = list(self.start_pos)

        # åŠ¨ä½œç©ºé—´ï¼šä¸Šä¸‹å·¦å³ + åœæ­¢
        self.actions = [(0, 1), (0, -1), (1, 0), (-1, 0), (0, 0)]
        self.action_names = ['ä¸Š', 'ä¸‹', 'å³', 'å·¦', 'åœæ­¢']

        # è·¯å¾„è®°å½•
        self.path_history = [self.robot_pos.copy()]

    def generate_static_obstacles(self):
        """ç”Ÿæˆé™æ€éšœç¢ç‰©"""
        # æ·»åŠ è¾¹ç•Œå¢™
        self.static_map[0, :] = 1
        self.static_map[-1, :] = 1
        self.static_map[:, 0] = 1
        self.static_map[:, -1] = 1

        # éšæœºæ·»åŠ å†…éƒ¨éšœç¢ç‰©
        for _ in range(self.num_obstacles):
            while True:
                x, y = np.random.randint(2, self.size-2, 2)
                if (x, y) != self.start_pos and (x, y) != self.goal_pos:
                    self.static_map[x, y] = 1
                    break

        # æ·»åŠ ä¸€äº›ç»“æ„åŒ–éšœç¢ç‰©ï¼ˆå¢™ä½“ï¼‰
        mid = self.size // 2
        for i in range(3, mid):
            self.static_map[i, mid] = 1
        for i in range(mid+2, self.size-3):
            self.static_map[i, mid] = 1

    def generate_dynamic_obstacles(self):
        """ç”ŸæˆåŠ¨æ€éšœç¢ç‰©"""
        for _ in range(self.num_dynamic_obstacles):
            while True:
                x, y = np.random.randint(2, self.size-2, 2)
                if (self.static_map[x, y] == 0 and
                    (x, y) != self.start_pos and
                    (x, y) != self.goal_pos):

                    # éšæœºé€Ÿåº¦å’Œæ–¹å‘
                    vx, vy = np.random.choice([-1, 0, 1], 2)
                    self.dynamic_obstacles.append({
                        'pos': [x, y],
                        'velocity': [vx, vy],
                        'size': 1
                    })
                    break

    def update_dynamic_obstacles(self):
        """æ›´æ–°åŠ¨æ€éšœç¢ç‰©ä½ç½®"""
        self.dynamic_map.fill(0)

        for obs in self.dynamic_obstacles:
            # æ›´æ–°ä½ç½®
            new_x = obs['pos'][0] + obs['velocity'][0]
            new_y = obs['pos'][1] + obs['velocity'][1]

            # è¾¹ç•Œæ£€æŸ¥å’Œç¢°æ’æ£€æŸ¥
            if (0 < new_x < self.size-1 and 0 < new_y < self.size-1 and
                self.static_map[new_x, new_y] == 0):
                obs['pos'] = [new_x, new_y]
            else:
                # åå¼¹
                obs['velocity'][0] *= -1
                obs['velocity'][1] *= -1

            # åœ¨åŠ¨æ€åœ°å›¾ä¸Šæ ‡è®°
            x, y = obs['pos']
            self.dynamic_map[x, y] = 1

    def get_state(self):
        """è·å–å½“å‰çŠ¶æ€"""
        # å±€éƒ¨è§‚æµ‹ï¼šrobotå‘¨å›´5x5åŒºåŸŸ
        local_size = 5
        half_size = local_size // 2

        local_obs = np.zeros((local_size, local_size, 3))  # é™æ€ã€åŠ¨æ€ã€ç›®æ ‡

        rx, ry = self.robot_pos

        for i in range(local_size):
            for j in range(local_size):
                world_x = rx - half_size + i
                world_y = ry - half_size + j

                if 0 <= world_x < self.size and 0 <= world_y < self.size:
                    # é™æ€éšœç¢ç‰©
                    local_obs[i, j, 0] = self.static_map[world_x, world_y]
                    # åŠ¨æ€éšœç¢ç‰©
                    local_obs[i, j, 1] = self.dynamic_map[world_x, world_y]
                    # ç›®æ ‡ä½ç½®
                    if (world_x, world_y) == self.goal_pos:
                        local_obs[i, j, 2] = 1
                else:
                    # è¾¹ç•Œå¤–è§†ä¸ºéšœç¢ç‰©
                    local_obs[i, j, 0] = 1

        # æ·»åŠ å…¨å±€ä¿¡æ¯
        goal_direction = np.array([
            self.goal_pos[0] - rx,
            self.goal_pos[1] - ry
        ])
        goal_distance = np.linalg.norm(goal_direction)

        if goal_distance > 0:
            goal_direction = goal_direction / goal_distance

        # ç»„åˆçŠ¶æ€ï¼šå±€éƒ¨è§‚æµ‹ + ç›®æ ‡æ–¹å‘ + è·ç¦»
        state = {
            'local_obs': local_obs.flatten(),
            'goal_direction': goal_direction,
            'goal_distance': min(goal_distance / self.size, 1.0),
            'robot_pos': np.array(self.robot_pos, dtype=float) / self.size
        }

        return np.concatenate([
            state['local_obs'],
            state['goal_direction'],
            [state['goal_distance']],
            state['robot_pos']
        ])

    def step(self, action):
        """æ‰§è¡ŒåŠ¨ä½œ"""
        # æ›´æ–°åŠ¨æ€éšœç¢ç‰©
        self.update_dynamic_obstacles()

        # æ‰§è¡Œæœºå™¨äººåŠ¨ä½œ
        dx, dy = self.actions[action]
        new_x = self.robot_pos[0] + dx
        new_y = self.robot_pos[1] + dy

        # æ£€æŸ¥æ˜¯å¦å¯ä»¥ç§»åŠ¨
        reward = -0.01  # åŸºç¡€ç§»åŠ¨æˆæœ¬

        if (0 <= new_x < self.size and 0 <= new_y < self.size and
            self.static_map[new_x, new_y] == 0 and
            self.dynamic_map[new_x, new_y] == 0):

            # è®¡ç®—ç§»åŠ¨å‰åçš„ç›®æ ‡è·ç¦»
            old_dist = np.linalg.norm(np.array(self.robot_pos) - np.array(self.goal_pos))
            new_dist = np.linalg.norm(np.array([new_x, new_y]) - np.array(self.goal_pos))

            # ç§»åŠ¨æœºå™¨äºº
            self.robot_pos = [new_x, new_y]
            self.path_history.append(self.robot_pos.copy())

            # è·ç¦»å¥–åŠ±
            if new_dist < old_dist:
                reward += 0.05  # æ¥è¿‘ç›®æ ‡çš„å¥–åŠ±
            else:
                reward -= 0.02  # è¿œç¦»ç›®æ ‡çš„æƒ©ç½š

        else:
            reward -= 0.1  # ç¢°æ’æƒ©ç½š

        # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç›®æ ‡
        done = False
        if tuple(self.robot_pos) == self.goal_pos:
            reward += 10.0  # åˆ°è¾¾ç›®æ ‡çš„å¤§å¥–åŠ±
            done = True

        # æ£€æŸ¥æ˜¯å¦è¢«åŠ¨æ€éšœç¢ç‰©æ’å‡»
        if self.dynamic_map[self.robot_pos[0], self.robot_pos[1]] == 1:
            reward -= 5.0  # è¢«æ’æƒ©ç½š

        # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
        if len(self.path_history) > self.size * 3:
            done = True
            reward -= 1.0  # è¶…æ—¶æƒ©ç½š

        return self.get_state(), reward, done

    def reset(self):
        """é‡ç½®ç¯å¢ƒ"""
        self.robot_pos = list(self.start_pos)
        self.path_history = [self.robot_pos.copy()]

        # é‡æ–°ç”ŸæˆåŠ¨æ€éšœç¢ç‰©
        self.dynamic_obstacles.clear()
        self.generate_dynamic_obstacles()
        self.update_dynamic_obstacles()

        return self.get_state()

class SensorFusionModule:
    """ä¼ æ„Ÿå™¨èåˆæ¨¡å—"""

    def __init__(self, dt=0.1):
        self.dt = dt

        # EKFçŠ¶æ€ï¼š[x, y, vx, vy, theta]
        self.state = np.array([1.0, 1.0, 0.0, 0.0, 0.0])  # åˆå§‹çŠ¶æ€
        self.P = np.eye(5) * 0.1  # åæ–¹å·®çŸ©é˜µ

        # è¿‡ç¨‹å™ªå£°
        self.Q = np.diag([0.01, 0.01, 0.1, 0.1, 0.05])

        # è§‚æµ‹å™ªå£°
        self.R_gps = np.eye(2) * 0.5  # GPSå™ªå£°
        self.R_odom = np.eye(2) * 0.1  # é‡Œç¨‹è®¡å™ªå£°

        # ä¼ æ„Ÿå™¨å™ªå£°å‚æ•°
        self.gps_noise_std = 0.3
        self.odom_noise_std = 0.1

        # å†å²è®°å½•
        self.position_history = []
        self.uncertainty_history = []

    def predict(self, control_input):
        """é¢„æµ‹æ­¥éª¤"""
        # çŠ¶æ€è½¬ç§»çŸ©é˜µ
        F = np.array([
            [1, 0, self.dt, 0, 0],
            [0, 1, 0, self.dt, 0],
            [0, 0, 1, 0, 0],
            [0, 0, 0, 1, 0],
            [0, 0, 0, 0, 1]
        ])

        # æ§åˆ¶è¾“å…¥çŸ©é˜µ
        B = np.array([
            [0.5 * self.dt**2, 0],
            [0, 0.5 * self.dt**2],
            [self.dt, 0],
            [0, self.dt],
            [0, 0]
        ])

        # çŠ¶æ€é¢„æµ‹
        self.state = F @ self.state + B @ control_input

        # åæ–¹å·®é¢„æµ‹
        self.P = F @ self.P @ F.T + self.Q

    def update_gps(self, gps_measurement):
        """GPSæ›´æ–°"""
        # è§‚æµ‹çŸ©é˜µ
        H = np.array([
            [1, 0, 0, 0, 0],
            [0, 1, 0, 0, 0]
        ])

        # æ–°æ¯
        y = gps_measurement - H @ self.state

        # æ–°æ¯åæ–¹å·®
        S = H @ self.P @ H.T + self.R_gps

        # å¡å°”æ›¼å¢ç›Š
        K = self.P @ H.T @ np.linalg.inv(S)

        # çŠ¶æ€æ›´æ–°
        self.state = self.state + K @ y

        # åæ–¹å·®æ›´æ–°
        I = np.eye(len(self.state))
        self.P = (I - K @ H) @ self.P

    def update_odometry(self, odom_measurement):
        """é‡Œç¨‹è®¡æ›´æ–°"""
        # è§‚æµ‹çŸ©é˜µï¼ˆé€Ÿåº¦ï¼‰
        H = np.array([
            [0, 0, 1, 0, 0],
            [0, 0, 0, 1, 0]
        ])

        # æ–°æ¯
        y = odom_measurement - H @ self.state

        # æ–°æ¯åæ–¹å·®
        S = H @ self.P @ H.T + self.R_odom

        # å¡å°”æ›¼å¢ç›Š
        K = self.P @ H.T @ np.linalg.inv(S)

        # çŠ¶æ€æ›´æ–°
        self.state = self.state + K @ y

        # åæ–¹å·®æ›´æ–°
        I = np.eye(len(self.state))
        self.P = (I - K @ H) @ self.P

    def get_position_estimate(self):
        """è·å–ä½ç½®ä¼°è®¡"""
        return self.state[:2].copy()

    def get_uncertainty(self):
        """è·å–ä½ç½®ä¸ç¡®å®šæ€§"""
        return np.sqrt(self.P[0, 0] + self.P[1, 1])

    def simulate_sensors(self, true_pos, true_vel):
        """æ¨¡æ‹Ÿä¼ æ„Ÿå™¨æ•°æ®"""
        # GPSæ•°æ®ï¼ˆå¸¦å™ªå£°ï¼Œå¶å°”ä¸¢å¤±ï¼‰
        gps_available = np.random.random() > 0.1  # 90%å¯ç”¨ç‡
        if gps_available:
            gps_noise = np.random.normal(0, self.gps_noise_std, 2)
            gps_data = true_pos + gps_noise
        else:
            gps_data = None

        # é‡Œç¨‹è®¡æ•°æ®ï¼ˆå¸¦å™ªå£°ï¼‰
        odom_noise = np.random.normal(0, self.odom_noise_std, 2)
        odom_data = true_vel + odom_noise

        return gps_data, odom_data

    def update_sensors(self, true_pos, true_vel):
        """æ›´æ–°ä¼ æ„Ÿå™¨èåˆ"""
        # æ§åˆ¶è¾“å…¥ï¼ˆç®€åŒ–ä¸ºé›¶ï¼‰
        control_input = np.array([0.0, 0.0])

        # é¢„æµ‹
        self.predict(control_input)

        # æ¨¡æ‹Ÿä¼ æ„Ÿå™¨æ•°æ®
        gps_data, odom_data = self.simulate_sensors(true_pos, true_vel)

        # æ›´æ–°
        if gps_data is not None:
            self.update_gps(gps_data)

        self.update_odometry(odom_data)

        # è®°å½•å†å²
        self.position_history.append(self.get_position_estimate())
        self.uncertainty_history.append(self.get_uncertainty())

class DQNNetwork(nn.Module):
    """æ·±åº¦Qç½‘ç»œ"""

    def __init__(self, state_size, action_size, hidden_size=128):
        super(DQNNetwork, self).__init__()

        self.fc1 = nn.Linear(state_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, hidden_size)
        self.fc4 = nn.Linear(hidden_size, action_size)

        self.dropout = nn.Dropout(0.2)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = F.relu(self.fc3(x))
        x = self.fc4(x)
        return x

class IntelligentNavigationAgent:
    """æ™ºèƒ½å¯¼èˆªæ™ºèƒ½ä½“"""

    def __init__(self, state_size, action_size, lr=0.001):
        self.state_size = state_size
        self.action_size = action_size
        self.lr = lr

        # ç¥ç»ç½‘ç»œ
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.q_network = DQNNetwork(state_size, action_size).to(self.device)
        self.target_network = DQNNetwork(state_size, action_size).to(self.device)
        self.optimizer = optim.Adam(self.q_network.parameters(), lr=lr)

        # ç»éªŒå›æ”¾
        self.memory = deque(maxlen=10000)
        self.batch_size = 32

        # æ¢ç´¢å‚æ•°
        self.epsilon = 1.0
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995

        # å…¶ä»–å‚æ•°
        self.gamma = 0.95  # æŠ˜æ‰£å› å­
        self.update_target_freq = 100  # ç›®æ ‡ç½‘ç»œæ›´æ–°é¢‘ç‡
        self.step_count = 0

        # æ€§èƒ½è®°å½•
        self.training_scores = []
        self.training_steps = []
        self.epsilon_history = []

    def choose_action(self, state):
        """é€‰æ‹©åŠ¨ä½œ"""
        if np.random.random() <= self.epsilon:
            return np.random.choice(self.action_size)

        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)
        q_values = self.q_network(state_tensor)
        return q_values.cpu().data.numpy().argmax()

    def remember(self, state, action, reward, next_state, done):
        """å­˜å‚¨ç»éªŒ"""
        self.memory.append((state, action, reward, next_state, done))

    def replay(self):
        """ç»éªŒå›æ”¾å­¦ä¹ """
        if len(self.memory) < self.batch_size:
            return

        batch = random.sample(self.memory, self.batch_size)
        states = torch.FloatTensor([e[0] for e in batch]).to(self.device)
        actions = torch.LongTensor([e[1] for e in batch]).to(self.device)
        rewards = torch.FloatTensor([e[2] for e in batch]).to(self.device)
        next_states = torch.FloatTensor([e[3] for e in batch]).to(self.device)
        dones = torch.BoolTensor([e[4] for e in batch]).to(self.device)

        current_q_values = self.q_network(states).gather(1, actions.unsqueeze(1))
        next_q_values = self.target_network(next_states).max(1)[0].detach()
        target_q_values = rewards + (self.gamma * next_q_values * ~dones)

        loss = F.mse_loss(current_q_values.squeeze(), target_q_values)

        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        # æ›´æ–°æ¢ç´¢ç‡
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay

        self.step_count += 1

        # æ›´æ–°ç›®æ ‡ç½‘ç»œ
        if self.step_count % self.update_target_freq == 0:
            self.target_network.load_state_dict(self.q_network.state_dict())

class IntegratedNavigationSystem:
    """é›†æˆå¯¼èˆªç³»ç»Ÿ"""

    def __init__(self, env_size=20):
        # ç¯å¢ƒ
        self.env = NavigationEnvironment(size=env_size)

        # ä¼ æ„Ÿå™¨èåˆæ¨¡å—
        self.sensor_fusion = SensorFusionModule()

        # å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“
        state_size = len(self.env.get_state())
        action_size = len(self.env.actions)
        self.agent = IntelligentNavigationAgent(state_size, action_size)

        # ç³»ç»ŸçŠ¶æ€
        self.episode_count = 0
        self.total_steps = 0

        # æ€§èƒ½è®°å½•
        self.navigation_results = {
            'episodes': [],
            'scores': [],
            'steps': [],
            'success_rate': [],
            'path_efficiency': [],
            'sensor_fusion_error': [],
            'localization_uncertainty': []
        }

    def train(self, num_episodes=500):
        """è®­ç»ƒå¯¼èˆªç³»ç»Ÿ"""
        print("å¼€å§‹è®­ç»ƒé›†æˆå¯¼èˆªç³»ç»Ÿ...")

        success_window = deque(maxlen=100)

        for episode in range(num_episodes):
            state = self.env.reset()
            total_reward = 0
            steps = 0
            done = False

            # é‡ç½®ä¼ æ„Ÿå™¨èåˆ
            self.sensor_fusion = SensorFusionModule()

            while not done:
                # é€‰æ‹©åŠ¨ä½œ
                action = self.agent.choose_action(state)

                # æ‰§è¡ŒåŠ¨ä½œ
                next_state, reward, done = self.env.step(action)

                # æ›´æ–°ä¼ æ„Ÿå™¨èåˆ
                true_pos = np.array(self.env.robot_pos, dtype=float)
                true_vel = np.array([0.0, 0.0])  # ç®€åŒ–é€Ÿåº¦
                if len(self.env.path_history) > 1:
                    prev_pos = np.array(self.env.path_history[-2], dtype=float)
                    true_vel = (true_pos - prev_pos) / 0.1

                self.sensor_fusion.update_sensors(true_pos, true_vel)

                # è·å–èåˆåçš„ä½ç½®ä¼°è®¡
                estimated_pos = self.sensor_fusion.get_position_estimate()
                uncertainty = self.sensor_fusion.get_uncertainty()

                # å°†èåˆä¿¡æ¯åŠ å…¥åˆ°çŠ¶æ€ä¸­ï¼ˆå¯é€‰ï¼‰
                # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬åªè®°å½•èåˆæ€§èƒ½

                # å­˜å‚¨ç»éªŒ
                self.agent.remember(state, action, reward, next_state, done)

                # å­¦ä¹ 
                self.agent.replay()

                state = next_state
                total_reward += reward
                steps += 1

                if steps > self.env.size * 3:  # é˜²æ­¢æ— é™å¾ªç¯
                    break

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            success = tuple(self.env.robot_pos) == self.env.goal_pos
            success_window.append(success)

            path_length = len(self.env.path_history)
            optimal_path_length = abs(self.env.goal_pos[0] - self.env.start_pos[0]) + \
                                 abs(self.env.goal_pos[1] - self.env.start_pos[1])
            path_efficiency = optimal_path_length / max(path_length, 1)

            # ä¼ æ„Ÿå™¨èåˆè¯¯å·®
            if len(self.sensor_fusion.position_history) > 0:
                true_positions = np.array([[pos[0], pos[1]] for pos in self.env.path_history[1:]])
                estimated_positions = np.array(self.sensor_fusion.position_history)

                min_len = min(len(true_positions), len(estimated_positions))
                if min_len > 0:
                    fusion_error = np.mean(np.linalg.norm(
                        true_positions[:min_len] - estimated_positions[:min_len], axis=1
                    ))
                    avg_uncertainty = np.mean(self.sensor_fusion.uncertainty_history)
                else:
                    fusion_error = 0
                    avg_uncertainty = 0
            else:
                fusion_error = 0
                avg_uncertainty = 0

            # è®°å½•ç»“æœ
            self.navigation_results['episodes'].append(episode)
            self.navigation_results['scores'].append(total_reward)
            self.navigation_results['steps'].append(steps)
            self.navigation_results['success_rate'].append(np.mean(success_window))
            self.navigation_results['path_efficiency'].append(path_efficiency)
            self.navigation_results['sensor_fusion_error'].append(fusion_error)
            self.navigation_results['localization_uncertainty'].append(avg_uncertainty)

            # æ›´æ–°æ™ºèƒ½ä½“è®°å½•
            self.agent.training_scores.append(total_reward)
            self.agent.training_steps.append(steps)
            self.agent.epsilon_history.append(self.agent.epsilon)

            if episode % 50 == 0:
                avg_score = np.mean(self.agent.training_scores[-50:])
                success_rate = np.mean(success_window) * 100
                print(f"Episode {episode}: Avg Score = {avg_score:.2f}, "
                      f"Success Rate = {success_rate:.1f}%, "
                      f"Epsilon = {self.agent.epsilon:.3f}, "
                      f"Fusion Error = {fusion_error:.3f}")

        print("è®­ç»ƒå®Œæˆï¼")
        return self.navigation_results

    def evaluate(self, num_episodes=10):
        """è¯„ä¼°å¯¼èˆªç³»ç»Ÿ"""
        print("è¯„ä¼°å¯¼èˆªç³»ç»Ÿæ€§èƒ½...")

        # ä¸´æ—¶ä¿å­˜æ¢ç´¢ç‡
        original_epsilon = self.agent.epsilon
        self.agent.epsilon = 0  # è¯„ä¼°æ—¶ä¸æ¢ç´¢

        evaluation_results = {
            'success_count': 0,
            'total_episodes': num_episodes,
            'path_lengths': [],
            'fusion_errors': [],
            'trajectories': []
        }

        for episode in range(num_episodes):
            state = self.env.reset()
            done = False
            steps = 0

            # é‡ç½®ä¼ æ„Ÿå™¨èåˆ
            self.sensor_fusion = SensorFusionModule()

            trajectory = {
                'true_path': [],
                'estimated_path': [],
                'uncertainty': []
            }

            while not done and steps < self.env.size * 2:
                action = self.agent.choose_action(state)
                state, reward, done = self.env.step(action)

                # æ›´æ–°ä¼ æ„Ÿå™¨èåˆ
                true_pos = np.array(self.env.robot_pos, dtype=float)
                true_vel = np.array([0.0, 0.0])
                if len(self.env.path_history) > 1:
                    prev_pos = np.array(self.env.path_history[-2], dtype=float)
                    true_vel = (true_pos - prev_pos) / 0.1

                self.sensor_fusion.update_sensors(true_pos, true_vel)

                # è®°å½•è½¨è¿¹
                trajectory['true_path'].append(true_pos.copy())
                trajectory['estimated_path'].append(self.sensor_fusion.get_position_estimate())
                trajectory['uncertainty'].append(self.sensor_fusion.get_uncertainty())

                steps += 1

            # è®°å½•ç»“æœ
            success = tuple(self.env.robot_pos) == self.env.goal_pos
            if success:
                evaluation_results['success_count'] += 1

            evaluation_results['path_lengths'].append(len(self.env.path_history))

            # è®¡ç®—èåˆè¯¯å·®
            if len(trajectory['true_path']) > 0:
                true_path = np.array(trajectory['true_path'])
                est_path = np.array(trajectory['estimated_path'])
                fusion_error = np.mean(np.linalg.norm(true_path - est_path, axis=1))
                evaluation_results['fusion_errors'].append(fusion_error)

            evaluation_results['trajectories'].append(trajectory)

        # æ¢å¤æ¢ç´¢ç‡
        self.agent.epsilon = original_epsilon

        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        success_rate = evaluation_results['success_count'] / num_episodes
        avg_path_length = np.mean(evaluation_results['path_lengths'])
        avg_fusion_error = np.mean(evaluation_results['fusion_errors']) if evaluation_results['fusion_errors'] else 0

        print(f"è¯„ä¼°å®Œæˆ:")
        print(f"æˆåŠŸç‡: {success_rate*100:.1f}%")
        print(f"å¹³å‡è·¯å¾„é•¿åº¦: {avg_path_length:.1f}")
        print(f"å¹³å‡èåˆè¯¯å·®: {avg_fusion_error:.3f}")

        evaluation_results['metrics'] = {
            'success_rate': success_rate,
            'avg_path_length': avg_path_length,
            'avg_fusion_error': avg_fusion_error
        }

        return evaluation_results

class SystemVisualizer:
    """ç³»ç»Ÿå¯è§†åŒ–å™¨"""

    def __init__(self, navigation_system, training_results, evaluation_results):
        self.system = navigation_system
        self.training_results = training_results
        self.evaluation_results = evaluation_results

        # åˆ›å»ºç»“æœç›®å½•
        self.results_dir = "results"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # åˆå§‹åŒ–æ—¶å†æ¬¡è®¾ç½®å­—ä½“
        self._setup_fonts()
        
    def _setup_fonts(self):
        """ç¡®ä¿åœ¨ç»˜å›¾æ—¶æ­£ç¡®è®¾ç½®å­—ä½“"""
        # è¿™é‡Œå†æ¬¡è°ƒç”¨å­—ä½“è®¾ç½®å‡½æ•°ï¼Œç¡®ä¿åœ¨åˆ›å»ºæ¯ä¸ªå›¾è¡¨å‰å­—ä½“è®¾ç½®æ­£ç¡®
        setup_chinese_fonts()

    def plot_training_progress(self):
        """ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹"""
        # ç»˜å›¾å‰å†æ¬¡ç¡®è®¤å­—ä½“è®¾ç½®
        self._setup_fonts()
        plt.figure(figsize=(15, 12))

        episodes = self.training_results['episodes']

        # è®­ç»ƒåˆ†æ•°
        plt.subplot(3, 2, 1)
        scores = self.training_results['scores']
        plt.plot(episodes, scores, alpha=0.3, color='blue')
        # ç§»åŠ¨å¹³å‡
        window = 50
        if len(scores) >= window:
            moving_avg = np.convolve(scores, np.ones(window)/window, mode='valid')
            plt.plot(episodes[window-1:], moving_avg, 'r-', linewidth=2, label='ç§»åŠ¨å¹³å‡')
        plt.xlabel('Episode')
        plt.ylabel('ç´¯ç§¯å¥–åŠ±')
        plt.title('è®­ç»ƒåˆ†æ•°å˜åŒ–')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # æˆåŠŸç‡
        plt.subplot(3, 2, 2)
        success_rates = [rate * 100 for rate in self.training_results['success_rate']]
        plt.plot(episodes, success_rates, 'g-', linewidth=2)
        plt.xlabel('Episode')
        plt.ylabel('æˆåŠŸç‡ (%)')
        plt.title('ä»»åŠ¡æˆåŠŸç‡')
        plt.grid(True, alpha=0.3)

        # è·¯å¾„æ•ˆç‡
        plt.subplot(3, 2, 3)
        efficiency = self.training_results['path_efficiency']
        plt.plot(episodes, efficiency, 'orange', alpha=0.7)
        plt.xlabel('Episode')
        plt.ylabel('è·¯å¾„æ•ˆç‡')
        plt.title('è·¯å¾„è§„åˆ’æ•ˆç‡')
        plt.grid(True, alpha=0.3)

        # æ¢ç´¢ç‡
        plt.subplot(3, 2, 4)
        epsilon_history = self.system.agent.epsilon_history
        plt.plot(episodes, epsilon_history, 'purple', linewidth=2)
        plt.xlabel('Episode')
        plt.ylabel('æ¢ç´¢ç‡ (Îµ)')
        plt.title('æ¢ç´¢ç­–ç•¥å˜åŒ–')
        plt.grid(True, alpha=0.3)

        # ä¼ æ„Ÿå™¨èåˆè¯¯å·®
        plt.subplot(3, 2, 5)
        fusion_errors = self.training_results['sensor_fusion_error']
        plt.plot(episodes, fusion_errors, 'red', alpha=0.7)
        plt.xlabel('Episode')
        plt.ylabel('å®šä½è¯¯å·®')
        plt.title('ä¼ æ„Ÿå™¨èåˆæ€§èƒ½')
        plt.grid(True, alpha=0.3)

        # å®šä½ä¸ç¡®å®šæ€§
        plt.subplot(3, 2, 6)
        uncertainty = self.training_results['localization_uncertainty']
        plt.plot(episodes, uncertainty, 'brown', alpha=0.7)
        plt.xlabel('Episode')
        plt.ylabel('ä¸ç¡®å®šæ€§')
        plt.title('å®šä½ä¸ç¡®å®šæ€§å˜åŒ–')
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/training_progress.png', dpi=300, bbox_inches='tight')
        plt.close()

    def plot_evaluation_results(self):
        """ç»˜åˆ¶è¯„ä¼°ç»“æœ"""
        # ç»˜å›¾å‰å†æ¬¡ç¡®è®¤å­—ä½“è®¾ç½®
        self._setup_fonts()
        plt.figure(figsize=(15, 10))

        # é€‰æ‹©ä¸€ä¸ªæˆåŠŸçš„è½¨è¿¹è¿›è¡Œå¯è§†åŒ–
        best_trajectory = None
        best_episode = -1

        for i, traj in enumerate(self.evaluation_results['trajectories']):
            if len(traj['true_path']) > 0:
                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç›®æ ‡
                final_pos = traj['true_path'][-1]
                goal_pos = np.array(self.system.env.goal_pos)
                if np.linalg.norm(final_pos - goal_pos) < 1.5:
                    best_trajectory = traj
                    best_episode = i
                    break

        if best_trajectory is None and self.evaluation_results['trajectories']:
            best_trajectory = self.evaluation_results['trajectories'][0]
            best_episode = 0

        if best_trajectory:
            # è½¨è¿¹å¯¹æ¯”
            plt.subplot(2, 3, 1)
            true_path = np.array(best_trajectory['true_path'])
            est_path = np.array(best_trajectory['estimated_path'])

            plt.plot(true_path[:, 0], true_path[:, 1], 'b-', linewidth=2,
                    label='çœŸå®è½¨è¿¹', alpha=0.8)
            plt.plot(est_path[:, 0], est_path[:, 1], 'r--', linewidth=2,
                    label='èåˆä¼°è®¡', alpha=0.8)

            # æ ‡è®°èµ·ç‚¹å’Œç»ˆç‚¹
            plt.scatter(*self.system.env.start_pos, color='green', s=100,
                       marker='o', label='èµ·ç‚¹', zorder=5)
            plt.scatter(*self.system.env.goal_pos, color='red', s=100,
                       marker='*', label='ç»ˆç‚¹', zorder=5)

            plt.xlabel('X åæ ‡')
            plt.ylabel('Y åæ ‡')
            plt.title(f'è½¨è¿¹å¯¹æ¯” (Episode {best_episode})')
            plt.legend()
            plt.grid(True, alpha=0.3)
            plt.axis('equal')

        # ç¯å¢ƒåœ°å›¾
        plt.subplot(2, 3, 2)
        env_map = self.system.env.static_map + self.system.env.dynamic_map
        plt.imshow(env_map, cmap='gray_r', origin='lower')
        plt.colorbar(label='éšœç¢ç‰©')
        plt.title('ç¯å¢ƒåœ°å›¾')
        plt.xlabel('X åæ ‡')
        plt.ylabel('Y åæ ‡')

        # æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”
        plt.subplot(2, 3, 3)
        metrics = ['æˆåŠŸç‡', 'å¹³å‡è·¯å¾„é•¿åº¦', 'å¹³å‡èåˆè¯¯å·®']
        values = [
            self.evaluation_results['metrics']['success_rate'] * 100,
            self.evaluation_results['metrics']['avg_path_length'],
            self.evaluation_results['metrics']['avg_fusion_error'] * 10  # ç¼©æ”¾ä»¥ä¾¿æ˜¾ç¤º
        ]
        colors = ['green', 'blue', 'red']

        bars = plt.bar(metrics, values, color=colors, alpha=0.7)
        plt.ylabel('æŒ‡æ ‡å€¼')
        plt.title('è¯„ä¼°æ€§èƒ½æŒ‡æ ‡')
        plt.xticks(rotation=45)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, values):
            if 'Error' in metrics[values.index(value)]:
                label = f'{value/10:.3f}'  # è¿˜åŸç¼©æ”¾
            elif 'Success' in metrics[values.index(value)]:
                label = f'{value:.1f}%'
            else:
                label = f'{value:.1f}'
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                    label, ha='center', va='bottom')

        if best_trajectory:
            # å®šä½è¯¯å·®éšæ—¶é—´å˜åŒ–
            plt.subplot(2, 3, 4)
            true_path = np.array(best_trajectory['true_path'])
            est_path = np.array(best_trajectory['estimated_path'])
            errors = np.linalg.norm(true_path - est_path, axis=1)

            plt.plot(errors, 'r-', linewidth=2, label='å®šä½è¯¯å·®')
            plt.fill_between(range(len(errors)), 0, best_trajectory['uncertainty'],
                           alpha=0.3, color='gray', label='ä¸ç¡®å®šæ€§')
            plt.xlabel('æ—¶é—´æ­¥')
            plt.ylabel('è¯¯å·® / ä¸ç¡®å®šæ€§')
            plt.title('å®šä½æ€§èƒ½åˆ†æ')
            plt.legend()
            plt.grid(True, alpha=0.3)

        # è·¯å¾„é•¿åº¦åˆ†å¸ƒ
        plt.subplot(2, 3, 5)
        path_lengths = self.evaluation_results['path_lengths']
        plt.hist(path_lengths, bins=10, alpha=0.7, color='blue', edgecolor='black')
        plt.axvline(np.mean(path_lengths), color='red', linestyle='--',
                   label=f'å¹³å‡å€¼: {np.mean(path_lengths):.1f}')
        plt.xlabel('è·¯å¾„é•¿åº¦')
        plt.ylabel('é¢‘æ¬¡')
        plt.title('è·¯å¾„é•¿åº¦åˆ†å¸ƒ')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # èåˆè¯¯å·®åˆ†å¸ƒ
        plt.subplot(2, 3, 6)
        fusion_errors = self.evaluation_results['fusion_errors']
        if fusion_errors:
            plt.hist(fusion_errors, bins=10, alpha=0.7, color='orange', edgecolor='black')
            plt.axvline(np.mean(fusion_errors), color='red', linestyle='--',
                       label=f'å¹³å‡å€¼: {np.mean(fusion_errors):.3f}')
            plt.xlabel('èåˆè¯¯å·®')
            plt.ylabel('é¢‘æ¬¡')
            plt.title('ä¼ æ„Ÿå™¨èåˆè¯¯å·®åˆ†å¸ƒ')
            plt.legend()
            plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/evaluation_results.png', dpi=300, bbox_inches='tight')
        plt.close()

    def plot_system_integration(self):
        """ç»˜åˆ¶ç³»ç»Ÿé›†æˆåˆ†æ"""
        # ç»˜å›¾å‰å†æ¬¡ç¡®è®¤å­—ä½“è®¾ç½®
        self._setup_fonts()
        plt.figure(figsize=(12, 8))

        # å¼ºåŒ–å­¦ä¹ vsä¼ æ„Ÿå™¨èåˆæ€§èƒ½å…³ç³»
        plt.subplot(2, 2, 1)
        episodes = self.training_results['episodes']
        rl_performance = np.array(self.training_results['success_rate'])
        fusion_performance = 1.0 / (1.0 + np.array(self.training_results['sensor_fusion_error']))

        plt.scatter(rl_performance, fusion_performance, alpha=0.6, c=episodes,
                   cmap='viridis', s=20)
        plt.colorbar(label='Training Episode')
        plt.xlabel('å¼ºåŒ–å­¦ä¹ æˆåŠŸç‡')
        plt.ylabel('ä¼ æ„Ÿå™¨èåˆæ€§èƒ½')
        plt.title('RLä¸ä¼ æ„Ÿå™¨èåˆæ€§èƒ½å…³ç³»')
        plt.grid(True, alpha=0.3)

        # ç»¼åˆæ€§èƒ½æŒ‡æ ‡
        plt.subplot(2, 2, 2)
        ç»¼åˆæ€§èƒ½ = (np.array(self.training_results['success_rate']) *
                np.array(self.training_results['path_efficiency']) *
                fusion_performance)

        plt.plot(episodes, ç»¼åˆæ€§èƒ½, 'purple', linewidth=2)
        plt.xlabel('Episode')
        plt.ylabel('ç»¼åˆæ€§èƒ½æŒ‡æ ‡')
        plt.title('ç³»ç»Ÿç»¼åˆæ€§èƒ½')
        plt.grid(True, alpha=0.3)

        # å„ç»„ä»¶è´¡çŒ®åº¦åˆ†æ
        plt.subplot(2, 2, 3)
        æœ€å100ä¸ª_episodes = episodes[-100:] if len(episodes) >= 100 else episodes
        æœ€å100ä¸ª_success = self.training_results['success_rate'][-100:] if len(episodes) >= 100 else self.training_results['success_rate']
        æœ€å100ä¸ª_fusion = fusion_performance[-100:] if len(episodes) >= 100 else fusion_performance

        components = ['å¼ºåŒ–å­¦ä¹ ', 'ä¼ æ„Ÿå™¨èåˆ', 'ç³»ç»Ÿé›†æˆ']
        contributions = [
            np.mean(æœ€å100ä¸ª_success) * 100,
            np.mean(æœ€å100ä¸ª_fusion) * 100,
            np.mean(ç»¼åˆæ€§èƒ½[-100:]) * 100 if len(episodes) >= 100 else np.mean(ç»¼åˆæ€§èƒ½) * 100
        ]
        colors = ['blue', 'orange', 'green']

        bars = plt.bar(components, contributions, color=colors, alpha=0.7)
        plt.ylabel('æ€§èƒ½è´¡çŒ®åº¦ (%)')
        plt.title('å„ç»„ä»¶æ€§èƒ½è´¡çŒ®')
        plt.xticks(rotation=45)

        for bar, value in zip(bars, contributions):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                    f'{value:.1f}%', ha='center', va='bottom')

        # å­¦ä¹ æ›²çº¿æ”¶æ•›åˆ†æ
        plt.subplot(2, 2, 4)
        window = 20
        if len(self.training_results['scores']) >= window:
            scores = np.array(self.training_results['scores'])
            convergence = np.convolve(scores, np.ones(window)/window, mode='valid')
            convergence_episodes = episodes[window-1:]

            plt.plot(convergence_episodes, convergence, 'red', linewidth=2, label='æ”¶æ•›æ›²çº¿')

            # æ‰¾åˆ°æ”¶æ•›ç‚¹ï¼ˆå˜åŒ–ç‡å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
            if len(convergence) > 50:
                gradient = np.gradient(convergence)
                converged_idx = None
                for i in range(50, len(gradient)):
                    if abs(gradient[i]) < 0.01:  # æ”¶æ•›é˜ˆå€¼
                        converged_idx = i
                        break

                if converged_idx:
                    plt.axvline(convergence_episodes[converged_idx], color='green',
                               linestyle='--', label=f'æ”¶æ•›ç‚¹: Episode {convergence_episodes[converged_idx]:.0f}')

            plt.xlabel('Episode')
            plt.ylabel('å¹³å‡å¥–åŠ±')
            plt.title('å­¦ä¹ æ”¶æ•›åˆ†æ')
            plt.legend()
            plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f'{self.results_dir}/system_integration.png', dpi=300, bbox_inches='tight')
        plt.close()

class ComprehensiveReportGenerator:
    """ç»¼åˆæŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, navigation_system, training_results, evaluation_results):
        self.system = navigation_system
        self.training_results = training_results
        self.evaluation_results = evaluation_results
        self.results_dir = "results"
        
        # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
        os.makedirs(self.results_dir, exist_ok=True)

    def generate_report(self):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""

        # è®¡ç®—å…³é”®æŒ‡æ ‡
        final_success_rate = self.training_results['success_rate'][-1] * 100
        avg_fusion_error = np.mean(self.training_results['sensor_fusion_error'][-50:])
        eval_success_rate = self.evaluation_results['metrics']['success_rate'] * 100
        eval_fusion_error = self.evaluation_results['metrics']['avg_fusion_error']

        # æ”¶æ•›åˆ†æ
        convergence_episode = "æœªæ”¶æ•›"
        if len(self.training_results['success_rate']) > 100:
            success_rates = self.training_results['success_rate'][-100:]
            if np.mean(success_rates) > 0.8:  # 80%ä»¥ä¸Šè®¤ä¸ºæ”¶æ•›
                convergence_episode = len(self.training_results['episodes']) - 100

        report = f"""
æ™ºèƒ½å¯¼èˆªç»¼åˆç³»ç»Ÿåˆ†ææŠ¥å‘Š
========================
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ç³»ç»Ÿæ¦‚è¿°
--------
æœ¬æŠ¥å‘Šå±•ç¤ºäº†ä¸€ä¸ªé›†æˆå¼ºåŒ–å­¦ä¹ ä¸ä¼ æ„Ÿå™¨èåˆæŠ€æœ¯çš„æ™ºèƒ½æœºå™¨äººå¯¼èˆªç³»ç»Ÿã€‚
ç³»ç»Ÿç»“åˆäº†æ·±åº¦Qç½‘ç»œ(DQN)çš„è·¯å¾„è§„åˆ’èƒ½åŠ›å’Œæ‰©å±•å¡å°”æ›¼æ»¤æ³¢å™¨(EKF)çš„
ç²¾ç¡®å®šä½èƒ½åŠ›ï¼Œå®ç°äº†å¤æ‚åŠ¨æ€ç¯å¢ƒä¸‹çš„è‡ªä¸»å¯¼èˆªã€‚

ç³»ç»Ÿæ¶æ„
--------
1. ç¯å¢ƒæ¨¡å—
   - ç½‘æ ¼ä¸–ç•Œç¯å¢ƒ ({self.system.env.size}x{self.system.env.size})
   - é™æ€éšœç¢ç‰©æ•°é‡: {self.system.env.num_obstacles}
   - åŠ¨æ€éšœç¢ç‰©æ•°é‡: {self.system.env.num_dynamic_obstacles}
   - èµ·ç‚¹: {self.system.env.start_pos}
   - ç»ˆç‚¹: {self.system.env.goal_pos}

2. å¼ºåŒ–å­¦ä¹ æ¨¡å—
   - ç®—æ³•: æ·±åº¦Qç½‘ç»œ (DQN)
   - çŠ¶æ€ç©ºé—´ç»´åº¦: {self.system.agent.state_size}
   - åŠ¨ä½œç©ºé—´å¤§å°: {self.system.agent.action_size}
   - ç¥ç»ç½‘ç»œå±‚æ•°: 4å±‚å…¨è¿æ¥ç½‘ç»œ
   - ç»éªŒå›æ”¾ç¼“å†²åŒº: {self.system.agent.memory.maxlen}

3. ä¼ æ„Ÿå™¨èåˆæ¨¡å—
   - ç®—æ³•: æ‰©å±•å¡å°”æ›¼æ»¤æ³¢å™¨ (EKF)
   - çŠ¶æ€å‘é‡: [x, y, vx, vy, Î¸]
   - ä¼ æ„Ÿå™¨ç±»å‹: GPS + é‡Œç¨‹è®¡
   - GPSå™ªå£°æ ‡å‡†å·®: {self.system.sensor_fusion.gps_noise_std}
   - é‡Œç¨‹è®¡å™ªå£°æ ‡å‡†å·®: {self.system.sensor_fusion.odom_noise_std}

è®­ç»ƒç»“æœ
--------
è®­ç»ƒé…ç½®:
  - è®­ç»ƒè½®æ•°: {len(self.training_results['episodes'])}
  - æœ€ç»ˆæˆåŠŸç‡: {final_success_rate:.1f}%
  - æ”¶æ•›è½®æ•°: {convergence_episode}
  - æœ€ç»ˆæ¢ç´¢ç‡: {self.system.agent.epsilon:.3f}

æ€§èƒ½æŒ‡æ ‡:
  - æœ€ç»ˆ50è½®å¹³å‡å¥–åŠ±: {np.mean(self.training_results['scores'][-50:]):.2f}
  - æœ€ç»ˆè·¯å¾„æ•ˆç‡: {np.mean(self.training_results['path_efficiency'][-50:]):.3f}
  - å¹³å‡ä¼ æ„Ÿå™¨èåˆè¯¯å·®: {avg_fusion_error:.4f}
  - å¹³å‡å®šä½ä¸ç¡®å®šæ€§: {np.mean(self.training_results['localization_uncertainty'][-50:]):.4f}

è¯„ä¼°ç»“æœ
--------
è¯„ä¼°é…ç½®:
  - è¯„ä¼°è½®æ•°: {self.evaluation_results['total_episodes']}
  - æµ‹è¯•æ¨¡å¼: æ— æ¢ç´¢ (Îµ = 0)

å…³é”®æŒ‡æ ‡:
  - æœ€ç»ˆæˆåŠŸç‡: {eval_success_rate:.1f}%
  - å¹³å‡è·¯å¾„é•¿åº¦: {self.evaluation_results['metrics']['avg_path_length']:.1f}
  - å¹³å‡ä¼ æ„Ÿå™¨èåˆè¯¯å·®: {eval_fusion_error:.4f}
  - è·¯å¾„é•¿åº¦æ ‡å‡†å·®: {np.std(self.evaluation_results['path_lengths']):.2f}

ç³»ç»Ÿé›†æˆæ•ˆæœ
----------
1. å¼ºåŒ–å­¦ä¹ ç»„ä»¶è¡¨ç°: {'ä¼˜ç§€' if eval_success_rate > 80 else 'è‰¯å¥½' if eval_success_rate > 60 else 'ä¸€èˆ¬'}
   - åœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­å®ç°äº† {eval_success_rate:.1f}% çš„ä»»åŠ¡æˆåŠŸç‡
   - èƒ½å¤Ÿå­¦ä¼šé¿å¼€é™æ€å’ŒåŠ¨æ€éšœç¢ç‰©
   - è·¯å¾„è§„åˆ’å…·æœ‰è‰¯å¥½çš„é€‚åº”æ€§

2. ä¼ æ„Ÿå™¨èåˆç»„ä»¶è¡¨ç°: {'ä¼˜ç§€' if eval_fusion_error < 0.1 else 'è‰¯å¥½' if eval_fusion_error < 0.2 else 'ä¸€èˆ¬'}
   - å®ç°äº† {eval_fusion_error:.4f} çš„å¹³å‡å®šä½è¯¯å·®
   - æˆåŠŸèåˆGPSå’Œé‡Œç¨‹è®¡æ•°æ®
   - åœ¨GPSä¿¡å·ä¸¢å¤±æ—¶ä¿æŒå®šä½ç²¾åº¦

3. ç³»ç»Ÿç»¼åˆè¡¨ç°: {'ä¼˜ç§€' if eval_success_rate > 80 and eval_fusion_error < 0.1 else 'è‰¯å¥½'}
   - ä¸¤ä¸ªå­ç³»ç»ŸååŒå·¥ä½œè‰¯å¥½
   - ç²¾ç¡®å®šä½æ”¯æŒäº†æœ‰æ•ˆçš„è·¯å¾„è§„åˆ’
   - ç³»ç»Ÿæ•´ä½“é²æ£’æ€§å¼º

æŠ€æœ¯äº®ç‚¹
--------
1. å¤šä¼ æ„Ÿå™¨æ•°æ®èåˆ
   - å®ç°äº†GPSå’Œé‡Œç¨‹è®¡çš„æœ‰æ•ˆèåˆ
   - é€šè¿‡EKFç®—æ³•å¤„ç†ä¼ æ„Ÿå™¨ä¸ç¡®å®šæ€§
   - æä¾›å®æ—¶çš„ä½ç½®ä¼°è®¡å’Œä¸ç¡®å®šæ€§é‡åŒ–

2. æ·±åº¦å¼ºåŒ–å­¦ä¹ 
   - ä½¿ç”¨DQNç®—æ³•å®ç°æ™ºèƒ½è·¯å¾„è§„åˆ’
   - é€šè¿‡ç»éªŒå›æ”¾æé«˜å­¦ä¹ æ•ˆç‡
   - è‡ªé€‚åº”æ¢ç´¢ç­–ç•¥å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨

3. åŠ¨æ€ç¯å¢ƒé€‚åº”
   - èƒ½å¤Ÿå¤„ç†é™æ€å’ŒåŠ¨æ€éšœç¢ç‰©
   - å®æ—¶é‡æ–°è§„åˆ’è·¯å¾„
   - å¯¹ç¯å¢ƒå˜åŒ–å…·æœ‰è‰¯å¥½çš„é²æ£’æ€§

4. ç³»ç»Ÿé›†æˆ
   - å¼ºåŒ–å­¦ä¹ ä¸ä¼ æ„Ÿå™¨èåˆæ— ç¼é›†æˆ
   - æ¨¡å—åŒ–è®¾è®¡ä¾¿äºæ‰©å±•å’Œç»´æŠ¤
   - å®æ—¶æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

æ€§èƒ½å¯¹æ¯”åˆ†æ
----------
ç›¸æ¯”å•ä¸€æŠ€æœ¯çš„ä¼˜åŠ¿:
1. vs çº¯å¼ºåŒ–å­¦ä¹ :
   - å®šä½ç²¾åº¦æå‡çº¦ {(2.0 - eval_fusion_error) / 2.0 * 100:.1f}%
   - è·¯å¾„è§„åˆ’æ›´åŠ ç²¾ç¡®
   - å‡å°‘äº†ç”±äºå®šä½è¯¯å·®å¯¼è‡´çš„å¤±è´¥

2. vs çº¯ä¼ æ„Ÿå™¨èåˆ:
   - å¢åŠ äº†æ™ºèƒ½å†³ç­–èƒ½åŠ›
   - èƒ½å¤Ÿå¤„ç†å¤æ‚çš„è·¯å¾„è§„åˆ’é—®é¢˜
   - é€‚åº”åŠ¨æ€ç¯å¢ƒå˜åŒ–

3. vs ä¼ ç»Ÿå¯¼èˆªæ–¹æ³•:
   - å­¦ä¹ èƒ½åŠ›å¼ºï¼Œèƒ½å¤Ÿé€‚åº”æ–°ç¯å¢ƒ
   - ä¸éœ€è¦é¢„å…ˆå»ºç«‹è¯¦ç»†åœ°å›¾
   - å¯¹ä¼ æ„Ÿå™¨æ•…éšœå…·æœ‰é²æ£’æ€§

åº”ç”¨å‰æ™¯
--------
æœ¬ç³»ç»Ÿå¯åº”ç”¨äº:
1. è‡ªä¸»ç§»åŠ¨æœºå™¨äººå¯¼èˆª
2. æ— äººé©¾é©¶è½¦è¾†è·¯å¾„è§„åˆ’
3. æ— äººæœºè‡ªä¸»é£è¡Œæ§åˆ¶
4. æœåŠ¡æœºå™¨äººå®¤å†…å¯¼èˆª
5. å·¥ä¸šè‡ªåŠ¨åŒ–è¿è¾“ç³»ç»Ÿ

æ”¹è¿›å»ºè®®
--------
1. ç®—æ³•ä¼˜åŒ–:
   - è€ƒè™‘ä½¿ç”¨PPOæˆ–SACç­‰æ›´å…ˆè¿›çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•
   - å®ç°æ— è¿¹å¡å°”æ›¼æ»¤æ³¢å™¨(UKF)å¤„ç†å¼ºéçº¿æ€§
   - æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶æé«˜ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›

2. ä¼ æ„Ÿå™¨æ‰©å±•:
   - é›†æˆæ¿€å…‰é›·è¾¾è¿›è¡ŒSLAM
   - æ·»åŠ è§†è§‰ä¼ æ„Ÿå™¨æä¾›ä¸°å¯Œç¯å¢ƒä¿¡æ¯
   - å®ç°å¤šæ¨¡æ€ä¼ æ„Ÿå™¨èåˆ

3. ç³»ç»Ÿä¼˜åŒ–:
   - å®ç°åˆ†å¸ƒå¼è®¡ç®—æé«˜å®æ—¶æ€§
   - æ·»åŠ é¢„æµ‹æ¨¡å‹å¤„ç†åŠ¨æ€éšœç¢ç‰©
   - å®ç°åœ¨çº¿å­¦ä¹ é€‚åº”æ–°ç¯å¢ƒ

å®éªŒæ•°æ®æ–‡ä»¶
----------
- training_progress.png: è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–
- evaluation_results.png: è¯„ä¼°ç»“æœåˆ†æ
- system_integration.png: ç³»ç»Ÿé›†æˆåˆ†æ
- navigation_report.txt: æœ¬æŠ¥å‘Šæ–‡ä»¶
- results_data.json: è¯¦ç»†å®éªŒæ•°æ®

ç»“è®º
----
æœ¬æ¬¡å®éªŒæˆåŠŸå®ç°äº†å¼ºåŒ–å­¦ä¹ ä¸ä¼ æ„Ÿå™¨èåˆæŠ€æœ¯çš„æ·±åº¦é›†æˆï¼Œæ„å»ºäº†
ä¸€ä¸ªé«˜æ€§èƒ½çš„æ™ºèƒ½å¯¼èˆªç³»ç»Ÿã€‚å®éªŒç»“æœè¡¨æ˜:

1. ç³»ç»Ÿåœ¨å¤æ‚åŠ¨æ€ç¯å¢ƒä¸­å®ç°äº† {eval_success_rate:.1f}% çš„é«˜æˆåŠŸç‡
2. ä¼ æ„Ÿå™¨èåˆæ˜¾è‘—æé«˜äº†å®šä½ç²¾åº¦ï¼ˆè¯¯å·® {eval_fusion_error:.4f}ï¼‰
3. å¼ºåŒ–å­¦ä¹ ç®—æ³•æˆåŠŸå­¦ä¼šäº†å¤æ‚çš„å¯¼èˆªç­–ç•¥
4. ä¸¤ä¸ªå­ç³»ç»Ÿçš„é›†æˆäº§ç”Ÿäº†ååŒæ•ˆåº”

è¯¥ç³»ç»Ÿä¸ºæ™ºèƒ½æœºå™¨äººå¯¼èˆªæä¾›äº†ä¸€ä¸ªæœ‰æ•ˆçš„æŠ€æœ¯è§£å†³æ–¹æ¡ˆï¼Œå…·æœ‰
è‰¯å¥½çš„åº”ç”¨å‰æ™¯å’Œè¿›ä¸€æ­¥å‘å±•çš„æ½œåŠ›ã€‚

æŠ¥å‘Šç”Ÿæˆå®Œæ¯•ã€‚
================================================================
"""

        # ç¡®ä¿ä½¿ç”¨UTF-8ç¼–ç ä¿å­˜æŠ¥å‘Š
        with open(f'{self.results_dir}/navigation_report.txt', 'w', encoding='utf-8') as f:
            f.write(report)

        # ä¿å­˜è¯¦ç»†æ•°æ®
        detailed_data = {
            'training_results': {
                'episodes': self.training_results['episodes'],
                'scores': self.training_results['scores'],
                'success_rate': self.training_results['success_rate'],
                'sensor_fusion_error': self.training_results['sensor_fusion_error']
            },
            'evaluation_results': {
                'metrics': self.evaluation_results['metrics'],
                'path_lengths': self.evaluation_results['path_lengths'],
                'fusion_errors': self.evaluation_results['fusion_errors']
            },
            'system_config': {
                'env_size': self.system.env.size,
                'num_obstacles': self.system.env.num_obstacles,
                'state_size': self.system.agent.state_size,
                'action_size': self.system.agent.action_size
            }
        }

        # ç¡®ä¿JSONæ–‡ä»¶ä¹Ÿä½¿ç”¨UTF-8ç¼–ç å¹¶ä¿ç•™ä¸­æ–‡å­—ç¬¦
        with open(f'{self.results_dir}/results_data.json', 'w', encoding='utf-8') as f:
            json.dump(detailed_data, f, indent=2, ensure_ascii=False)

        print("ç»¼åˆåˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
        return report

def main():
    """ä¸»å‡½æ•°ï¼šå®Œæ•´çš„æ™ºèƒ½å¯¼èˆªç³»ç»Ÿæ¼”ç¤º"""
    print("=" * 60)
    print("æ™ºèƒ½å¯¼èˆªç»¼åˆç³»ç»Ÿæ¼”ç¤ºé¡¹ç›®")
    print("=" * 60)
    print("æœ¬é¡¹ç›®é›†æˆäº†å¼ºåŒ–å­¦ä¹ ä¸ä¼ æ„Ÿå™¨èåˆæŠ€æœ¯")
    print("å®ç°å¤æ‚ç¯å¢ƒä¸‹çš„è‡ªä¸»æœºå™¨äººå¯¼èˆª")
    print("=" * 60)

    # æ­¥éª¤1ï¼šåˆå§‹åŒ–ç³»ç»Ÿ
    print("\næ­¥éª¤1: åˆå§‹åŒ–æ™ºèƒ½å¯¼èˆªç³»ç»Ÿ...")
    navigation_system = IntegratedNavigationSystem(env_size=20)
    print("âœ“ ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
    print("âœ“ å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“å‡†å¤‡å°±ç»ª")
    print("âœ“ ä¼ æ„Ÿå™¨èåˆæ¨¡å—å¯åŠ¨")

    # æ­¥éª¤2ï¼šè®­ç»ƒç³»ç»Ÿ
    print("\næ­¥éª¤2: è®­ç»ƒæ™ºèƒ½å¯¼èˆªç³»ç»Ÿ...")
    training_results = navigation_system.train(num_episodes=500)

    final_success_rate = training_results['success_rate'][-1] * 100
    final_fusion_error = training_results['sensor_fusion_error'][-1]

    print(f"âœ“ è®­ç»ƒå®Œæˆ!")
    print(f"  æœ€ç»ˆæˆåŠŸç‡: {final_success_rate:.1f}%")
    print(f"  æœ€ç»ˆèåˆè¯¯å·®: {final_fusion_error:.4f}")
    print(f"  æœ€ç»ˆæ¢ç´¢ç‡: {navigation_system.agent.epsilon:.3f}")

    # æ­¥éª¤3ï¼šè¯„ä¼°ç³»ç»Ÿ
    print("\næ­¥éª¤3: è¯„ä¼°ç³»ç»Ÿæ€§èƒ½...")
    evaluation_results = navigation_system.evaluate(num_episodes=20)

    eval_success_rate = evaluation_results['metrics']['success_rate'] * 100
    eval_fusion_error = evaluation_results['metrics']['avg_fusion_error']

    print(f"âœ“ è¯„ä¼°å®Œæˆ!")
    print(f"  è¯„ä¼°æˆåŠŸç‡: {eval_success_rate:.1f}%")
    print(f"  å¹³å‡èåˆè¯¯å·®: {eval_fusion_error:.4f}")
    print(f"  å¹³å‡è·¯å¾„é•¿åº¦: {evaluation_results['metrics']['avg_path_length']:.1f}")

    # æ­¥éª¤4ï¼šç”Ÿæˆå¯è§†åŒ–
    print("\næ­¥éª¤4: ç”Ÿæˆå¯è§†åŒ–åˆ†æ...")
    visualizer = SystemVisualizer(navigation_system, training_results, evaluation_results)
    visualizer.plot_training_progress()
    visualizer.plot_evaluation_results()
    visualizer.plot_system_integration()
    print("âœ“ å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆ")

    # æ­¥éª¤5ï¼šç”Ÿæˆç»¼åˆæŠ¥å‘Š
    print("\næ­¥éª¤5: ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...")
    report_generator = ComprehensiveReportGenerator(
        navigation_system, training_results, evaluation_results
    )
    report = report_generator.generate_report()
    print("âœ“ ç»¼åˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")

    # æœ€ç»ˆæ€»ç»“
    print("\n" + "=" * 60)
    print("æ™ºèƒ½å¯¼èˆªç»¼åˆç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)

    print(f"\nğŸ“Š æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡:")
    print(f"   å¼ºåŒ–å­¦ä¹ æˆåŠŸç‡: {eval_success_rate:.1f}%")
    print(f"   ä¼ æ„Ÿå™¨èåˆç²¾åº¦: {(1-eval_fusion_error)*100:.1f}%")
    print(f"   ç³»ç»Ÿç»¼åˆå¾—åˆ†: {(eval_success_rate + (1-eval_fusion_error)*100)/2:.1f}%")

    print(f"\nğŸ“ ç”Ÿæˆæ–‡ä»¶:")
    print(f"   results/training_progress.png - è®­ç»ƒè¿‡ç¨‹åˆ†æ")
    print(f"   results/evaluation_results.png - è¯„ä¼°ç»“æœåˆ†æ")
    print(f"   results/system_integration.png - ç³»ç»Ÿé›†æˆåˆ†æ")
    print(f"   results/navigation_report.txt - ç»¼åˆåˆ†ææŠ¥å‘Š")
    print(f"   results/results_data.json - è¯¦ç»†å®éªŒæ•°æ®")

    print(f"\nğŸ¯ ç³»ç»Ÿç‰¹ç‚¹:")
    print(f"   âœ“ æ·±åº¦å¼ºåŒ–å­¦ä¹ æ™ºèƒ½å†³ç­–")
    print(f"   âœ“ å¤šä¼ æ„Ÿå™¨æ•°æ®èåˆå®šä½")
    print(f"   âœ“ åŠ¨æ€ç¯å¢ƒè‡ªé€‚åº”å¯¼èˆª")
    print(f"   âœ“ å®æ—¶æ€§èƒ½ç›‘æ§ä¼˜åŒ–")
    print(f"   âœ“ æ¨¡å—åŒ–å¯æ‰©å±•æ¶æ„")

    print(f"\nğŸš€ åº”ç”¨å‰æ™¯:")
    print(f"   â€¢ è‡ªä¸»ç§»åŠ¨æœºå™¨äºº")
    print(f"   â€¢ æ— äººé©¾é©¶è½¦è¾†")
    print(f"   â€¢ æ— äººæœºè‡ªä¸»é£è¡Œ")
    print(f"   â€¢ æœåŠ¡æœºå™¨äººå¯¼èˆª")
    print(f"   â€¢ å·¥ä¸šè‡ªåŠ¨åŒ–ç³»ç»Ÿ")

    if eval_success_rate > 80 and eval_fusion_error < 0.1:
        print(f"\nğŸ‰ ç³»ç»Ÿæ€§èƒ½è¯„ä»·: ä¼˜ç§€")
        print(f"   è¯¥ç³»ç»Ÿè¾¾åˆ°äº†å·¥ä¸šåº”ç”¨æ ‡å‡†ï¼Œå¯ç”¨äºå®é™…éƒ¨ç½²")
    elif eval_success_rate > 60 and eval_fusion_error < 0.2:
        print(f"\nğŸ‘ ç³»ç»Ÿæ€§èƒ½è¯„ä»·: è‰¯å¥½")
        print(f"   è¯¥ç³»ç»Ÿå…·æœ‰è‰¯å¥½çš„åŸºç¡€æ€§èƒ½ï¼Œå¯è¿›ä¸€æ­¥ä¼˜åŒ–")
    else:
        print(f"\nâš ï¸  ç³»ç»Ÿæ€§èƒ½è¯„ä»·: éœ€è¦æ”¹è¿›")
        print(f"   å»ºè®®è°ƒæ•´å‚æ•°æˆ–ç®—æ³•ä»¥æé«˜æ€§èƒ½")

if __name__ == "__main__":
    main()